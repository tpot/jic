#!/usr/bin/python
# coding=utf-8
#
# JIC - JIRA CLI client
#   by Serge Broslavsky <serge.broslavsky@linaro.org>
#
# Copyright 2014 Linaro Limited
# License: GPLv2
#

# Backlog:
# [ ] add URL to every fetched issue
# [ ] matching field names for flter for online/offline

from __future__ import print_function
import sys
import imp
import argparse
import signal
from os.path import expanduser, expandvars, isfile
import datetime
from tempfile import NamedTemporaryFile
import re
import os
from getpass import getpass
import subprocess
import shlex
import base64
import urlparse
import textwrap
import difflib
from tlslite.utils import keyfactory
import datetime
import json
import errno
import traceback
from collections import OrderedDict


__version__ = '15.07.1'


JIC_PROGRAM_NAME = 'jic'

# Verbosity levels
VERBOSITY_QUIET     = 0
VERBOSITY_ERRORS    = 1
VERBOSITY_WARNINGS  = 2
VERBOSITY_INFO      = 3

verbosity = VERBOSITY_ERRORS

def vset(new_verbosity):
    """Set current verbosity level."""
    global verbosity
    verbosity = new_verbosity


def vget():
    """Get current verbosity level."""
    global verbosity
    return verbosity


def vpre(msg_verbosity, string=u'', end=u'\n', flush=False):
    """Output the string to stderr if its verbosity does not exceed
    the current verbosity."""
    global verbosity
    if msg_verbosity <= verbosity:
        print(string.encode('utf-8'), file=sys.stderr, end=end)
        if flush:
            sys.stderr.flush()

def vpr(string=u'', end=u'\n', flush=False):
    """Output the string to stdout if its verbosity does not exceed
    the current verbosity."""
    global verbosity
    if msg_verbosity <= verbosity:
        print(string.encode('utf-8'), file=sys.stdout, end=end)
        if flush:
            sys.stdout.flush()

try:
    from jira.client import JIRA
    from jira.exceptions import JIRAError
    from jira.resources import Comment, Component, Issue, IssueType, \
                               Project, Resolution, Status, User, \
                               Version, Worklog
except ImportError:
    vpre(VERBOSITY_ERRORS,
         'Could not find jira-python module. Please install it as '\
         'described in INSTALL.md file. Aborting.')
    sys.exit(1)

class Util (object):

    DIRECTION_UP = u'up'
    DIRECTION_DOWN = u'down'
    DIRECTION_BOTH = u'both'
    DIRECTIONS = (DIRECTION_UP, DIRECTION_DOWN, DIRECTION_BOTH)

    # regexp that matches JIRA issue keys
    re_issue_key = re.compile(r'''^\w+-\d+$''')

    # regexp that matches new (not yet created) issue keys
    re_new_issue_key = re.compile(r'''^NEW-\w+-\d+$''')

    # regexp to match JIRA comment ids (with a leading issue key or not)
    re_comment_id = re.compile(r'''(?:\w+-\d+:)?\d+''')


    @staticmethod
    def is_issue_key(string):
        return Util.re_issue_key.match(string) is not None


    @staticmethod
    def is_new_issue_key(string):
        return Util.re_new_issue_key.match(string) is not None


    @staticmethod
    def is_comment_id(string):
        return Util.re_comment_id.match(string) is not None


    @staticmethod
    def to_int(value):
        if not value:
            return None

        vt = type(value)

        if vt is int:
            return value

        if vt is long:
            return int(value)

        if vt in (str, unicode):
            try:
                value = value.strip().lower()
                vl = len(value)
                if value[0] == u'0':
                    if vl == 1:
                        return 0
                    elif value[1] == u'x':
                        if vl == 2:
                            return None
                        else:
                            return int(value[2:], 16)
                    elif value[1] == u'o':
                        if vl == 2:
                            return None
                        else:
                            return int(value[2:], 8)
                    elif value[1] == u'b':
                        if vl == 2:
                            return None
                        else:
                            return int(value[2:], 2)
                    else:
                        return int(value, 8)
                else:
                    return int(value)
            except Exception:
                return None


    @staticmethod
    def ensure_dir_access(directory, access, mode):

        try:
            os.makedirs(directory, mode)
        except OSError, e:
            if e.errno != errno.EEXIST:
                return e, False

        if not os.access(directory, access):
            return True, False

        return True, True


    @staticmethod
    def get_nested_value(container, path, default=None):
        current = container
        while path:
            if current is None:
                return default

            item, _, path = path.partition(u'.')
            if not path:
                break

            try:
                if hasattr(current, '__dict__') and item in current.__dict__:
                    current = current.__dict__.get(item)
                elif item in current:
                    current = current.get(item)
                else:
                    return default
            except Exception:
                return default

        try:
            if hasattr(current, '__dict__') and item in current.__dict__:
                return current.__dict__.get(item)
            else:
                return current.get(item)
        except Exception:
            return default


    @staticmethod
    def get_issue_field_value(issue, field_name, return_object=False):
        # TODO: optimize
        if not issue:
            return None

        value = Util.get_nested_value(issue, field_name)

        if value is None:
            value = Util.get_nested_value(issue, 'fields.%s' % field_name)

        if field_name.endswith('updated') \
        or field_name.endswith('created') \
        or field_name.endswith('date'):
            value = Util.parse_jira_date(value)
        elif not return_object:
            tmp = Util.get_nested_value(issue, 'fields.%s.name' % field_name)
            if tmp is not None:
                value = tmp

        return value


    @staticmethod
    def is_stale(ttl, retrieved_at):
        if not retrieved_at:
            return True
        ts_now = datetime.datetime.utcnow()
        age = ts_now - retrieved_at
        if ttl < age.total_seconds():
            return True
        else:
            return False


    @staticmethod
    def unwrap_list_of_lists(val):
        if type(val) not in (list,tuple):
            return [val,]

        result = []
        for chop in val:
            chop = chop[0] if type(chop) in (list,tuple) else chop
            for item in chop.split(','):
                result.append(item.strip())

        return result


    @staticmethod
    def generate_sorting_key(field_name):
        def anonymous(issue):
            return Util.get_issue_field_value(issue, field_name)
        return anonymous


    @staticmethod
    def sort_issues(issues, criteria):
        if criteria is None:
            return issues
        # Python sorted() is a stable sort
        for criterion in reversed(criteria):
            criterion = criterion.strip()
            reverse = (criterion[-1] == u'-')
            criterion = criterion[:-1] \
                      if criterion[-1] in u'-+' \
                      else criterion
            fn = Util.generate_sorting_key(criterion)
            issues = sorted(issues, key=fn, reverse=reverse)
        return issues


    @staticmethod
    def get_jic_file():
        running_script = os.path.abspath(sys.argv[0])
        if os.path.islink(running_script):
            running_script = os.path.realpath(running_script)
        return running_script


    @staticmethod
    def get_jic_location():
        return os.path.dirname(Util.get_jic_file()) + os.sep


    FILTER_OP_CHARS = '=~!<>[]'
    FILTER_OP_CHARS_EX = FILTER_OP_CHARS + '\t '
    FILTER_CRITERION_DELIMITER = ','
    FILTER_VALUE_DELIMITER = ','

    @staticmethod
    def parse_filter_criterion(filter_criteria):
        """Parses -f switch payload.

        The filter expression can contain one or more sub-expressions, which
        are delimited by a comma. The format of sub-expression is:
            <name><operation><value>
        where <operation> is one of '=', '!=', '<', '<=', '>', '>='

        Sub expression can also be:
            <name><operation-start><value-list><operation-end>

        where <operation-start> and <operation-end> are one of '[', ']'
        and <value-list> is a coma-separated list ov strings

        The function returns a tuple of the following structure:
            #0 - error message or None
            #1 - list of sub expressions, each of which is a tuple:
                    #0 - name
                    #1 - operation
                    #2 - value or list of values depending on operation
        """

        if not filter_criteria:
            return (None, ())

        #filter_criteria = filter_criteria.strip()

        state = 'name'
        name = ''
        op = ''
        value = ''
        values = []
        sub_expressions = []
        list_delimiter = ''
        total_chars = len(filter_criteria)

        for pos, char in enumerate(filter_criteria, 1):

            if state == 'name':
                if char in Util.FILTER_OP_CHARS:
                    name = name.strip()
                    state = 'op'
                    # fall through
                elif char != Util.FILTER_CRITERION_DELIMITER:
                    name += char
                    if pos == total_chars and len(name.strip()):
                        return ('missing operator after "%s"'  % name,
                                sub_expressions)
                    continue

            if state == 'op':
                if char == '[':
                    op = char
                    state = 'in-list'
                    if pos == total_chars:
                        return ('missing value after "%s"'  % op,
                                sub_expressions)
                    continue
                elif char == ']':
                    op = char
                    state = 'not-in-list'
                    if pos == total_chars:
                        return ('missing value after "%s"'  % op,
                                sub_expressions)
                    continue
                elif char not in Util.FILTER_OP_CHARS_EX:
                    op = op.replace(' ','').replace('\t','')
                    if not op:
                        return ('missing value after "%s"'  % name,
                                sub_expressions)
                    state = 'value'
                    # fall through
                else:
                    op += char
                    if pos == total_chars:
                        return ('missing value after "%s"'  % op,
                                sub_expressions)
                    continue

            if state == 'value':
                if char == Util.FILTER_CRITERION_DELIMITER:
                    value = value.strip()
                    if not value:
                        return ('missing value after "%s"'  % op,
                                sub_expressions)
                    sub_expressions.append((name, op, value))
                    name = ''
                    op = ''
                    value = ''
                    values = []
                    list_delimiter = ''
                    state = 'name'
                    continue
                else:
                    value += char
                    if pos == total_chars:
                        value = value.strip()
                        if not value:
                            return ('missing value after "%s"'  % op,
                                    sub_expressions)
                        sub_expressions.append((name, op, value))
                        name = ''
                        op = ''
                        value = ''
                        values = []
                        list_delimiter = ''
                        state = 'name'
                    continue

            if state == 'in-list':
                if char == ']':
                    return ('empty list of values for "%s"'  % name.strip(),
                            sub_expressions)
                elif not char.isspace():
                    list_delimiter = char
                    if pos == total_chars:
                        return ('unclosed list of values for "%s"'  % name.strip(),
                                sub_expressions)
                    state = 'in-list-value'
                    continue

            if state == 'in-list-value':
                if char == list_delimiter:
                    value = value.strip()
                    if value:
                        values.append(value)
                        value = ''
                        if pos == total_chars:
                            return ('unclosed list of values for "%s"'  % name.strip(),
                                    sub_expressions)
                        continue
                elif char == ']':
                    value = value.strip()
                    if value:
                        values.append(value)
                        value = ''
                    sub_expressions.append((name, 'in', values))
                    name = ''
                    op = ''
                    value = ''
                    values = []
                    list_delimiter = ''
                    state = 'name'
                    continue
                else:
                    value += char
                    if pos == total_chars:
                        return ('unclosed list of values for "%s"'  % name.strip(),
                                sub_expressions)
                    continue

            if state == 'not-in-list':
                if char == '[':
                    return ('empty list of values for "%s"'  % name.strip(),
                            sub_expressions)
                elif not char.isspace():
                    list_delimiter = char
                    if pos == total_chars:
                        return ('unclosed list of values for "%s"'  % name.strip(),
                                sub_expressions)
                    state = 'not-in-list-value'
                    continue

            if state == 'not-in-list-value':
                if char == list_delimiter:
                    value = value.strip()
                    if value:
                        values.append(value)
                        value = ''
                        if pos == total_chars:
                            return ('unclosed list of values for "%s"'  % name.strip(),
                                    sub_expressions)
                        continue
                elif char == '[':
                    value = value.strip()
                    if value:
                        values.append(value)
                        value = ''
                    sub_expressions.append((name, 'not in', values))
                    name = ''
                    op = ''
                    value = ''
                    values = []
                    list_delimiter = ''
                    state = 'name'
                    continue
                else:
                    value += char
                    if pos == total_chars:
                        return ('unclosed list of values for "%s"'  % name.strip(),
                                sub_expressions)
                    continue

        return (None, sub_expressions)


    @staticmethod
    def generate_issue_diff_job(original, updated, field_meta):
        batch_job = []
        updated_issues = {}
        for issue in updated:
            updated_issues[issue['key']] = issue

        for o_issue in original:
            issue_job = {}
            if o_issue.key not in updated_issues:
                continue

            for name, o_value in o_issue.fields.__dict__.iteritems():
                u_value = updated.fields.__dict__.get(name)
                if not Util.are_field_values_equal(
                                o_value, u_value, field_meta):
                    field_job = Util.generate_field_diff_job(
                                        name, o_value, u_value,
                                        field_meta)
                    issue_job[field_job[0]] = field_job[1]
            if issue_job:
                batch_job.append((o_issue.key, issue_job))

        return batch_job


    @staticmethod
    def generate_field_diff_job(name, original_value, updated_value,
                                field_meta):
        # TODO: implement
        return (name, updated_value)


    @staticmethod
    def are_field_values_equal(lhs, rhs, field_meta):
        # TODO: implement
        return False


    @staticmethod
    def parse_filter_criteria(filter_criteria):
        if filter_criteria is None:
            return None

        or_groups = []
        for or_group in filter_criteria:
            error, criteria = \
                Util.parse_filter_criterion(or_group)
            if error:
                print('Error parsing filter "%s": %s' % \
                    (or_group[0], error))
                return None
            else:
                # build a sub-tree
                subtree = criteria[-1]
                for item in reversed(criteria[:-1]):
                    subtree = (item, 'and', subtree)
                or_groups.append(subtree)

        #build an AST now
        result = or_groups[-1] if len(or_groups) else None
        for or_group in reversed(or_groups[:-1]):
            result = (or_group, 'or', result)

        return result if result else None


    @staticmethod
    def evaluate_expression(issue, variables, expression):
        left, op, right = expression
        if isinstance(left, tuple):
            left = Util.evaluate_expression(issue, variables, left)

        if isinstance(left, basestring):
            if left[0] == '$':
                left = variables.get(left[1:], left)
            else:
                val = Util.get_issue_field_value(issue, left)
                if val is None:
                    val = Util.get_issue_field_value(issue, left + 's')
                left = val

        if isinstance(right, tuple):
            right = Util.evaluate_expression(issue, variables, right)

        if isinstance(right, basestring):
            if right[0] == '$':
                right = variables.get(right[1:], right)
            #else:
                #right = Util.get_issue_field_value(issue, right)

        if op == u'=' or op == u'==':
            if type(left) in (list,tuple):
                for item in left:
                    val = Util.get_nested_value(item, 'name')
                    if val and val == right:
                        return True
                    return False
            else:
                return left == right
        elif op == u'!=':
            return left != right
        elif op == u'~' or op == u'==':
            return left.find(right) != -1
        elif op == u'!~':
            return left.find(right) == -1
        elif op == u'<':
            return left < right
        elif op == u'<=' or op == u'=<':
            return left <= right
        elif op == u'>':
            return left < right
        elif op == u'>=' or op == u'=>':
            return left <= right
        elif op == u'in':
            return left in right
        elif op == u'not in':
            return left not in right
        elif op == u'or':
            return left or right
        elif op == u'and':
            return left and right


    @staticmethod
    def issue_matches_filter(issue, variables, filter):
        if not filter:
            return True
        if not variables:
            variables = {}

        filter = Util.expand_filter_variables(filter, variables)

        return Util.evaluate_expression(issue, variables, filter)


    @staticmethod
    def parse_jira_date(string):
        try:
            return datetime.datetime.strptime(string[:19], '%Y-%m-%dT%H:%M:%S')
        except Exception:
            return string


    @staticmethod
    def expand_filter_variables(filter, variables):
        if not filter:
            return filter

        lhs, op, rhs = filter
        if type(lhs) == tuple:
            lhs = Util.expand_filter_variables(lhs, variables)
        else:
            lhs = Util.expand_variables(lhs, variables)

        if type(rhs) == tuple:
            rhs = Util.expand_filter_variables(rhs, variables)
        else:
            rhs = Util.expand_variables(rhs, variables)

        return (lhs, op, rhs)


    @staticmethod
    def expand_variables(value, variables):
        if type(value) == list:
            return [Util.expand_variables(item, variables) \
                        for item in value]

        start = 0
        result = u''
        string = value
        nchars = len(string)
        while True:
            pos = string.find(u'$', start)
            if pos == -1:
                result += string[start:]
                break
            result += string[start:pos]
            pos += 1
            name = u''
            while pos < nchars and string[pos].isalnum():
                name += string[pos]
                pos += 1
            value = variables.get(name)
            result += str(value)
            start = pos
        return result


    @staticmethod
    def edit_file(editor, file_name):
        try:
            subprocess.call([editor, file_name])
            return True
        except:
            return False


    @staticmethod
    def get_from_editor(cfg, editor, initial_text, file_suffix=u''):
        file_prefix = u'jic-'
        if file_suffix:
            file_prefix += file_suffix + u'-'
        try:
            f_to_edit = NamedTemporaryFile(
                    mode='wt', prefix=file_prefix, delete=False)
            f_to_edit.write(initial_text.encode('utf-8'))
            f_to_edit.close()
        except Exception, e:
            raise RuntimeError(
                u'ERROR: Unable to create a file for editing: ' +
                str(e))

        if not Util.edit_file(editor, f_to_edit.name):
            return None

        try:
            f_edited = open(f_to_edit.name)
            new_text = f_edited.read().decode('utf-8')
            f_edited.close()
            os.remove(f_to_edit.name)
        except Exception, e:
            raise RuntimeError(
                u'ERROR: Unable to edit file \'%s\': %s' % (
                    f_to_edit.name, str(e)))

        if new_text == initial_text:
            return None

        return new_text


    @staticmethod
    def parse_comment_ids(args):
        job = []
        current_issue = None
        for chunk in args:
            for pair in chunk.split(u','):
                head, _, tail = pair.partition(u':')
                head = head.strip()
                tail = tail.strip()
                if tail:
                    current_issue = head
                    job.append((current_issue, [tail,]))
                else:
                    if Util.is_issue_key(head):
                        current_issue = head
                        job.append((current_issue, []))
                    elif current_issue:
                        job[-1][1].append(head)
                    else:
                        pre(u'WARNING: \'%s\' is not an issue key '\
                            u'- ignored' % head)
        return job


    @staticmethod
    def confirm(prompt, strict=False):
        if not sys.stdin.isatty():
            # confirmation requires human input
            return False

        prompt = prompt + u' '
        response = ''
        while response == '':
            try:
                response = raw_input(prompt)
            except EOFError:
                response = 'n'
            if strict:
                if response == 'YES':
                    return True
                elif response != '':
                    return False
            else:
                if response == '':
                    continue
                if response.lower() == 'y':
                    return True
                else:
                    return False

# class Util


class TextIterator:
    """Helps iterating through text lines"""
    def __init__(self, text):
        self.lines = text.splitlines()
        self.nline_next = 0
        self.nline_max = len(self.lines) - 1


    def __iter__(self):
        return self


    def next(self):
        if self.nline_next > self.nline_max:
            raise StopIteration
        else:
            nline = self.nline_next
            self.nline_next += 1
            return self.lines[nline]


    def previous(self):
        if self.nline_next == 0:
            raise StopIteration
        else:
            self.nline_next -= 1
            return self.lines[self.nline_next]

# class TextIterator


class FileTextIterator:

    # indexes of self.cache data bits
    IDX_FROM    = 0
    IDX_TO      = 1
    IDX_NLINES  = 2
    IDX_LINES   = 3

    """Helps iterating through text lines of a file"""
    def __init__(self, file, cache_size=1):
        self.file = file
        self.previous_line = None
        self.last_line = None
        self.owns_file = False
        if isinstance(file, basestring):
            self.file = open(self.file, 'rt')
            self.owns_file = True


    def __iter__(self):
        return self


    def next(self):
        if self.previous_line is not None:
            self.last_line = self.previous_line
            self.previous_line = None
            return self.last_line
        self.last_line = self.file.readline().decode('utf-8')
        #self.last_line = self.read_line()
        if self.last_line == u'':
            self.last_line = None
            raise StopIteration
        return self.last_line


    def previous(self):
        if self.previous_line is not None:
            raise StopIteration
        self.previous_line = self.last_line
        return self.last_line


    def read_line(self):
        line = ''
        while True:
            ch = self.file.read(1)
            pre(u'Char: %s (%d)' % (ch, ord(ch) if ch else -1))
            if ch in ('', '\004', '\n'):
                return None if not line else line
            else:
                line += ch


# class TextIterator


class JQL (object):

    @staticmethod
    def emit_order_by(fields):
        if not fields:
            return u''

        result = []
        for field in fields:
            field = field.strip()
            if field[-1] == u'-':
                result.append(u'%s desc' % field[:-1])
            elif field[-1] == u'+':
                result.append(u'%s asc' % field[:-1])
            else:
                result.append(u'%s asc' % field)

        return u'order by ' + u', '.join(result)


    @staticmethod
    def emit_filter(filter, variables):
        left, op, right = filter

        if isinstance(left, tuple):
            left = JQL.emit_filter(left, variables)

        if isinstance(right, tuple):
            right = JQL.emit_filter(right, variables)
        elif isinstance(right, list):
            right = '(' + (','.join([('"%s"' % item) \
                        for item in right])) + ')'
        else:
            if right[0] == '$':
                right = variables.get(right[1:], left)
            right = '"%s"' % right

        if op in ('and', 'or'):
            wrap = True
        else:
            wrap = False

        return '%s%s %s %s%s' % (
                    '( ' if wrap else '',
                    left, op, right,
                    ' )' if wrap else '')


    @staticmethod
    def parse_jql_statement(jql):
        # TODO: implement
        return None, None


    @staticmethod
    def replace_variable_with_JQL(name):
        if name == '$me':
            return 'currentUser()'
        return name

# class JQL


class Namespace (object):

    def __init__(self, dictionary=None, mapping=None):
        object.__setattr__(self, '_values', {})
        object.__setattr__(self, '_learn', True)
        if dictionary:
            self.update_from(dictionary, mapping)


    def cleanup(self):
        vals = object.__getattribute__(self, '__dict__').get('_values')
        for name in vals.keys():
            value = vals.get(name)
            if type(value) == Namespace:
                if value.cleanup():
                    del vals[name]

        return len(vals) == 0


    def learn(self, flag):
        current = object.__getattribute__(self, '_learn')
        if not flag:
            self.cleanup()
        for name, val in self.iteritems():
            if type(val) == Namespace:
                val.learn(flag)
        object.__setattr__(self, '_learn', flag)


    def get(self, name, default=None):
        #print('get_value(%s)' % name, end='')
        internal = object.__getattribute__(self, '__dict__')
        if name.startswith('_') or name in internal:
            return object.__getattribute__(self, name)

        current = internal.get('_values')
        path = name
        while path:
            name, _, path = path.partition('.')
            if name in current:
                if path:
                    current = current[name]
                    continue
                #print(' => %s' % current[name])
                return current[name]
            break

        #print(' => None')
        return default


    def set(self, name, value):
        #print('set(%s, %s)' % (name,value))
        if not name:
            return
        internal = object.__getattribute__(self, '__dict__')
        if name.startswith('__') or name in internal:
            return object.__setattr__(self, name, value)

        values = object.__getattribute__(self, '_values')
        current = values
        previous = current
        for subname in name.split('.'):
            if subname not in current \
            or type(current[subname]) != Namespace:
                current[subname] = Namespace()
            previous = current
            current = current[subname]

        if type(value) == dict:
            val = Namespace(value)
        previous[subname] = value
        return
        #return object.__setattr__(self, name, value)


    def update_from(self, obj, mapping=None):
        """Update values in the namespace hierarchically using the
        values from `obj` and translating their names using `mapping` if
        present."""
        if not obj:
            return
        if type(obj) == dict:
            iterator = obj.iteritems()
        elif type(obj) == argparse.Namespace:
            iterator = (
                (key, val) for key, val in obj._get_kwargs() \
                                        if not key.startswith('_'))
        elif type(obj) == type(self):
            iterator = obj.itertree()
        else:
            raise TypeError(\
                'only dict and Namespace types are supported')
        for path, val in iterator:
            if val is not None:
                if mapping:
                    mapped_name = mapping.get(path)
                    if mapped_name:
                        if type(mapped_name) in (list,tuple):
                            mapped_name, convertor = mapped_name
                            val = convertor(val)
                        path = mapped_name
                self.set(path, val)


    def __getattribute__(self, name):
        #print('__get_attribute__(%s)' % name, end='')
        if name.startswith('_') \
        or name in object.__getattribute__(self, '__dict__') \
        or name in object.__getattribute__(self, '__class__').__dict__:
            #print(' => %s' % object.__getattribute__(self, name))
            return object.__getattribute__(self, name)

        values = object.__getattribute__(self, '_values')
        if name not in values:
            if object.__getattribute__(self, '_learn'):
                values[name] = Namespace()
            else:
                return None

        #print(' => %s' % values.get(name))
        return values.get(name)


    def __setattr__(self, name, value):
        #print('__setattr__(%s, %s)' % (name,value))
        internal = object.__getattribute__(self, '__dict__')
        if name.startswith('_') \
        or name in internal:
            return object.__setattr__(self, name, value)
        #vals = object.__getattribute__(self, '_values')
        vals = internal.get('_values')
        vals[name] = value


    def __getitem__(self, key):
        #print('__getitem__(%s) => %s' % (
            #key, object.__getattribute__(self, '_values').get(key)), end='')
        return object.__getattribute__(self, '_values').get(key)


    def __setitem__(self, key, value):
        #print('__setitem__(%s, %s)' % (key,value))
        return self.set(key, value)


    def __delitem__(self, key):
        #print('__delitem__(%s)' % key, end='')
        del object.__getattribute__(self, '_values')[key]


    def __contains__(self, path):
        name, _, rest = path.partition('.')
        vals = object.__getattribute__(self, '_values')
        if name not in vals:
            return False
        option = vals.get(name)
        if rest:
            return rest in option
        return True


    def __len__(self):
        return len(object.__getattribute__(self, '_values'))


    def __iter__(self):
        return sorted(
            object.__getattribute__(self, '_values').__iter__())


    def iterkeys(self):
        return sorted(
            object.__getattribute__(self, '_values').iterkeys())


    def iteritems(self):
        return sorted(
            object.__getattribute__(self, '_values').iteritems())


    def itertree(self):
        """iterate tree leafes - depth first approach"""

        class TreeDepthFirstIterator (object):

            def __init__(self, namespace):
                self.queue = [('',namespace),]

            def __iter__(self):
                return self

            def next(self):
                current_path = ''
                while self.queue:
                    path, item = self.queue.pop(0)
                    if type(item) == Namespace:
                        for name, value in reversed(item.iteritems()):
                            if path:
                                self.queue.insert(
                                    0, ('%s.%s' % (path, name), value))
                            else:
                                self.queue.insert(
                                    0, ('%s' % name, value))
                    else:
                        return path, item

                raise StopIteration()

        return TreeDepthFirstIterator(self)


    def __str__(self):
        res = u''
        for path, value in self.itertree():
            res += u'%s: %s\n' % (path, value)
        return res

# class Namespace


class Configuration (object):

    # previous jic versions' configuration file formats
    old_version_parsers = {} # initialized after the class definition
    CONFIG_FILE_NAME = 'config'
    CONFIG_FILE_SIGNATURE = '# JIC Configuration File Version '
    OLD_CONFIGURATION_FILE = '~/.jicrc'

    # jic configuration file format version
    version = 3

    # mapping of old configuration option names to new ones
    map_old_options_to_new = {} # initialized after the class definition

    defaults = {
        # FS location for configuration file and other data
        'home.location': '~/.jic/',

        # FS mode to be used for home FS location
        'home.mode': 0700,

        # default command line mode; options are:
        #   'porcelain' - for high-level commands
        #   'plumbing'  - for low-level commands
        'cl.mode': 'plumbing',

        # caching mode; options are:
        #   'online'    - always query from the server, but keep cache
        #                 up to date
        #   'cached'    - query from the cache if not stale, query from
        #                 the server otherwise
        #   'offline'   - always query from the cache
        'cache.mode': 'online',

        # cache TTL in seconds
        'cache.ttl': 3600,

        # location of the cache's FS storage; use '+' prefix for paths
        # relative to 'home.location'
        'cache.location': '+cache',

        # should searches be done using server in `cached` mode
        # (alternative is to search in local cache only)
        'query.search_online': False,

        # default message verbosity
        'display.verbosity': VERBOSITY_WARNINGS,
    }

    new_file_defaults = {
        # porcelain mode command definitions
        'commands.jadd.aliases': 'add,ad,a',
        'commands.jadd.help': 'add issue comments',
        'commands.jadd.plumbing': 'comments add',

        'commands.jedc.aliases': 'editc,edic,edc,ec',
        'commands.jedc.help': 'edit issue comments',
        'commands.jedc.plumbing': 'comments edit',

        'commands.jdel.aliases': 'delete,delet,dele,del,de,d',
        'commands.jdel.help': 'delete issue comments',
        'commands.jdel.plumbing': 'comments delete',

        'commands.jsh.aliases': 'show,sho,sh,s',
        'commands.jsh.help': 'show essential issue information',
        'commands.jsh.plumbing': 'issue show -p fields',

        'commands.jsh.sc.comments.aliases':
        'comment,commen,comme,comm,com,cmts,cmt,co,c',
        'commands.jsh.sc.comments.help': 'show issue comments',
        'commands.jsh.sc.comments.plumbing': 'issues show -p comments',

        'commands.jsh.sc.fields.aliases': 'field,fiel,fie,fld,fi,fl,f',
        'commands.jsh.sc.fields.help': 'show issue fields',
        'commands.jsh.sc.fields.plumbing': 'issues show -p fields',

        'commands.jsh.sc.history.aliases': 'histor,histo,hist,his,hi,h',
        'commands.jsh.sc.history.help': 'show issue change history',
        'commands.jsh.sc.history.plumbing': 'issues show -p history',

        'commands.jsh.sc.links.aliases': 'link,lin,lnk,li,ln,l',
        'commands.jsh.sc.links.help': 'show issue links',
        'commands.jsh.sc.links.plumbing': 'issues show -p links',

        'commands.jsh.sc.all.aliases': 'al,a',
        'commands.jsh.sc.all.help': 'show all information for the issue',
        'commands.jsh.sc.all.plumbing': 'issues show -p all',

        'commands.jls.aliases': 'list,lis,li,ls,l',
        'commands.jls.help': 'list issues reported by or assigned to you',
        'commands.jls.plumbing': 'issues list -f assignee=$me -f reporter=$me',

        'commands.jls.sc.assigned.aliases': 'assigne,assign,assig,assi,ass,as,a',
        'commands.jls.sc.assigned.help': 'list issues assigned to you',
        'commands.jls.sc.assigned.plumbing': 'issues list -f assignee=$me',

        'commands.jls.sc.reported.aliases': 'reporte,report,repor,repo,rep,re,r',
        'commands.jls.sc.reported.help': 'list issues reported by you',
        'commands.jls.sc.reported.plumbing': 'issues list -f reporter=$me',

        'commands.jed.aliases': 'edit,edi,ed,e',
        'commands.jed.help': 'edit an existing issue',
        'commands.jed.plumbing': 'issues edit -e',

        'commands.jo.aliases': 'open,ope,op,o',
        'commands.jo.help': 'open issues in a browser',
        'commands.jo.plumbing': 'issues open',
    }

    def __init__(self):
        # TODO: refactor - try and fix instead of check and try
        self.o = self.get_defaults()

        # get home location from env
        self.o.home.location = os.environ.get(
            'JIC_O_HOME_LOCATION', self.o.home.location)
        self.o.home.mode = Util.to_int(os.environ.get(
            'JIC_O_HOME_MODE', self.o.home.mode))
        self.o.display.verbosity = Util.to_int(os.environ.get(
            'JIC_O_DISPLAY_VERBOSITY', self.o.display.verbosity))
        vset(self.o.display.verbosity)

        home = os.path.expanduser(
                    os.path.expandvars(self.o.home.location))

        home_exists, home_accessible = Util.ensure_dir_access(
                home, os.R_OK | os.W_OK | os.X_OK, 0700)

        if home_exists != True:
            raise home_exists

        if not home_accessible:
            raise RuntimeError(
               'Home directory \'%s\' should have \'rwx\' mode' %\
                                                       self.o.home)

        self.config_file = home + os.sep + Configuration.CONFIG_FILE_NAME
        if not os.access(self.config_file, os.F_OK):
            options = self.get_defaults()
            old_options = self.parse_old_config_file()
            if old_options:
                vpre(VERBOSITY_INFO, u'Imported old version\'s options')
            options.update_from(old_options)
            new_file_options = Namespace(Configuration.new_file_defaults)
            options.update_from(new_file_options)
            vpre(VERBOSITY_INFO, u'Creating new config file: %s' %\
                                                    self.config_file)
            self.create_new_file(options, self.config_file)

            if sys.stdin.isatty() and sys.stdout.isatty():
                editor = self.o.get('editor', 'sensible-editor')
                vpre(VERBOSITY_INFO,
                    u'Editing new config file \'%s\' in %s' %\
                        (self.config_file, editor))
                Util.edit_file(editor, self.config_file)

        vpre(VERBOSITY_INFO, u'Reloading new config file \'%s\'' %\
                                                    self.config_file)
        self.o.update_from(self.load_file(self.config_file))
        vset(self.o.display.verbosity)
        self.update_from_environment()


    def freeze(self, freeze=True):
        self.o.learn(not freeze)


    def get_defaults(self):
        defaults = Namespace(Configuration.defaults)
        defaults.set('symlink.location', Util.get_jic_location())
        return defaults


    def init_home(self):
        home_location = self.o.get('home.location')
        if home_location is None:
            return False, 'homeless configuration'
        home_mode = self.o.get('home.mode')
        if home_mode is None:
            home_mode = 0700
        home_location = os.path.expanduser(
                            os.path.expandvars(home_location))
        try:
            os.mkdir(home_location, home_mode)
        except OSerror, e:
            if e.errno != errno.EEXISTS:
                return False, e.message


    def create_new_file(self, options, config_file):
        try:
            if not options:
                options = self.o
            if not config_file:
                home = os.path.expanduser(
                            os.path.expandvars(self.o.home.location))
                config_file = home + Configuration.CONFIG_FILE_NAME

            f = open(config_file, 'w')
            f.write(Configuration.CONFIG_FILE_SIGNATURE +\
                    str(self.version) + '\n\n')
            for path, value in options.itertree():
                f.write(u'o.' + path + u' = ' + repr(value) + u'\n')
            f.close()
        except IOError, e:
            # TODO: report error
            raise


    def update_file(self, options):
        to_update = {}

        if type(options) == Namespace:
            for path, value in options.itertree():
                to_update[path] = value
        else:
            to_update = options

        try:
            home = os.path.expanduser(
                        os.path.expandvars(self.o.home.location))
            config_file_name = home + Configuration.CONFIG_FILE_NAME

            replacing = False
            fi = open(config_file_name, 'r')
            fo = open(config_file_name + '.new', 'w')
            for line in fi:
                if not line.strip() and not replacing:
                    fo.write(u'\n')
                    continue

                ch = line[0]

                if ch == u'#' and not replacing:
                    fo.write(line)
                    continue

                if not ch.isspace():
                    if replacing:
                        replacing = False

                    name, _, value = line.partition(u'=')
                    if _ != u'=':
                        fo.write(line)
                        continue

                    name = name.strip()
                    if not name.startswith(u'o.'):
                        fo.write(line)
                        continue

                    name = name[2:]
                    if name in to_update:
                        value = to_update.get(name)
                        if isinstance(value, basestring) \
                        and value.find('\n') >= 0:
                            first = True
                            lines = value.splitlines(True)
                            max_idx = len(lines) - 1
                            for idx, line in enumerate(lines):
                                if first:
                                    fo.write(u'o.%s = \\\n' % name)
                                    first = False
                                line = line.replace('\t','\\t').\
                                            replace('\n','\\n')
                                fo.write(u'    u\'%s\'%s\n' % (
                                    line, ('\\' if idx != max_idx else '')))
                        elif value is not None:
                            fo.write(u'o.%s = %s\n' % (name, repr(value)))
                        del to_update[name]
                        replacing = True
                    else:
                        fo.write(line)

                else:
                    if not replacing:
                        fo.write(line)

            fo.write(u'\n')

            keys = sorted(to_update.keys())
            for name in keys:
                value = to_update.get(name)
                if isinstance(value, basestring) \
                and value.find('\n') >= 0:
                    first = True
                    lines = value.splitlines(True)
                    max_idx = len(lines) - 1
                    for idx, line in enumerate(lines):
                        if first:
                            fo.write(u'o.%s = \\\n' % name)
                            first = False
                        line = line.replace('\t','\\t').\
                                    replace('\n','\\n')
                        fo.write(u'    \'%s\'%s\n' % (
                            line, ('\\' if idx != max_idx else '')))
                    fo.write
                else:
                    fo.write(u'o.%s = %s\n' % (name, repr(value)))

            fo.write(u'\n')

            fo.close()
            fi.close()
            os.rename(config_file_name, config_file_name + '~')
            os.rename(config_file_name + '.new', config_file_name)
        except IOError, e:
            # TODO: report error
            raise


    def parse_config_file(self):
        return self.load_file()


    def parse_old_config_file(self):
        """Reads configuration from a v2 configuration file."""
        try:
            version = None
            file_name = Configuration.OLD_CONFIGURATION_FILE
            file_name = os.path.expanduser(
                            os.path.expandvars(file_name))
            f = open(file_name, 'r')
            config_text = f.read()
            f.close()
            # check version
            if not config_text.startswith(
                    Configuration.CONFIG_FILE_SIGNATURE):
                raise IOError(
                    'Configuration file %s has no signature '
                    'string. Aborting.' % file_name)
            else:
                version = \
                    config_text[ \
                        len(Configuration.CONFIG_FILE_SIGNATURE):]\
                            .split()[0]
                if version not in Configuration.version_parsers:
                    raise IOError(
                        '%s - config file format has version %s '\
                        'which is not supported.' % (
                            file_name, version))
                # call appropriate config parser
                return Configuration.version_parsers[version]\
                        (self, file_name, config_text)
        except IOError, e:
            # TODO: report error properly
            return None

        if opts['oauth_cert'] is not None:
            try:
                cf = opts['oauth_cert']
                if not os.access(cf, os.R_OK | os.W_OK | os.X_OK):
                    raise RuntimeError('OAuth certificate file \'%s\' '\
                        'should have at least \'r\' mode' % cf)
                f = open(os.path.expanduser(
                            os.path.expandvars(opts['oauth_cert'])))
                key = f.read().strip()
                opts['oauth_cert'] = key
            except Exception, e:
                pre(u'Failed to read private key from %s: %s\n'\
                    u'OAuth is not available' % \
                    (opts['oauth_cert'], unicode(e)))
                sys.exit(1)


    def parse_old_config_v2(self, file_name, config_text):
        """Parses config and populates __options"""
        result = Namespace()
        parsed = {}
        try:
            exec(config_text, globals(), parsed)

            if parsed['oauth_cert'] is not None:
                try:
                    f = open(os.path.expanduser(
                                os.path.expandvars(parsed['oauth_cert'])))
                    key = f.read().strip()
                    parsed['oauth_cert'] = key
                except Exception, e:
                    pre(u'Failed to read private key from %s: %s\n'\
                        u'OAuth is not available' % \
                        (parsed['oauth_cert'], unicode(e)))
                    sys.exit(1)

            for name, value in parsed.iteritems():
                target = self.map_old_options_to_new.get(name)
                if target:
                    if callable(target):
                        target(result, value)
                    else:
                        result.set(target, value)

            result.set('server', 'default')

        except Exception, e:
            pre(u'Error parsing configuration file \'%s\': %s' % \
                (file_name, unicode(e)))
            return None

        return result


    def load_file(self, file_name=None):
        if not file_name:
            file_name = self.o.home.location + os.sep +\
                Configuration.CONFIG_FILE_NAME

        file_name = os.path.expanduser(
                        os.path.expandvars(file_name))

        try:
            options = Namespace()
            parsed = {}
            f = open(file_name, 'r')
            config_text = f.read()
            f.close()
            # check version
            if not config_text.startswith(
                    Configuration.CONFIG_FILE_SIGNATURE):
                raise IOError(
                    'Configuration file %s has no signature '
                    'string. Aborting.' % file_name)
            else:
                version = Util.to_int(\
                    config_text[ \
                        len(Configuration.CONFIG_FILE_SIGNATURE):]\
                            .split()[0])
                if version != self.version:
                    raise IOError(
                        '%s - config file format has version %s '\
                        'which is not supported.' % (
                            file_name, version))
            exec(config_text, {'o': options}, parsed)
            return options

        except IOError, e:
            raise
            # TODO: properly handle
        except Exception, e:
            raise
            # TODO: properly handle


    def update_from_environment(self, env=None):
        if env is None:
            env = os.environ
        for name, value in env.iteritems():
            if name.startswith('JIC_O_'):
                option_name = \
                    name[6:].strip().replace('_','.').replace('..','_').lower()
                self.o[option_name] = value.strip()


    @staticmethod
    def _split_oauth_pair(ns, pair):
        """Splits oauth pair into token and secret and stores them in
        namespace"""
        ns.servers.default.oauth.token,\
                ns.servers.default.oauth.secret = pair.split(':')


    def __str__(self):
        return '%s(%s)' % (
                type(self).__name__,
                str(self.o))


Configuration.map_old_options_to_new = {
    'editor':       'editor',
    'browser':      'browser',
    'server':       'servers.default.url',
    'user':         'servers.default.user',
    'password':     'servers.default.password',
    'oauth_pair':   Configuration._split_oauth_pair,
    'oauth_cert':   'servers.default.oauth.cert',
}

Configuration.version_parsers = {
    '2': Configuration.parse_old_config_v2,
}

# class Configuration

class CommandLine (object):

    UNWRAP_NONE   = staticmethod(lambda val: val)

    UNWRAP_SINGLE = staticmethod(lambda val: val[0] if type(val) in (list,tuple) \
                                       else val)

    UNWRAP_LIST   = staticmethod(lambda val: [item[0] if type(item) in (list,tuple) \
                                         else item \
                                            for item in val])

    UNWRAP_LIST_OF_LISTS = staticmethod(Util.unwrap_list_of_lists)

    cl_to_options_map = {} # filled in in the end of class declaration

    def __init__(self, cfg):
        # TODO: implement
        self.cfg = cfg
        #self.porcelain_commands = self._build_commands_from_config(
        #                               cfg.o.commands)
        self._build_plumbing_commands()
        self._build_porcelain_commands()

        command_path, parsed_cl = self._parse_command_line(cfg.o)

        options = Namespace()
        direct_options = Namespace(parsed_cl,
                                   CommandLine.cl_to_options_map)

        if direct_options.cl.mode == 'porcelain':
            # translate porcelain command into plumbing one
            #command_path, parsed_cl = self._porcelain_into_plumbing(
            # TODO: remove magic numbers
            if (command_path is None or len(command_path) == 0) \
            and len(parsed_cl.args) > 0:
                cfg.o.set('cl.unrecognized', parsed_cl.args)
                raise RuntimeError(u'Unrecognized command: %s' % \
                        u' '.join(parsed_cl.args))

            aliases, subcommands, (action_type, action), description = \
                    command_path[0]
            if action_type != 'plumbing':
                # TODO: report error: inconsistent command definition
                print('Incorrect command definition for \'%s\'' %
                        aliases[0])
                sys.exit(1)
            # TODO: remove magic numbers
            args = shlex.split(action)
            args.extend(direct_options.query.args)
            direct_options.cl.args = None
            command_path, parsed_plumbing_cl = \
                self._parse_modal_command_line(self.plumbing_commands,
                                               args)
            options = Namespace(parsed_plumbing_cl,
                                CommandLine.cl_to_options_map)

        options.update_from(direct_options)

        cfg.o.update_from(options)

        self.command_path = command_path
        self.command = command_path[0] if command_path else None

        # normalize configuration values
        if cfg.o.get('query.process_all', False):
            cfg.o.set('query.parts', ('all',))
        else:
            normalized = []
            for part in cfg.o.get('query.parts', ()):
                part = part.strip()
                if part in ('all', 'al', 'a'):
                    normalized.append('all')
                    break
                elif part in ('fields', 'field', 'fiel', 'fie', 'fld',
                              'fi', 'fl', 'f'):
                    normalized.append('fields')
                elif part in ('comments', 'comment', 'commen', 'comme',
                              'comm', 'com', 'cmts', 'cmt', 'co', 'c'):
                    normalized.append('comments')
                elif part in ('history', 'histor', 'histo', 'hist',
                              'his', 'hi', 'h'):
                    normalized.append('history')
                elif part in ('links', 'link', 'lin', 'lnk', 'li', 'ln',
                              'l'):
                    normalized.append('links')
                elif part in ('worklog', 'worklo', 'workl', 'work',
                              'wor', 'wo', 'w'):
                    normalized.append('worklog')
                else:
                    pre(u'Unrecognized part specified: '\
                        u'\'%s\'. Ignored.' % part)
            if normalized:
                cfg.o.set('query.parts', normalized)

        filter = Util.parse_filter_criteria(cfg.o.get('query.filter'))
        cfg.o.set('query.filter', filter)

        # set verbosity
        vset(cfg.o.get('display.verbosity', vget()))

        # get values requested from the stdin

        if cfg.o.get('query.get_keys', False):
            # read keys from the stdin until an empty line or an EOF
            new_keys = []
            while True:
                line = sys.stdin.readline()
                line = line.strip()
                if not line:
                    break
                for chunk in line.split(','):
                    for key in chunk.split(' '):
                        if not key:
                            continue
                        if not Util.is_issue_key(key) \
                        and not Util.is_comment_id(key):
                            raise RuntimeError(
                                u'Invalid issue key or comment id provided: \'%s\'' % key)
                        new_keys.append(key)

            keys = cfg.o.get('query.args')
            if type(keys) != list:
                keys = new_keys
            else:
                keys.extend(new_keys)
            cfg.o.set('query.args', keys)

        if cfg.o.get('query.from_stdin', False):
            stdin_query = sys.stdin.readline().strip()
            if stdin_query:
                queries = cfg.o.get('query.jql', [])
                queries.append(stdin_query)
                cfg.o.set('query.jql', queries)


    def execute(self, cfg):
        # TODO: implement
        if not self.command:
            return

        aliases, subcommands, action_pair, description = self.command

        if not action_pair:
            raise RuntimeError(
                u'Please specify subcommand for \'%s\'' % aliases[0])

        action_type, action = action_pair

        if action_type == 'python':
            return action(self.cfg)
        else:
            RuntimeError(
                u'Don\'t know how to perform the command %s (%s)' % \
                    (aliases[0], action_type))


    def _parse_command_line(self, cfg=None, args=None):
        """Parses command line taking into account its mode.

        Returns: (subject, command, namespace)
        """

        if not cfg:
            cfg = self.cfg

        prog_name = os.path.basename(sys.argv[0])
        if not prog_name or not prog_name.strip():
            return None

        mode = None
        if prog_name != JIC_PROGRAM_NAME:
            mode = 'porcelain'

        root_parser = self._build_root_parser()
        parsed_cl, unparsed_args = root_parser.parse_known_args(args)
        if parsed_cl.help:
            if parsed_cl.mode:
                mode = parsed_cl.mode
            if mode is None:
                root_parser.print_help()
                sys.exit(0)
            else:
                if mode == 'porcelain':
                    self._build_modal_parser(self.porcelain_commands).print_help()
                elif mode == 'plumbing':
                    self._build_modal_parser(self.plumbing_commands).print_help()
                sys.exit(0)

        if parsed_cl.mode is None:
            if mode is None:
                mode = cfg.get('cl.mode')
        else:
            mode = parsed_cl.mode

        args = unparsed_args

        if prog_name != JIC_PROGRAM_NAME:
            args.insert(0, prog_name)

        commands = None
        if mode == 'porcelain':
            commands = self.porcelain_commands
        elif mode == 'plumbing':
            commands = self.plumbing_commands

        command_path, parsed_cl = \
            self._parse_modal_command_line(commands, args)

        parsed_cl.mode = mode

        return (command_path, parsed_cl)


    def _parse_modal_command_line(self, command_defs, args):

        modal_parser = self._build_modal_parser(command_defs)
        parsed_cl, unparsed_args = modal_parser.parse_known_args(args)
        if parsed_cl.help:
            modal_parser.print_help()
            sys.exit(0)

        consumed_args = 0

        consumed_args, command_path = \
            self._lookup_command(command_defs, unparsed_args)

        del unparsed_args[:consumed_args]

        parsed_cl.args = unparsed_args

        return (command_path, parsed_cl)


    def _lookup_command(self, command_defs, args):
        """Returns (no_of_consumed_args, command_path)"""
        if args is None or len(args) < 1:
            return (0, None)
        next_arg = 0
        nargs = len(args)
        consumed_args = 0

        command_path = []
        current_level_commands = command_defs

        while current_level_commands:
            next_level = False
            for command in current_level_commands:
                aliases, commands, function, description = command
                for alias in aliases:
                    if alias == args[next_arg]:
                        command_path.insert(0, command)
                        next_arg += 1
                        consumed_args += 1
                        next_level = True
                        if next_arg >= nargs:
                            return (consumed_args, command_path)
                        if type(commands) in (list,tuple):
                            current_level_commands = commands
                            break
                        else:
                            current_level_commands = None
                            break
                if next_level:
                    break
            if not next_level:
                break

        return (consumed_args, command_path)

    def _build_plumbing_commands(self):
        self.plumbing_commands = (
            (('comments', 'comment', 'commen', 'comme', 'comm', 'com',
                    'co', 'c'),
                (
                    (('add', 'ad', 'a'),
                        None,
                        ('python', cmd_comments_add),
                        'add new comments'),
                    (('delete', 'delet', 'dele', 'del', 'de', 'd'),
                        None,
                        ('python', cmd_comments_delete),
                        'delete existing comments'),
                    (('edit', 'edi', 'ed', 'e'),
                        None,
                        ('python', cmd_comments_edit),
                        'edit existing comments'),
                    (('list', 'lis', 'li', 'ls', 'l'),
                        None,
                        ('python', cmd_comments_list),
                        'list comments'),
                    #(('reply', 'repl', 'rep', 're', 'r'),
                        #None,
                        #('python', cmd_comments_reply),
                        #'reply to existing comments'),
                    (('show', 'sho', 'sh', 's'),
                        None,
                        ('python', cmd_comments_show),
                        'show comments'),
                ),
                None,
                'issue comment related commands'
            ),
            (('commands', 'command', 'comman', 'comma', 'comm', 'com',
                    'co', 'cm'),
                (
                    #(('add', 'ad', 'a'),
                        #None,
                        #('python', lambda cfg, cache, tpl: print('commands:add')),
                        #'add a command for the porcelain mode'),
                    #(('delete', 'delet', 'dele', 'del', 'de', 'd'),
                        #None,
                        #('python', lambda cfg, cache, tpl: print('commands:delete')),
                        #'delete a porcelain mode command'),
                    #(('edit', 'edi', 'ed', 'e'),
                        #None,
                        #('python', lambda cfg, cache, tpl: print('commands:edit')),
                        #'edit a porcelain mode command'),
                    #(('list', 'lis', 'li', 'ls', 'l'),
                        #None,
                        #('python', lambda cfg, cache, tpl: print('commands:list')),
                        #'list porcelain mode commands'),
                    #(('show', 'sho', 'sh', 's'),
                        #None,
                        #('python', lambda cfg, cache, tpl: print('commands:show')),
                        #'show a porcelain mode command'),
                    (('symlink', 'symlin', 'symli', 'syml', 'sym', 'sy',
                        'sl', 'ln'),
                        None,
                        ('python', cmd_commands_symlink),
                        'create porcelain mode symlinks for commands defined'),
                ),
                None,
                'operations with porcelain mode commands'
            ),
            (('configuration', 'configuratio', 'configurati',
                    'configurat', 'configura', 'configur', 'configu',
                    'config', 'confi', 'conf', 'con', 'cfg', 'cf'),
                (
                    (('edit', 'edi', 'ed', 'e'),
                        None,
                        ('python', cmd_configuration_edit),
                        'edit configuration file'),
                    #(('list', 'lis', 'li', 'ls', 'l'),
                        #None,
                        #('python', lambda cfg, cache, tpl: print('configuration:list')),
                        #'list options and their values'),
                    #(('set', 'se', 's'),
                        #None,
                        #('python', lambda cfg, cache, tpl: print('configuration:set')),
                        #'set options\' values'),
                    #(('show', 'sho', 'sh'),
                        #None,
                        #('python', lambda cfg, cache, tpl: print('configuration:show')),
                        #'show options'),
                    #(('unset', 'unse', 'uns', 'un', 'u'),
                        #None,
                        #('python', lambda cfg, cache, tpl: print('configuration:unset')),
                        #'unset options'),
                ),
                None,
                'configuration related commands'
            ),
            (('issues', 'issue', 'issu', 'iss', 'is', 'i'),
                (
                    #(('clone', 'clon', 'clo', 'cl'),
                        #None,
                        #('python', lambda cfg, cache, tpl: print('issues:clone')),
                        #'clone existing issues and edit clones'),
                    (('create', 'creat', 'crea', 'cre', 'cr', 'c'),
                        None,
                        ('python', cmd_issues_create),
                        'create new issues'),
                    #(('delete', 'delet', 'dele', 'del', 'de', 'd'),
                        #None,
                        #('python', lambda cfg, cache, tpl: print('issues:delete')),
                        #'delete existing issues'),
                    (('edit', 'edi', 'ed', 'e'),
                        None,
                        ('python', cmd_issues_edit),
                        'edit existing issues'),
                    (('fetch', 'fetc', 'fet', 'fe', 'f'),
                        None,
                        ('python', cmd_issues_fetch),
                        'cache issues locally'),
                    (('fields', 'field', 'fiel', 'fie', 'fi'),
                        None,
                        ('python', cmd_issues_fields),
                        'show issues\' fields'),
                    #(('forget', 'forge', 'forg', 'for', 'fo'),
                        #None,
                        #('python', cmd_issues_forget),
                        #'remove issues from local cache'),
                    (('list', 'lis', 'ls', 'l'),
                        None,
                        ('python', cmd_issues_list),
                        'list issues'),
                    #(('link', 'lin', 'ln'),
                        #None,
                        #('python', lambda cfg, cache, tpl: print('issues:link')),
                        #'link issues between each other'),
                    #(('move', 'mov', 'mo', 'mv', 'm'),
                        #None,
                        #('python', lambda cfg, cache, tpl: print('issues:move')),
                        #'move issues between projects'),
                    (('open', 'ope', 'op', 'o'),
                        None,
                        ('python', cmd_issues_open),
                        'open issues in a web browser'),
                    (('pull', 'pul', 'p'),
                        None,
                        ('python', cmd_issues_pull),
                        'refresh issues in local cache'),
                    #(('push', 'pus', 'pu'),
                        #None,
                        #('python', lambda cfg, cache, tpl: print('issues:push')),
                        #'push local changes to the server'),
                    #(('revert', 'rever', 'reve', 'rev', 're', 'r'),
                        #None,
                        #('python', lambda cfg, cache, tpl: print('issues:revert')),
                        #'revert changes'),
                    (('show', 'sho', 'sh', 's'),
                        None,
                        ('python', cmd_issues_show),
                        'show issues in details'),
                    #(('status', 'statu', 'stat', 'sta', 'st'),
                        #None,
                        #('python', lambda cfg, cache, tpl: print('issues:status')),
                        #'show status of local cache'),
                    #(('transition', 'transitio', 'transiti', 'transit',
                        #'transi', 'trans', 'tran', 'tra', 'tr'),
                        #None,
                        #('python', lambda cfg, cache, tpl: print('issues:transition')),
                        #'transition issues between states'),
                    #(('tree', 'tre', 't'),
                        #None,
                        #('python', lambda cfg, cache, tpl: print('issues:tree')),
                        #'show issue trees'),
                    #(('unlink', 'unlin', 'unli', 'unl', 'un', 'u'),
                        #None,
                        #('python', lambda cfg, cache, tpl: print('issues:unlink')),
                        #'remove linke between issues'),
                ),
                None,
                'issue related commands'
            ),
            #(('link', 'lin', 'lnk'),
                #(
                    #(('create', 'creat', 'crea', 'cre', 'cr', 'c'),
                        #None,
                        #('python', lambda cfg, cache, tpl: print('link:create')),
                        #'create links between issues'),
                    #(('delete', 'delet', 'dele', 'del', 'de', 'd'),
                        #None,
                        #('python', lambda cfg, cache, tpl: print('link:delete')),
                        #'delete links between issues'),
                    #(('list', 'lis', 'li', 'ls', 'l'),
                        #None,
                        #('python', lambda cfg, cache, tpl: print('link:list')),
                        #'list links'),
                #),
                #None,
                #'isue link related commands'
            #),
            #(('list', 'lst', 'li'),
                #(
                    #(('add', 'ad', 'a'),
                        #None,
                        #('python', lambda cfg, cache, tpl: print('list:add')),
                        #'add issues into a list of issues'),
                    #(('create', 'creat', 'crea', 'cre', 'cr', 'c'),
                        #None,
                        #('python', lambda cfg, cache, tpl: print('list:create')),
                        #'create a local list of issues'),
                    #(('delete', 'delet', 'dele', 'del', 'de', 'd'),
                        #None,
                        #('python', lambda cfg, cache, tpl: print('list:delete')),
                        #'delete an existing list of issues'),
                    #(('edit', 'edi', 'ed', 'e'),
                        #None,
                        #('python', lambda cfg, cache, tpl: print('list:edit')),
                        #'edit an existing list of issues'),
                    #(('list', 'lis', 'li', 'ls', 'l'),
                        #None,
                        #('python', lambda cfg, cache, tpl: print('list:list')),
                        #'list issue lists'),
                    #(('receive', 'receiv', 'recei', 'rece', 'rec', 'rcv'),
                        #None,
                        #('python', lambda cfg, cache, tpl: print('list:receive')),
                        #'receive a list of issues sent by `send` command'),
                    #(('remove', 'remov', 'remo', 'rem', 're', 'r'),
                        #None,
                        #('python', lambda cfg, cache, tpl: print('list:remove')),
                        #'remove issues from an existing list of issues'),
                    #(('send', 'sen', 'snd', 'se'),
                        #None,
                        #('python', lambda cfg, cache, tpl: print('list:send')),
                        #'send a list of issues'),
                    #(('show', 'sho', 'sh', 's'),
                        #None,
                        #('python', lambda cfg, cache, tpl: print('list:show')),
                        #'show an existing issue list'),
                #),
                #None,
                #'issue list related commands'
            #),
            #(('report', 'repor', 'repo', 'rep'),
                #(
                    #(('create', 'creat', 'crea', 'cre', 'cr', 'c'),
                        #None,
                        #('python', lambda cfg, cache, tpl: print('report:create')),
                        #'create a report definition'),
                    #(('delete', 'delet', 'dele', 'del', 'de', 'd'),
                        #None,
                        #('python', lambda cfg, cache, tpl: print('report:delete')),
                        #'delete a report definition'),
                    #(('edit', 'edi', 'ed', 'e'),
                        #None,
                        #('python', lambda cfg, cache, tpl: print('report:edit')),
                        #'edit a report definition'),
                    #(('generate', 'generat', 'genera', 'gener', 'gene',
                            #'gen', 'ge', 'g'),
                        #None,
                        #('python', lambda cfg, cache, tpl: print('report:generate')),
                        #'generate reports'),
                    #(('list', 'lis', 'li', 'ls', 'l'),
                        #None,
                        #('python', lambda cfg, cache, tpl: print('report:list')),
                        #'list report definitiona'),
                #),
                #None,
                #'report related commands'
            #),
            (('servers', 'server', 'serve', 'serv', 'ser', 'srv', 'se'),
                (
                    (('add', 'ad', 'a'),
                        None,
                        ('python', cmd_servers_add),
                        'register new JIRA server'),
                    (('dance', 'danc', 'dan', 'da'),
                        None,
                        ('python', cmd_servers_dance),
                        'perform OAuth authentication with a JIRA server'),
                    (('delete', 'delet', 'dele', 'del', 'de', 'd'),
                        None,
                        ('python', cmd_servers_delete),
                        'delete a JIRA server'),
                    (('edit', 'edi', 'ed', 'e'),
                        None,
                        ('python', cmd_servers_add),
                        'edit a JIRA server information'),
                    (('list', 'lis', 'li', 'ls', 'l'),
                        None,
                        ('python', cmd_servers_list),
                        'list known JIRA servers'),
                    (('select', 'selec', 'sele', 'sel', 'se'),
                        None,
                        ('python', cmd_servers_select),
                        'select a server as a default one'),
                    (('show', 'sho', 'sh', 's'),
                        None,
                        ('python', cmd_servers_show),
                        'show a JIRA server\'s information'),
                ),
                None,
                'server connection related commands'
            ),
            #(('template', 'templat', 'templa', 'templ', 'temp', 'tem',
                    #'tpl', 'te'),
                #(
                    #(('create', 'creat', 'crea', 'cre', 'cr', 'c'),
                        #None,
                        #('python', lambda cfg, cache, tpl: print('template:create')),
                        #'create a new template'),
                    #(('delete', 'delet', 'dele', 'del', 'de', 'd'),
                        #None,
                        #('python', lambda cfg, cache, tpl: print('template:delete')),
                        #'delete an existing template'),
                    #(('edit', 'edi', 'ed', 'e'),
                        #None,
                        #('python', lambda cfg, cache, tpl: print('template:edit')),
                        #'edit an existing template'),
                    #(('list', 'lis', 'li', 'ls', 'l'),
                        #None,
                        #('python', lambda cfg, cache, tpl: print('template:list')),
                        #'list defined templates'),
                    #(('show', 'sho', 'sh', 's'),
                        #None,
                        #('python', lambda cfg, cache, tpl: print('template:show')),
                        #'show template details'),
                #),
                #None,
                #'information representation template related commands'
            #),
            #(('worklog', 'worklo', 'workl', 'work', 'wor', 'wo', 'wl',
                    #'w'),
                #(
                    #(('add', 'ad', 'a'),
                        #None,
                        #('python', lambda cfg, cache, tpl: print('worklog:add')),
                        #'add records into issue\'s worklog'),
                    #(('delete', 'delet', 'dele', 'del', 'de', 'd'),
                        #None,
                        #('python', lambda cfg, cache, tpl: print('worklog:delete')),
                        #'delete work log records'),
                    #(('edit', 'edi', 'ed', 'e'),
                        #None,
                        #('python', lambda cfg, cache, tpl: print('worklog:edit')),
                        #'edit existing work log records'),
                    #(('list', 'lis', 'li', 'ls', 'l'),
                        #None,
                        #('python', lambda cfg, cache, tpl: print('worklog:list')),
                        #'list existing worklog records'),
                    #(('show', 'sho', 'sh', 's'),
                        #None,
                        #('python', lambda cfg, cache, tpl: print('worklog:show')),
                        #'show worklog issues'),
                #),
                #None,
                #'worklog related commands'
            #),
        )


    def _build_porcelain_commands(self):
        command_defs = self.cfg.o.get('commands')
        if command_defs:
            self.porcelain_commands = \
                self._build_commands_from_config(command_defs)
        else:
            self.porcelain_commands = ()


    def _build_commands_from_config(self, cfg_commands):
        result = []
        index = {}
        if not cfg_commands:
            return None
        for name, command in cfg_commands.iteritems():
            result.append(self._build_one_command_from_config(name, command))
        return result


    def _build_one_command_from_config(self, name, cfg_cmd):
        res_aliases = [name,]
        cfg_aliases = cfg_cmd.get('aliases')
        if cfg_aliases:
            for alias in cfg_aliases.split(','):
                res_aliases.append(alias.strip())
        res_help = ''
        cfg_help = cfg_cmd.get('help')
        if cfg_help:
            res_help = cfg_help.strip()
        res_function = None
        cfg_plumbing = cfg_cmd.get('plumbing')
        if cfg_plumbing:
            res_function = ('plumbing', cfg_plumbing.strip())
        res_sc = None
        cfg_sc = cfg_cmd.get('sc')
        if cfg_sc:
            res_sc = self._build_commands_from_config(cfg_sc)
        return (res_aliases, res_sc, res_function, res_help)


    def _build_root_parser(self, commands=None):
        parser = argparse.ArgumentParser(
            prog='jic',
            description='jic - JIRA CLI tool (v%s)\n\n'\
                'Allows dealing with JIRA from within '\
                'your terminal.' % __version__,
            fromfile_prefix_chars='@',
            formatter_class=argparse.RawTextHelpFormatter,
            add_help=False
        )

        parser.add_argument('-h', '--help', action='store_true',
            dest='help',
            help='show usage information')
        parser.add_argument('--porcelain', action='store_const',
            const='porcelain', dest='mode',
            help='set porcelain mode of operation')
        parser.add_argument('--plumbing', action='store_const',
            const='plumbing', dest='mode',
            help='set plumbing mode of operation')

        return parser


    def _build_modal_parser(self, commands=None):
        command_help = self._format_command_help(
                            commands,
                            'supported commands are:\n\n') \
                         if commands is not None \
                         else None

        parser = argparse.ArgumentParser(
            prog='jic',
            description='jic - JIRA CLI tool (v%s)\n\n'\
                'Allows dealing with JIRA from within '\
                'your terminal.' % __version__,
            epilog=command_help,
            fromfile_prefix_chars='@',
            formatter_class=argparse.RawTextHelpFormatter,
            add_help=False
        )

        parser.add_argument('-a', '--all', action='store_true',
            dest='process_all', default=None,
            help='process all items/parts')
        parser.add_argument('-b', '--order-by', nargs=1, action='append',
            dest='order_by', metavar='CRITERIA_LIST',
            help='order results according to the criteria')
        parser.add_argument('-d', '--down', action='store_true',
            dest='down', default=None,
            help='process children')
        parser.add_argument('-D', '--down-from', nargs=1, action='append',
            dest='down_from', metavar="ISSUE_LIST",
            help='process children of the parent(s) specified')
        parser.add_argument('-e', '--editor', action='store_true',
            dest='use_editor', default=None,
            help='use editor to provide information to jic')
        parser.add_argument('-f', '--filter', nargs=1, action='append',
            dest='filter', metavar='CRITERIA_LIST',
            help='only process items matching the criteria')
        parser.add_argument('-F', '--fields', nargs=1, action='append',
            dest='fields', metavar='FIELD_LIST',
            help='only process the fields listed')
        parser.add_argument('-h', '--help', action='store_true',
            dest='help', default=None,
            help='show usage information')
        parser.add_argument('-H', '--depth', nargs=1, type=int,
            dest='depth', default=None, metavar='NUMBER',
            help='only process so many levels starting from the referred object')
        #parser.add_argument('-i', '--interactive', action='store_true',
            #dest='interactive', default=None,
            #help='perform actions interactively, asking for confirmation')
        #parser.add_argument('-j', '--json', action='store_true',
            #dest='use_json', default=None,
            #help='use JSON representation of the data')
        parser.add_argument('-k', '--keys', action='store_true',
            dest='get_keys', default=None,
            help='get keys of the objects to be processed')
        parser.add_argument('-L', '--link-types', nargs=1, action='append',
            dest='link_types', metavar='LINK_TYPE_LIST',
            help='process/use only the link types specified')
        #parser.add_argument('-m', '--message', nargs=1, action='append',
            #dest='message', metavar='TEXT',
            #help='use this message, don\'t expect it from stdin/editor')
        parser.add_argument('-n', '--number-of-items', nargs=1,
            dest='number_of_items', metavar='NUMBER_OF_ITEMS', default=None,
            help='process only so many items')
        parser.add_argument('-o', '--flip_online', action='count',
            dest='flip_online', default=None,
            help='flip between cached and online modes')
        parser.add_argument('--online', action='store_true',
            dest='online', default=None,
            help='perform actions on the server')
        parser.add_argument('--cached', action='store_true',
            dest='cached', default=None,
            help='perform actions on the server using cache')
        parser.add_argument('-O', '--offline', action='store_true',
            dest='offline', default=None,
            help='perform actions in the local cache only')
        parser.add_argument('-p', '--parts', nargs=1, action='append',
            dest='parts', metavar='PART_LIST',
            help='process only object parts mentioned')
        #parser.add_argument('-P', '--purge', nargs=1, action='append',
            #dest='items_to_purge', metavar='ITEM_LIST',
            #help='process only items mentioned')
        parser.add_argument('-q', '--query', nargs=1, action='append',
            dest='query', metavar='JQL_query',
            help='get the list of issues to process using a JQL query')
        parser.add_argument('-Q', '--query-stdin', action='store_true',
            dest='query_in_stdin', default=None,
            help='get the list of issues to process using a JQL query')
        parser.add_argument('-r', '--raw', action='store_true',
            dest='output_raw', default=None,
            help='output raw data')
        #parser.add_argument('-R', '--range', nargs=1, action='append',
            #dest='range', metavar='RANGE',
            #help='process only items matching the range')
        parser.add_argument('-s', '--self', action='store_true',
            dest='include_self', default=None,
            help='include the issue specified (besides children/ancestors)')
        parser.add_argument('-S', '--server', nargs=1,
            dest='server_name', default=None, metavar='SERVER_NAME',
            help='work with JIRA server specified')
        parser.add_argument('-t', '--template', nargs=1,
            dest='template', default=None, metavar='NAME',
            help='use the template specified')
        parser.add_argument('-T', '--issue-types', nargs=1, action='append',
            dest='issue_types', metavar='ISSUE_TYPE_LIST',
            help='process/use only the issue types specified')
        parser.add_argument('-u', '--up', action='store_true',
            dest='up', default=None,
            help='process ancestors')
        parser.add_argument('-U', '--up-from', nargs=1, action='append',
            dest='up_from', metavar="ISSUE_LIST",
            help='process ancestors of the issue(s) specified')
        parser.add_argument('-v', '--verbose', action='count',
            dest='verbosity', default=None,
            help='be verbose while performing actions')
        parser.add_argument('-V', '--version', action='version',
            version='%(prog)s v' + __version__,
            help='show jic\'s version information')
        parser.add_argument('-w', '--output_width', nargs=1,
            dest='output_width', metavar='OUTPUT_WIDTH', default=None,
            help='wrap output as specified')

        return parser

    def _format_command_help(self, commands, title=None,
                             show_group_titles=False):
        res = title \
            if title is not None \
            else ''
        res += self._format_command_tree(commands,
                                         show_title=show_group_titles)
        return res

    def _format_command_tree(self, command_list, prefix='',
                             show_title=False):
        res = ''
        for aliases, commands, function, description in command_list:
            if type(commands) in (list,tuple):
                res += '%s%s%s\n' % (
                        prefix,
                        aliases[0],
                        description if show_title else '')
                res += self._format_command_tree(commands,
                                                 prefix + ' '*4,
                                                 show_title)
            else:
                prefixed_name = prefix + aliases[0]
                res += '%-19s  %-55s\n' % (
                            prefixed_name,
                            description)
        return res
        first_cmd = True
        for subject in cli_sac:
            aliases, commands = subject
            res += '\n  ' + aliases[0] + ' (' + \
                    ', '.join(aliases[1:]) + ')\n'
            for names, _, description in commands:
                res += '    %-19s  %-55s\n' % (names[0], description)
        res += '\nWhen subject is omitted, `issue` is assumed.\n\n' + \
            'For more details please see `man jic`.\n'


CommandLine.cl_to_options_map = {
    'args':             ('query.args', CommandLine.UNWRAP_NONE),
    'depth':            ('query.depth', CommandLine.UNWRAP_SINGLE),
    'down':             ('query.down', CommandLine.UNWRAP_NONE),
    'down_from':        ('query.down_from', CommandLine.UNWRAP_LIST),
    'fields':           ('display.fields', CommandLine.UNWRAP_LIST_OF_LISTS),
    'filter':           ('query.filter', CommandLine.UNWRAP_LIST),
    'get_keys':         ('query.get_keys', CommandLine.UNWRAP_NONE),
    'help':             ('help', CommandLine.UNWRAP_NONE),
    'include_self':     ('query.include_self', CommandLine.UNWRAP_NONE),
    'interactive':      ('cl.interactive', CommandLine.UNWRAP_NONE),
    'issue_types':      ('query.issue_types', CommandLine.UNWRAP_LIST_OF_LISTS),
    'items_to_purge':   ('query.items_to_purge', CommandLine.UNWRAP_LIST_OF_LISTS),
    'link_types':       ('query.link_types', CommandLine.UNWRAP_LIST_OF_LISTS),
    'message':          ('query.message', CommandLine.UNWRAP_LIST),
    'mode':             ('cl.mode', CommandLine.UNWRAP_NONE),
    'number_of_items':  ('query.number_of_items', CommandLine.UNWRAP_SINGLE),
    'flip_online':      ('query.flip_online', CommandLine.UNWRAP_NONE),
    'online':           ('query.online', CommandLine.UNWRAP_NONE),
    'offline':          ('query.offline', CommandLine.UNWRAP_NONE),
    'order_by':         ('display.order_by', CommandLine.UNWRAP_LIST_OF_LISTS),
    'output_raw':       ('display.raw', CommandLine.UNWRAP_NONE),
    'parts':            ('query.parts', CommandLine.UNWRAP_LIST_OF_LISTS),
    'process_all':      ('query.process_all', CommandLine.UNWRAP_NONE),
    'query':            ('query.jql', CommandLine.UNWRAP_SINGLE),
    'query_in_stdin':   ('query.from_stdin', CommandLine.UNWRAP_NONE),
    'range':            ('query.range', CommandLine.UNWRAP_LIST_OF_LISTS),
    'server_name':      ('server', CommandLine.UNWRAP_SINGLE),
    'template':         ('display.template', CommandLine.UNWRAP_SINGLE),
    'up':               ('query.up', CommandLine.UNWRAP_NONE),
    'up_from':          ('query.up_from', CommandLine.UNWRAP_LIST_OF_LISTS),
    'use_editor':       ('cl.use_editor', CommandLine.UNWRAP_NONE),
    'verbosity':        ('display.verbosity', CommandLine.UNWRAP_NONE),
    'output_width':     ('display.output_width', CommandLine.UNWRAP_SINGLE),
}

# class CommandLine


class Cache (object):

    HOME = 'cache'
    ISSUE_CACHE = 'issues'
    ISSUE_EDITMETA_CACHE = 'editmeta'
    ISSUE_CREATEMETA_CACHE = 'createmeta'
    WORKLOG_CACHE = 'worklogs'
    FIELD_CACHE = 'fields'

    TS_FORMAT = '%Y-%m-%d %H:%M:%S'

    # modes of operation
    DEFAULT_MODE = 'cached'

    # always get from the server, keep the cache up to date
    MODE_ONLINE = 'online'

    # get from the cache of not stale (ttl wise), get from the server
    # before updating, send updates to the server (write through)
    MODE_CACHED = 'cached'

    # only use local cache (also for recording updates)
    MODE_OFFLINE = 'offline'

    # default time to live for cached items
    DEFAULT_TTL = 3600

    # use online searches in cached mode (istead of cache based one)
    DEFAULT_SEARCH_ONLINE = True

    # data source options
    SOURCE_CACHE_ONLY = 0
    SOURCE_CACHED_SERVER = 1
    SOURCE_SERVER = 2

    # level 1 cache (level 2 being the FS storage)
    issue_L1 = {}
    editmeta_L1 = {}
    createmeta_L1 = {}
    worklog_L1 = {}


    def __init__(self, cfg, server_name=None):
        self.cfg = cfg
        self.srv_name = server_name

        self.srv_name = cfg.o.get('server', self.srv_name)

        if not self.srv_name:
            # TODO: report error
            raise RuntimeError(
                u'No server specified - please either '\
                u'do `jic server select` or use -S switch')

        self.srv_cfg = cfg.o.get('servers.' + self.srv_name)

        if self.srv_cfg is None:
            # TODO: report error
            raise RuntimeError(
                'Server \'%s\' is not known' % self.srv_name)

        self.jira = None
        self.field_by_id = {}
        self.field_by_name = {}

        self.home = os.path.expanduser(os.path.expandvars(
                    cfg.o.home.location + os.sep + Cache.HOME))

        home_exists, home_accessible = Util.ensure_dir_access(
                self.home, os.R_OK | os.W_OK | os.X_OK, 0700)

        if home_exists != True:
            raise home_exists

        if not home_accessible:
            raise RuntimeError(
               'Cache directory \'%s\' should have \'rwx\' mode' % self.home)

        self.srv_home = self.home + os.sep + self.srv_name

        srv_home_exists, srv_home_accessible = Util.ensure_dir_access(
                self.srv_home, os.R_OK | os.W_OK | os.X_OK, 0700)

        if srv_home_exists != True:
            raise home_exists

        if not srv_home_accessible:
            raise RuntimeError(
               'Cache directory \'%s\' should have \'rwx\' mode' %\
               self.srv_home)

        self.issue_home = self.srv_home + os.sep + Cache.ISSUE_CACHE

        issue_home_exists, issue_home_accessible = Util.ensure_dir_access(
                self.issue_home, os.R_OK | os.W_OK | os.X_OK, 0700)

        if issue_home_exists != True:
            raise issue_home_exists

        if not issue_home_accessible:
            raise RuntimeError(
               'Cache directory \'%s\' should have \'rwx\' mode' %\
               self.issue_home)

        self.editmeta_home = self.srv_home + os.sep \
                           + Cache.ISSUE_EDITMETA_CACHE

        editmeta_home_exists, editmeta_home_accessible = \
            Util.ensure_dir_access(
                self.editmeta_home, os.R_OK | os.W_OK | os.X_OK, 0700)

        if editmeta_home_exists != True:
            raise editmeta_home_exists

        if not editmeta_home_accessible:
            raise RuntimeError(
               'Cache directory \'%s\' should have \'rwx\' mode' %\
               self.editmeta_home)

        self.worklog_home = self.srv_home + os.sep + Cache.WORKLOG_CACHE

        worklog_home_exists, worklog_home_accessible = Util.ensure_dir_access(
                self.worklog_home, os.R_OK | os.W_OK | os.X_OK, 0700)

        if worklog_home_exists != True:
            raise worklog_home_exists

        if not worklog_home_accessible:
            raise RuntimeError(
               'Cache directory \'%s\' should have \'rwx\' mode' %\
               self.worklog_home)

        self.mode = cfg.o.get('cache.mode', Cache.DEFAULT_MODE)
        self.mode = self.srv_cfg.get('cache.mode', self.mode)

        # update caching mode
        if cfg.o.get('query.offline', False):
            self.mode = 'offline'
        else:
            if cfg.o.get('query.online', False):
                self.mode = 'online'
            flipovers = cfg.o.get('query.flip_online', 0)
            if flipovers > 1:
                self.mode = 'online'
            elif flipovers == 1:
                self.mode = 'cached'

        if self.mode == 'offline':
            self.source = Cache.SOURCE_CACHE_ONLY
        elif self.mode == 'cached':
            self.source = Cache.SOURCE_CACHED_SERVER
        elif self.mode == 'online':
            self.source = Cache.SOURCE_SERVER
        else:
            raise RuntimeError(
                u'Unknown caching mode: \'%s\'' % self.mode)

        self.ttl = cfg.o.get('cache.ttl', Cache.DEFAULT_TTL)
        self.ttl = self.srv_cfg.get('cache.ttl', self.ttl)

        self.user = cfg.o.get('user', None)
        self.user = self.srv_cfg.get('user', self.user)
        if not self.user:
            raise RuntimeError(
                u'Internal error: unknown user')

        self.variables = {
            'me':   self.user,
        }

        self.search_online = cfg.o.get('query.search_online',
                Cache.DEFAULT_SEARCH_ONLINE)
        self.search_online = self.srv_cfg.get('query.search_online',
                self.search_online)

        if not self._load_fields() \
        or (Util.is_stale(self.ttl, self.fields_ts) \
                and self.mode != Cache.MODE_OFFLINE):
            self._cache_fields()

        if not self._load_createmeta() \
        or (Util.is_stale(self.ttl, self.create_meta_ts) \
                and self.mode != Cache.MODE_OFFLINE):
            self._cache_createmeta()

        # resolve field names for query.filter
        def resolve_field_name(self, expression):
            if not expression:
                return expression
            if type(expression) not in (list,tuple):
                return expression
            lhs, op, rhs = expression
            if isinstance(lhs, basestring):
                new = self.get_field_id(lhs)
                if new:
                    lhs = new
            else:
                lhs = resolve_field_name(self, lhs)

            if type(rhs) != list:
                rhs = resolve_field_name(self, rhs)

            return (lhs, op, rhs)

        filter = resolve_field_name(self, cfg.o.get('query.filter'))
        cfg.o.set('query.filter', filter)

        vpre(VERBOSITY_INFO, u'Cache: server=%s, mode=%s' %\
                                    (self.srv_name, self.mode))


    def get_jira(self):
        if self.mode == Cache.MODE_OFFLINE:
            class Stub(object):
                def __init__(self):
                    self._session = None
                    self._options = None

            return Stub()

        if self.jira is None:
            oauth_token = self.srv_cfg.get('oauth.token')
            oauth_secret = self.srv_cfg.get('oauth.secret')
            oauth_cert = self.srv_cfg.get('oauth.cert')
            user = self.srv_cfg.get('user')
            server = self.srv_cfg.get('url')
            password = self.srv_cfg.get('password')

            if not server:
                raise RuntimeError(
                    'URL is missing for server \'%s\'' % self.srv_name)

            if oauth_token and oauth_secret:
                if not oauth_cert:
                    vpre(VERBOSITY_WARNINGS, 
                         u'OAuth certificate is missing for the server '\
                        '\'%s\' - not using OAuth' %\
                                self.srv_name)
                else:
                    try:
                        oauth2_location = imp.find_module('oauth2')
                        oauth2 = imp.load_module('oauth2', *oauth2_location)
                        sys.modules['oauth'] = oauth2
                        options = { 'server': server, 'verify': False }

                        oauth_auth = {
                            'access_token': oauth_token,
                            'access_token_secret': oauth_secret,
                            'consumer_key': 'jic-tool',
                            'key_cert': oauth_cert
                        }
                        self.jira = JIRA(options=options, oauth=oauth_auth)
                        vpre(VERBOSITY_INFO,
                             u'Using OAuth to connect to JIRA')
                        return self.jira
                    except ImportError, e:
                        vpre(VERBOSITY_WARNINGS,
                             u'Unable to import oauth2 module - not '\
                             u'using OAuth')
                    finally:
                        if oauth2_location[0]:
                            oauth2_location.close()

            if user and not password:
                password = self.get_password_from_keyring_or_console(
                    self.srv_name, user)

            options = { 'server': server, 'verify': False }
            if user:
                auth = (user, password)
                self.jira = JIRA(options=options, basic_auth=auth)
            else:
                self.jira = JIRA(options=options)

        return self.jira


    def get(self, issues=None, go_down=False, go_up=False,
            down_from=None, up_from=None, inclusive=False,
            link_types=None, depth=None, order_by=None, limit=None,
            filter=None, query=None, source=None, worklogs=False):
        """Get issues from cache/server according to the parameters`

        Parameters:
            issues      - iterable source of issue keys to return
            go_down     - also return issues down from each of `issues`
                          entries using the `link_types` for traversal
                          and going for `depth` steps in the hierarchy
            go_up       - also return issues up from each of `issues`
                          entries using the `link_types` for traversal
                          and going for `depth` steps in the hierarchy
            down_from   - iterable source of issue keys to traverse the
                          tree of links from; direction is towards
                          children; the traveral-starting issue is also
                          included if `include_self` is True; depth of
                          traveral is limited by `depth` parameter
            up_from     - same as for `down_from`, but the direction is
                          towards parents
            inclusive   - also include the traversal-starting issue in
                          results - it's not included by default
            link_types  - list of link type names to match; only links
                          with matched type names will be traversed
            depth       - integer specifying the depth of traversal; 1
                          being the traversal-starting issue only, 0
                          returning no issues
            order_by    - iterable with field names to order by,
                          prefixed by '-' (for descending) or '+' (for
                          ascending; default) to specify the direction;
                          if missing - `issues` are returned first,
                          followed by `down-from` ones and then
                          `up_from` ones
            filter      - parsed filter criteria
            limit       - limit the number of issues returned
            query       - JQL query
            worklogs    - also get worklogs (exposed as 'worklogs'
                          property for each issue returned)

        Returns:
            an iterable with Issue objects ordered according to the
            request
        """

        if limit:
            try:
                limit = int(limit)
            except TypeError:
                limit = -1
        else:
            limit = -1

        link_types = [lt.strip() for lt in link_types if lt] \
                   if link_types else None

        if source is None:
            source = self.source

        # 1. process `issues`, `filter` and `order_by`
        if isinstance(issues, basestring):
            issues = (issues,)

        ts_now = datetime.datetime.utcnow()

        listed_issues = []
        if issues:
            listed_issues = self._get_by_keys(
                                    issues, go_down, go_up,
                                    link_types, depth, order_by,
                                    filter, limit)
        elif filter:
            listed_issues = self._get_by_filter(filter, order_by, limit)

        downward_issues = []
        if down_from:
            if isinstance(down_from, basestring):
                down_from = (down_from,)
            for issue in down_from:
                if inclusive:
                    if isinstance(issue, basestring):
                        issues = self.get(issue)
                        if not len(issues):
                            continue
                        issue = issues[0]
                    downward_issues.append(issue)
                linked = self._get_linked_issues(
                                issue, True, False, link_types,
                                depth, order_by, limit, filter)
                if len(linked):
                    downward_issues.extend(linked)

        upward_issues = []
        if up_from:
            if isinstance(up_from, basestring):
                up_from = (up_from,)
            for issue in up_from:
                if inclusive:
                    if isinstance(issue, basestring):
                        issues = self.get(issue)
                        if not len(issues):
                            continue
                        issue = issues[0]
                    upward_issues.append(issue)
                linked = self._get_linked_issues(
                                issue, False, True, link_types,
                                depth, order_by, limit, filter)
                if len(linked):
                    upward_issues.extend(linked)

        queried_issues = self._get_by_query(query, limit) \
                       if query else []

        result = listed_issues + downward_issues + upward_issues + \
                    queried_issues

        if order_by:
            vpre(VERBOSITY_INFO, u'Sorting result set...', end=u'')
            result = Util.sort_issues(result, order_by)
            vpre(VERBOSITY_INFO, u' - done!')

        # TODO: get worklogs from the cache
        if worklogs:
            updated = []
            max_idx = len(result)
            for idx, issue in enumerate(result, 1):
                ts, wl = self._load_worklogs(issue.key)
                if Util.is_stale(self.ttl, ts) \
                and self.mode in (Cache.MODE_ONLINE,):
                    vpre(VERBOSITY_INFO,
                        u'\rFetching worklogs: %s (%d/%d)%s' %\
                            (issue.key, idx, max_idx, u' '*10),
                        end=u'')
                    wl = self.get_jira().worklogs(issue.key)
                    self._cache_worklogs(issue, wl)
                issue.worklogs = wl
                updated.append(issue)
            vpre(VERBOSITY_INFO, u' - done!')
            result = updated

        return result


    def get_comment(self, issue, comment_id):
        if isinstance(issue, basestring):
            issue = self._get_by_keys((issue,))
            if not issue:
                return None
            issue = issue[0]
        for comment in issue.fields.comment.comments:
            if comment.id == comment_id:
                return comment
        return None


    def create(self, fields):
        if self.mode == Cache.MODE_OFFLINE:
            raise RuntimeError(
                u'Creating issues is only supported in online mode')
        new_issue = self.get_jira().create_issue(fields)
        self._cache_issue(new_issue)
        return new_issue


    def update(self, changes):
        """Update issues in cache or on the server.

        Parameters:
            changes     - iterable of tuples:
                            #0: issue key
                            #1: dictionary with changes
        Returns:
            nothing
        """

        if self.mode in (Cache.MODE_CACHED, Cache.MODE_OFFLINE):
            raise RuntimeError(
                u'Only online mode is supported in this version of jic')

        pass


    def rollback(self, changes):
        """Roll changes back in cache or on the server"""
        # TODO: implement
        raise RuntimeError(
            u'Rolling back is not implemented in this version of jic')


    def pull(self):
        """Refresh only the already cached issues from the server"""

        if self.mode in (Cache.MODE_OFFLINE,):
            raise RuntimeError(
                u'Can\'t pull in offline mode')

        fetched_issues = set()

        done = 1

        wls = self._cached_worklogs()
        total = len(wls)

        issues = self._cached_issues()
        total += len(issues)

        for key in wls:
            vpre(VERBOSITY_INFO,
                u'\rPulling: %s (%d/%d)%s' %\
                    (key, done, total, u' '*10),
                end='')
            self.fetch(key, worklogs=True)
            fetched_issues.add(key)
            done += 1

        for key in issues:
            vpre(VERBOSITY_INFO,
                u'\rPulling: %s (%d/%d)%s' %\
                    (key, done, total, u' '*10),
                end='')
            if key not in fetched_issues:
                self.fetch(key)
            done += 1

        vpre(VERBOSITY_INFO, u' - done!')


    def fetch(self, issues=None, go_down=False, go_up=False,
            down_from=None, up_from=None, inclusive=False,
            link_types=None, depth=None, order_by=None, limit=None,
            filter=None, query=None, worklogs=False):
        """Fetch issues from the server and update cache"""

        if self.mode == Cache.MODE_OFFLINE:
            raise RuntimeError(
                u'Fetching is not possible in offline mode')

        if limit:
            try:
                limit = int(limit)
            except TypeError:
                limit = -1
        else:
            limit = -1

        link_types = [lt.strip() for lt in link_types if lt] \
                   if link_types else None

        if isinstance(issues, basestring):
            issues = (issues,)

        ts_now = datetime.datetime.utcnow()

        listed_issues = []
        if issues:
            listed_issues = self._get_by_keys(
                                    issues, go_down, go_up,
                                    link_types, depth, order_by,
                                    filter, limit,
                                    source=Cache.SOURCE_SERVER)
        elif filter:
            listed_issues = self._get_by_filter(
                                    filter,
                                    order_by,
                                    limit,
                                    source=Cache.SOURCE_SERVER)

        downward_issues = []
        if down_from:
            if isinstance(down_from, basestring):
                down_from = (down_from,)
            for issue in down_from:
                if inclusive:
                    if isinstance(issue, basestring):
                        issues = self.get(issue)
                        if not len(issues):
                            continue
                        issue = issues[0]
                    downward_issues.append(issue)
                linked = self._get_linked_issues(
                                issue, True, False, link_types,
                                depth, order_by, limit, filter,
                                source=Cache.SOURCE_SERVER)
                if len(linked):
                    downward_issues.extend(linked)

        upward_issues = []
        if up_from:
            if isinstance(up_from, basestring):
                up_from = (up_from,)
            for issue in up_from:
                if inclusive:
                    if isinstance(issue, basestring):
                        issues = self.get(issue)
                        if not len(issues):
                            continue
                        issue = issues[0]
                    upward_issues.append(issue)
                linked = self._get_linked_issues(
                                issue, False, True, link_types,
                                depth, order_by, limit, filter,
                                source=Cache.SOURCE_SERVER)
                if len(linked):
                    upward_issues.extend(linked)

        queried_issues = self._get_by_query(query, limit) \
                       if query else []

        result = listed_issues + downward_issues + upward_issues + \
                    queried_issues

        if order_by:
            #vpre(VERBOSITY_INFO, u'Sorting result set...', end=u'')
            result = Util.sort_issues(result, order_by)
            #vpre(VERBOSITY_INFO, u' - done!')

        # fetch editmeta
        updated = []
        max_idx = len(result)
        for idx, issue in enumerate(result, 1):
            #vpre(VERBOSITY_INFO,
                #u'\rFetching editmeta: %s (%d/%d)%s' %\
                    #(issue.key, idx, max_idx, u' '*10),
                #end=u'')
            em = self.get_jira().editmeta(issue.key)
            self._cache_editmeta(issue, em)
            issue.editmeta = em
            updated.append(issue)
        result = updated
        #vpre(VERBOSITY_INFO, u' - done!')

        if worklogs:
            updated = []
            max_idx = len(result)
            for idx, issue in enumerate(result, 1):
                #vpre(VERBOSITY_INFO,
                    #u'\rFetching worklogs: %s (%d/%d)%s' %\
                        #(issue.key, idx, max_idx, u' '*10),
                    #end=u'')
                wl = self.get_jira().worklogs(issue.key)
                self._cache_worklogs(issue, wl)
                issue.worklogs = wl
                updated.append(issue)
            result = updated
            #vpre(VERBOSITY_INFO, u' - done!')

        return result


    def push(self, issues=None, down_from=None, up_from=None,
            inclusive=False, depth=None, order_by=None, limit=None):
        """Push cached changes to the server"""
        # TODO: implement
        raise RuntimeError(
            u'Pushing is not implemented in this version of jic')


    def forget(self, issues=None, down_from=None, up_from=None,
            inclusive=False, depth=None, order_by=None, limit=None):
        """Remove issues' information from the cache"""
        # TODO: implement
        raise RuntimeError(
            u'Forgetting is not implemented in this version of jic')


    def stat(self):
        """Get cache statistics"""
        # TODO: implement
        return None


    def add_comment(self, issue, comment_body):
        if self.mode == Cache.MODE_OFFLINE:
            raise RuntimeError(
                u'Adding comments in offline mode not supported yet')

        if not isinstance(issue, basestring):
            issue = issue.key

        try:
            vpre(VERBOSITY_INFO,
                u'Adding a comment for %s...' % issue,
                end=u'')
            comment = self.get_jira().add_comment(issue, comment_body)
            vpre(VERBOSITY_INFO, u' - done!')
        except JIRAError, e:
            pre('ERROR: Unable to add comment for issue \'%s\': %s' % (\
                    issue, str(e)))
        vpre(VERBOSITY_INFO,
            u'Fetching the update version of %s...' % issue,
            end=u'')
        self.fetch(issue)
        vpre(VERBOSITY_INFO, u' - done!')


    def get_field_id(self, partial_name):
        if not self.fields:
            return None

        result = self.field_by_id.get(partial_name)
        if result:
            return result['id']

        result = self.field_by_name.get(partial_name)
        if result:
            return result['id']

        matches = []
        for name in self.field_by_id.keys():
            if name.find(partial_name) != -1:
                matches.append(self.field_by_id[name]['id'])
        if len(matches) > 1:
            raise RuntimeError(
                u'Partially specified field name \'%s\' is ambigous' %\
                    partial_name)
        if matches:
            return matches[0]

        matches = []
        for name in self.field_by_name.keys():
            if name.find(partial_name) != -1:
                matches.append(self.field_by_name[name]['id'])
        if len(matches) > 1:
            raise RuntimeError(
                u'Partially specified field name \'%s\' is ambigous' %\
                    partial_name)
        if matches:
            return matches[0]

        return None


    def _load_fields(self):
        file_name = self.srv_home + os.sep + Cache.FIELD_CACHE

        self.fields = ()
        self.fields_ts = None

        try:
            vpre(VERBOSITY_INFO,
                u'Loading field information from the cache...', end=u'')
            f = open(file_name, 'r')
            timestamp = datetime.datetime.strptime(
                            f.readline().strip(), Cache.TS_FORMAT)
            raw = json.load(f)
            f.close()
            vpre(VERBOSITY_INFO, u' - done!')

            self.fields = FieldMetadata(raw)
            self.fields_ts = timestamp

        except IOError, e:
            # TODO: properly handle
            if e.errno != errno.ENOENT:
                vpre(VERBOSITY_ERRORS,
                    u'ERROR: unable to load cached field '\
                    u'information: %s' % str(e))
            return False

        except Exception, e:
            # TODO: properly handle
            if e.errno != errno.ENOENT:
                vpre(VERBOSITY_ERRORS,
                    u'ERROR: unable to load cached field '\
                    u'information: %s' % str(e))
            return False

        return True


    def _cache_fields(self):
        try:
            self.fields = [
                {   'id': 'key',
                    'name': 'Key',
                    'schema': {
                        'type': 'string',
                        'system': 'key',}
                }, ]
            if self.mode != Cache.MODE_OFFLINE:
                vpre(VERBOSITY_INFO,
                    u'Fetching field information...',
                    end=u'')
                self.fields.extend(self.get_jira().fields())
            self.fields = FieldMetadata(self.fields)
            self.fields_ts = datetime.datetime.utcnow()

            if self.mode != Cache.MODE_OFFLINE:
                file_name = self.srv_home + os.sep + Cache.FIELD_CACHE
                tmp_file_name = self.issue_home + os.sep + '.' + Cache.FIELD_CACHE

                f = open(tmp_file_name, 'w')
                f.write(self.fields_ts.strftime('%s\n' % Cache.TS_FORMAT))
                f.write(json.dumps(self.fields.field_meta, indent=2, sort_keys=True))
                f.close()
                os.rename(tmp_file_name, file_name)
                vpre(VERBOSITY_INFO, u' - done!')

        except JIRAError, e:
            vpre(VERBOSITY_ERRORS,
                u'ERROR: unable to fetch field list '\
                u'from the server \'%s\': %s' % (self.srv_name, str(e)))
            return False

        except IOError, e:
            vpre(VERBOSITY_ERRORS,
                u'ERROR: unable to store field list: %s' % str(e))
            return False

        except Exception, e:
            vpre(VERBOSITY_ERRORS,
                u'ERROR: error fetching field list: %s' % str(e))
            return False

        return True


    def _load_createmeta(self):
        file_name = \
            self.srv_home + os.sep + Cache.ISSUE_CREATEMETA_CACHE

        self.create_meta = ()
        self.create_meta_ts = None

        try:
            vpre(VERBOSITY_INFO,
                u'Loading createmeta information from the cache...', end=u'')
            f = open(file_name, 'r')
            timestamp = datetime.datetime.strptime(
                            f.readline().strip(), Cache.TS_FORMAT)
            raw = json.load(f)
            f.close()
            vpre(VERBOSITY_INFO, u' - done!')

            self.create_meta = CreateIssueMetadata(raw)
            self.create_meta_ts = timestamp

        except IOError, e:
            # TODO: properly handle
            if e.errno != errno.ENOENT:
                vpre(VERBOSITY_ERRORS,
                    u'ERROR: unable to load cached createmeta '\
                    u'information: %s' % str(e))
            return False

        except Exception, e:
            # TODO: properly handle
            if e.errno != errno.ENOENT:
                vpre(VERBOSITY_ERRORS,
                    u'ERROR: unable to load cached createmeta '\
                    u'information: %s' % str(e))
            return False

        return True

    def get_password_from_keyring_or_console(self, server, user):

        name = "jic.server.%s" %(server)

        try:
            from keyring import get_password, set_password
            password = get_password(name, user)
        except ImportError:
            vpre(VERBOSITY_INFO,
                 u'keyring module not installed, getting password '\
                 u'from console')
            password = None

        if password:
            vpre(VERBOSITY_INFO,
                 u'Retrieved password from default keyring')
        else:
            password = self.get_password_from_console(server, user)

            try:
                set_password(name, user, password)
                vpre(VERBOSITY_WARNINGS,
                     u'Stored password into your default keyring')
            except:
                pass
        return password


    def get_password_from_console(self, server, user):

        #vpre(VERBOSITY_INFO, u'INFO: Using user/password to connect to JIRA')
        if not sys.stdin.isatty():
            raise RuntimeError(
                u'Password or oauth token/secret are missing '\
                u'for server \'%s\'' % server)
        pre(u'Please enter password for %s at %s.' % (\
                                                      user, server))
        try:
            password = getpass(u'password: ')
        except EOFError:
            raise RuntimeError(
                u'Password is missing for server \'%s\'' %\
                server)
        return password


    def _cache_createmeta(self):
        try:
            self.create_meta = CreateIssueMetadata({ 'projects': () })
            if self.mode != Cache.MODE_OFFLINE:
                vpre(VERBOSITY_INFO,
                    u'Fetching createmeta information...',
                    end=u'')
                self.create_meta = CreateIssueMetadata(
                        self.get_jira().createmeta(
                            expand='projects.issuetypes.fields'))
            self.create_meta_ts = datetime.datetime.utcnow()

            if self.mode != Cache.MODE_OFFLINE:
                file_name = \
                    self.srv_home + os.sep + Cache.ISSUE_CREATEMETA_CACHE
                tmp_file_name = \
                    self.issue_home + os.sep + '.' + Cache.ISSUE_CREATEMETA_CACHE

                f = open(tmp_file_name, 'w')
                f.write(self.create_meta_ts.strftime('%s\n' % Cache.TS_FORMAT))
                f.write(json.dumps(self.create_meta.create_meta,
                        indent=2, sort_keys=True))
                f.close()
                os.rename(tmp_file_name, file_name)
                vpre(VERBOSITY_INFO, u' - done!')

        except JIRAError, e:
            vpre(VERBOSITY_ERRORS,
                u'ERROR: unable to fetch createmeta information '\
                u'from the server \'%s\': %s' % (self.srv_name, str(e)))
            return False

        except IOError, e:
            vpre(VERBOSITY_ERRORS,
                u'ERROR: unable to store createmeta information: %s' % str(e))
            return False

        except Exception, e:
            vpre(VERBOSITY_ERRORS,
                u'ERROR: error fetching createmeta information: %s' % str(e))
            return False

        return True


    def _cache_issues(self, issues):
        #vpre(VERBOSITY_INFO,
            #u'Caching %d issues...' % len(issues),
            #end=u'')
        for issue in issues:
            self._cache_issue(issue)
        #vpre(VERBOSITY_INFO, u' - done!')


    def _cache_issue(self, issue):
        key = Util.get_nested_value(issue, 'key')
        if not key:
            return False

        ts = datetime.datetime.utcnow()

        self.issue_L1[key] = (ts, issue)

        file_name = self.issue_home + os.sep + str(key)
        tmp_file_name = self.issue_home + os.sep + '.' + str(key)

        try:
            f = open(tmp_file_name, 'w')
            f.write(ts.strftime('%s\n' % Cache.TS_FORMAT))
            f.write(json.dumps(issue.raw, indent=2, sort_keys=True))
            f.close()
            os.rename(tmp_file_name, file_name)

        except IOError, e:
            vpre(VERBOSITY_ERRORS,
                u'ERROR: unable to cache the issue %s: %s' %\
                    (issue.key, str(e)))
            return False

        except Exception, e:
            vpre(VERBOSITY_ERRORS,
                u'ERROR: error caching the issue %s: %s' %\
                    (issue.key, str(e)))
            return False

        return True


    def _cache_editmeta(self, issue, editmeta):
        if not isinstance(issue, basestring):
            issue = Util.get_nested_value(issue, 'key')

        if not issue or not editmeta:
            return False

        ts = datetime.datetime.utcnow()

        self.editmeta_L1[issue] = (ts, editmeta)

        file_name = self.editmeta_home + os.sep + str(issue)
        tmp_file_name = self.editmeta_home + os.sep + '.' + str(issue)

        try:
            f = open(tmp_file_name, 'w')
            f.write(ts.strftime('%s\n' % Cache.TS_FORMAT))
            f.write(json.dumps(editmeta, indent=2, sort_keys=True))
            f.close()
            os.rename(tmp_file_name, file_name)

        except IOError, e:
            vpre(VERBOSITY_ERRORS,
                u'ERROR: unable to cache editmeta for the issue %s: %s' %\
                    (issue.key, str(e)))
            return False

        except Exception, e:
            vpre(VERBOSITY_ERRORS,
                u'ERROR: error caching editmeta for the issue %s: %s' %\
                    (issue.key, str(e)))
            return False

        return True


    def _cache_worklogs(self, issue, worklogs):
        if not isinstance(issue, basestring):
            issue = Util.get_nested_value(issue, 'key')

        if not issue or not worklogs:
            return False

        if type(worklogs) not in (list,tuple):
            worklogs = (worklogs,)

        ts = datetime.datetime.utcnow()

        self.worklog_L1[issue] = (ts, worklogs)

        file_name = self.worklog_home + os.sep + str(issue)
        tmp_file_name = self.issue_home + os.sep + '.' + str(issue)

        try:
            f = open(tmp_file_name, 'w')
            f.write(ts.strftime('%s\n' % Cache.TS_FORMAT))
            f.write(json.dumps(
                [item.raw for item in worklogs],
                indent=2, sort_keys=True))
            f.close()
            os.rename(tmp_file_name, file_name)

        except IOError, e:
            vpre(VERBOSITY_ERRORS,
                u'ERROR: unable to cache worklogs for the issue %s: %s' %\
                    (issue.key, str(e)))
            return False

        except Exception, e:
            vpre(VERBOSITY_ERRORS,
                u'ERROR: error caching worklogs for the issue %s: %s' %\
                    (issue.key, str(e)))
            return False

        return True


    def _load_issue(self, issue_key):
        if not issue_key:
            return (None, None)

        L1_cached = self.issue_L1.get(issue_key)
        if L1_cached:
            return L1_cached

        file_name = self.issue_home + os.sep + str(issue_key)

        try:
            f = open(file_name, 'r')
            timestamp = f.readline().strip()
            raw = json.load(f)
            f.close()

            issue = Issue(self.get_jira()._options, self.get_jira()._session, raw)

            result = (
                datetime.datetime.strptime(timestamp, Cache.TS_FORMAT),
                issue
            )

            self.issue_L1[issue.key] = result

            return result

        except IOError, e:
            vpre(VERBOSITY_ERRORS,
                u'ERROR: unable to load the issue %s: %s' %\
                    (issue.key, str(e)))
            return (None, None)

        except Exception, e:
            # TODO: properly handle
            vpre(VERBOSITY_ERRORS,
                u'ERROR: error loading the issue %s: %s' %\
                    (issue.key, str(e)))
            return (None, None)

        return None, None


    def _load_editmeta(self, issue):
        if not issue:
            return (None, None)

        if not isinstance(issue, basestring):
            issue = issue.key

        L1_cached = self.editmeta_L1.get(issue)
        if L1_cached:
            return L1_cached

        file_name = self.editmeta_home + os.sep + str(issue)

        try:
            f = open(file_name, 'r')
            timestamp = f.readline().strip()
            editmeta = json.load(f)
            f.close()

            result = (
                datetime.datetime.strptime(timestamp, Cache.TS_FORMAT),
                editmeta
            )

            self.editmeta_L1[issue] = result

            return result

        except IOError, e:
            vpre(VERBOSITY_ERRORS,
                u'ERROR: unable to load editmeta for the issue %s: %s' %\
                    (issue.key, str(e)))
            return (None, None)

        except Exception, e:
            # TODO: properly handle
            vpre(VERBOSITY_ERRORS,
                u'ERROR: error loading editmeta for the issue %s: %s' %\
                    (issue.key, str(e)))
            return (None, None)

        return None, None


    def _load_worklogs(self, issue):
        if not issue:
            return (None, None)

        if not isinstance(issue, basestring):
            issue = issue.key

        L1_cached = self.worklog_L1.get(issue)
        if L1_cached:
            return L1_cached

        file_name = self.worklog_home + os.sep + str(issue)

        try:
            f = open(file_name, 'r')
            timestamp = f.readline().strip()
            raw = json.load(f)
            f.close()

            worklogs = [
                Worklog(self.get_jira()._options, self.get_jira()._session, worklog_raw) \
                    for worklog_raw in raw]

            result = (
                datetime.datetime.strptime(timestamp, Cache.TS_FORMAT),
                worklogs
            )

            self.worklog_L1[issue] = result

            return result

        except IOError, e:
            #vpre(VERBOSITY_ERRORS,
                #u'ERROR: unable to load worklogs for the issue %s: %s' %\
                    #(issue, str(e)))
            return (None, None)

        except Exception, e:
            # TODO: properly handle
            vpre(VERBOSITY_ERRORS,
                u'ERROR: error loading worklogs for the issue %s: %s' %\
                    (issue.key, str(e)))
            return (None, None)

        return None, None


    def _cached_issues(self):

        for (_, _, filenames) in os.walk(self.issue_home):
            break

        return [name for name in filenames if Util.is_issue_key(name)]

    def _cached_worklogs(self):

        for (_, _, filenames) in os.walk(self.worklog_home):
            break

        return [name for name in filenames if Util.is_issue_key(name)]


    def _get_by_keys(self, keys, go_down=False, go_up=False,
                     link_types=None, depth=None, order_by=None,
                     filter=None, limit=-1, source=None):

        if not keys or not len(keys):
            return ()

        ts_now = datetime.datetime.utcnow()

        if source is None:
            source = self.source

        result_issues = 0

        issues_to_fetch = []
        fresh_issues = []

        for key in keys:
            if source == Cache.SOURCE_SERVER \
            or (source == Cache.SOURCE_CACHED_SERVER \
                                and self.search_online):
                issues_to_fetch.append(key)
                result_issues += 1
                if limit > 0 and limit <= result_issues:
                    break
            else:
                ts, issue = self._load_issue(key)
                if not issue:
                    continue
                if source == Cache.SOURCE_CACHED_SERVER:
                    if Util.is_stale(self.ttl, ts):
                        issues_to_fetch.append(key)
                        result_issues += 1
                        if limit > 0 and limit <= result_issues:
                            break
                    else:
                        fresh_issues.append(issue)
                        result_issues += 1
                        if limit > 0 and limit <= result_issues:
                            break
                        if go_down or go_up:
                            issues = \
                                self._get_linked_issues(
                                    issue, go_down, go_up, link_types,
                                    depth, order_by, filter,
                                    (limit - result_issues) \
                                        if limit > 0 and not order_by \
                                        else -1,
                                    source=source)
                            for issue in issues:
                                fresh_issues.append(issue)
                                result_issues += 1
                elif source == Cache.SOURCE_CACHE_ONLY:
                    fresh_issues.append(issue)
                    result_issues += 1
                    if limit > 0 and limit <= result_issues:
                        break
                    if go_down or go_up:
                        issues = \
                            self._get_linked_issues(
                                issue, go_down, go_up, link_types,
                                depth, order_by, filter,
                                (limit - result_issues) \
                                    if limit > 0 and not order_by \
                                    else -1,
                                source=source)
                        for issue in issues:
                            fresh_issues.append(issue)
                            result_issues += 1
                else:
                    raise RuntimeError(
                        u'Internal error: unknown source for Cache')

        if issues_to_fetch:
            jql = u'key in (%s)' % u','.join(issues_to_fetch)
            if filter:
                jql += u' and %s' % JQL.emit_filter(filter)
            if order_by:
                jql += JQL.emit_order_by(order_by)

            try:
                #vpre(VERBOSITY_INFO,
                    #u'Fetching %d issues...' % len(issues_to_fetch),
                    #end=u'')
                issues = self.get_jira().search_issues(
                                    jql, fields='*all',
                                    expand='changelog',
                                    maxResults=\
                                        (limit - result_issues) \
                                            if limit > 0 and not order_by \
                                            else -1)
                #vpre(VERBOSITY_INFO, u' - done!')
                issues_to_fetch = []
                #vpre(VERBOSITY_INFO,
                    #u'Caching %d issues...' % len(issues),
                    #end=u'')
                for issue in issues:
                    issue.worklogs = None
                    issues_to_fetch.append(issue)
                    self._cache_issue(issue)
                    result_issues += 1
                #vpre(VERBOSITY_INFO, u' - done!')

                if go_down or go_up:
                    for linked_issue in self._get_linked_issues(
                                    issue, go_down, go_up, link_types,
                                    depth, order_by, filter,
                                    (limit - result_issues) \
                                        if limit > 0 and not order_by \
                                        else -1,
                                    source=source):
                        issues_to_fetch.append(issue)
                        result_issues += 1

            except JIRAError, e:
                #sc = int(Util.get_nested_value(e, 'status_code', 0))
                #if sc >= 400 and sc < 500:
                    #pre(u'ERROR: Issue%s \'%s\' not found.' % ( \
                            #u's' if len(issues) > 1 else u'',
                            #u', '.join(issues)))
                    # TODO: should we abort in this case?
                    #return ()
                #else:
                raise RuntimeError(str(e))

        # merge two lists
        result = fresh_issues + issues_to_fetch

        if order_by:
            vpre(VERBOSITY_INFO, u'Sorting result set...', end=u'')
            result = Util.sort_issues(result, order_by)
            vpre(VERBOSITY_INFO, u' - done!')

        if filter:
            vpre(VERBOSITY_INFO, u'Filtering result set...', end=u'')
            result = [issue for issue in result \
                        if Util.issue_matches_filter(
                            issue, self.variables, filter)]
            vpre(VERBOSITY_INFO, u' - done!')

        return result[:limit] if limit > 0 else result


    def _get_by_filter(self, filter, order_by=None, limit=-1, source=None):
        if not filter:
            raise RuntimeError(
                u'Internal error: empty filter for get_by_filter')

        if source is None:
            source = self.source

        result = []

        if source == Cache.SOURCE_SERVER \
        or (source == Cache.SOURCE_CACHED_SERVER \
                                and self.search_online):
            jql = JQL.emit_filter(filter, self.variables)
            if order_by:
                jql += u' %s' % JQL.emit_order_by(order_by)

            try:
                vpre(VERBOSITY_INFO,
                    u'Fetching issues using JQL: \'%s\'...' % jql)
                issues = self.get_jira().search_issues(
                                    jql, fields='*all',
                                    expand='changelog',
                                    maxResults=limit)
                #vpre(VERBOSITY_INFO, u' - done!')
                vpre(VERBOSITY_INFO,
                    u'Caching %d issues...' % len(issues),
                    end=u'')
                for issue in issues:
                    issue.worklogs = None
                    result.append(issue)
                    self._cache_issue(issue)
                vpre(VERBOSITY_INFO, u' - done!')

            except JIRAError, e:
                sc = int(Util.get_nested_value(e, 'status_code', 0))
                if sc >= 400 and sc < 500:
                    vpre(VERBOSITY_ERRORS, u'ERROR: Issues not found.')
                    # TODO: should we abort in this case?
                    #return ()
                else:
                    raise RuntimeError(str(e))

        elif source == Cache.SOURCE_CACHED_SERVER \
        or source == Cache.SOURCE_CACHE_ONLY:
            cached_issues = self._cached_issues()
            vpre(VERBOSITY_INFO,
                u'Loading issues using filter...',
                end=u'')
            for key in cached_issues:
                _, issue = self._load_issue(key)
                if Util.issue_matches_filter(issue, self.variables, filter):
                    result.append(issue)
                    if limit > 0 \
                    and not order_by \
                    and len(result) >= limit:
                        break
            vpre(VERBOSITY_INFO, u' - done!')

            if order_by:
                vpre(VERBOSITY_INFO, u'Sorting result set...', end=u'')
                result = Util.sort_issues(result, order_by)
                vpre(VERBOSITY_INFO, u' - done!')

        else:
            raise RuntimeError(u'Internal error: unknown mode')

        return result[:limit] if limit > 0 else result


    def _get_by_query(self, query, limit=-1):
        if not query:
            raise RuntimeError(
                u'Internal error: empty filter for get_by_query')

        result = []
        issues = ()

        for jql in query:

            if self.source == Cache.SOURCE_SERVER \
            or (self.source == Cache.SOURCE_CACHED_SERVER \
                                    and self.search_online):
                try:
                    vpre(VERBOSITY_INFO,
                        u'Fetching issues using JQL: \'%s\'...' % jql)
                    issues = self.get_jira().search_issues(
                                        jql, fields='*all',
                                        expand='changelog',
                                        maxResults=limit)
                    #vpre(VERBOSITY_INFO, u' - done!')
                    vpre(VERBOSITY_INFO,
                        u'Caching %d issues...' % len(issues),
                        end=u'')
                    for issue in issues:
                        issue.worklogs = None
                        result.append(issue)
                        self._cache_issue(issue)
                    vpre(VERBOSITY_INFO, u' - done!')

                except JIRAError, e:
                    sc = int(Util.get_nested_value(e, 'status_code', 0))
                    if sc >= 400 and sc < 500:
                        vpre(VERBOSITY_ERRORS,
                            u'ERROR: %s' % str(e.text))
                        #vpre(VERBOSITY_ERRORS,
                            #u'ERROR: Issue%s \'%s\' not found.' % ( \
                                #u's' if len(issues) > 1 else u'',
                                #u', '.join(issues)))
                        # TODO: should we abort in this case?
                        #return ()
                    else:
                        raise RuntimeError(str(e))

            elif self.source == Cache.SOURCE_CACHED_SERVER \
            or self.source == Cache.SOURCE_CACHE_ONLY:
                raise RuntimeError(
                    u'Offline JQL queries are not supported yet.')

            else:
                raise RuntimeError(u'Internal error: unknown mode')

        return result[:limit] if limit > 0 else result


    def _get_linked_issues(self, pivot_issue, traverse_down=True,
                           traverse_up=False, link_types=True,
                           depth=None, order_by=None, filter=None,
                           limit=None, query=None, source=None):
        """Depth first tree traversal"""
        if not pivot_issue:
            raise RuntimeError( \
                    u'Internal error: missing pivot issue')

        if isinstance(pivot_issue, basestring):
            issues = self.get(pivot_issue)
            if not len(issues):
                raise RuntimeError(
                        u'WARNING: Issue %s not found' % pivot_issue)
            pivot_issue = issues[0]

        if source is None:
            source = self.source

        if depth is not None and depth <= 0:
            depth = None

        queue = [(pivot_issue, traverse_up, traverse_down, depth), ]
        visited = set()
        result = []
        vpre(VERBOSITY_INFO,
            u'Traversing links for the issue %s...'  % pivot_issue,
            end=u'')
        while queue:
            issue, go_up, go_down, depth = queue.pop(0)

            if isinstance(issue, basestring):
                if issue.strip() in visited:
                    continue
                issues = self.get(issues=issue, source=source)
                if issues is None:
                    raise RuntimeError(
                        u'Unable to retrieve issue %s' % issue)
                issue = issues[0]
            else:
                if issue.key in visited:
                    continue

            visited.add(issue.key)
            if issue.key != pivot_issue.key:
                result.append(issue)

            if depth is not None and depth <= 0:
                continue

            links = Util.get_nested_value(
                            issue, 'fields.issuelinks', ())

            queue_chunk = []
            for link in links:
                if link_types and link.type.name not in link_types:
                    continue
                linked_go_up, linked_go_down = go_up, go_down

                child_issue_stub = Util.get_nested_value(
                                            link, 'inwardIssue')
                #child_key = Util.get_nested_value(
                                    #link, 'inwardIssue.key')
                if go_down and child_issue_stub:
                    child_issue_stub.stub = True
                    if child_issue_stub.key == pivot_issue.key:
                        linked_go_up = False
                    child_issue = self.get(issues=child_issue_stub.key,
                                           source=source)
                    if not child_issue:
                        child_issue = child_issue_stub
                    else:
                        child_issue = child_issue[0]
                    queue_chunk.append(
                                    (child_issue, linked_go_up,
                                        linked_go_down,
                                        depth - 1 if depth else None))

                parent_issue_stub = Util.get_nested_value(
                                            link, 'outwardIssue')
                if go_up and parent_issue_stub:
                    parent_issue_stub.stub = True
                    if parent_issue_stub.key == pivot_issue.key:
                        linked_go_down = False
                    parent_issue = self.get(issues=parent_issue_stub.key,
                                            source=source)
                    if not parent_issue:
                        parent_issue = parent_issue_stub
                    else:
                        parent_issue = parent_issue[0]
                    queue_chunk.append(
                                    (parent_issue, linked_go_up,
                                        linked_go_down,
                                        depth - 1 if depth else None))

            queue[0:0] = queue_chunk
        vpre(VERBOSITY_INFO, u' - done!')

        if order_by:
            vpre(VERBOSITY_INFO, u'Sorting result set...', end=u'')
            result = Util.sort_issues(result, order_by)
            vpre(VERBOSITY_INFO, u' - done!')

        return result


# class Cache


class Template (object):

    HOME = 'templates'
    DEFAULT_TEMPLATE_NAME = 'default'
    DEFAULT_FIELD_DELIMITER = u' - '
    DEFAULT_MINIMAL_ITEM_WIDTH = 8
    DEFAULT_OUTPUT_WIDTH = 72

    def __init__(self, cfg, cache=None):
        self.cfg = cfg
        self.cache = cache
        self.home = os.path.expanduser(os.path.expandvars(
                    cfg.o.home.location + os.sep + Template.HOME))

        home_exists, home_accessible = Util.ensure_dir_access(
                self.home, os.R_OK | os.W_OK | os.X_OK, 0700)

        if home_exists != True:
            raise home_exists

        if not home_accessible:
            raise RuntimeError(
               'Template directory \'%s\' should have \'rwx\' mode' % self.home)

        # set default formatters
        self.init = Template.Default.init
        self.format_value = Template.Default.format_value
        self.format_field_name = Template.Default.format_field_name
        self.format_field_value = Template.Default.format_field_value
        self.get_issue_type_icon = Template.Default.get_issue_type_icon
        self.print_issue_list = Template.Default.print_issue_list
        self.format_issue_list_item = \
                                Template.Default.format_issue_list_item
        self.print_issue_tree = Template.Default.print_issue_tree
        self.issue_tree_item = Template.Default.format_issue_tree_item
        self.format_issue_header = Template.Default.format_issue_header
        self.format_all_issue_fields = \
                                Template.Default.format_all_issue_fields
        self.print_issue_links = Template.Default.print_issue_links
        self.format_issue_links_item = \
                                Template.Default.format_issue_links_item
        self.print_issue_comments = \
                                Template.Default.print_issue_comments
        self.format_issue_comments_item = \
                                Template.Default.format_issue_comments_item
        self.print_issue_history = Template.Default.print_issue_history
        self.format_issue_history_item = \
                                Template.Default.format_issue_history_item
        self.print_issue_worklog = Template.Default.print_issue_worklog
        self.format_issue_worklog_item = \
                                Template.Default.format_issue_worklog_item
        self.format_server_list_item = \
                                Template.Default.format_server_list_item
        self.format_server = Template.Default.format_server
        self.convert_issue_fields_for_editing = \
                        Template.Default.convert_issue_fields_for_editing
        self.generate_issue_fields_for_creation = \
                        Template.Default.generate_issue_fields_for_creation
        self.convert_issue_fields_after_editing = \
                        Template.Default.convert_issue_fields_after_editing
        self.get_field_list_for_issue_creation = \
                        Template.Default.get_field_list_for_issue_creation
        self.get_field_list_for_issue_editing = \
                        Template.Default.get_field_list_for_issue_editing
        self.get_field_list_to_force_jicML_markers = \
                        Template.Default.get_field_list_to_force_jicML_markers
        self.format_issue_field_meta = \
                        Template.Default.format_issue_field_meta
        self.get_new_issue_field_values = \
                        Template.Default.get_new_issue_field_values

        template = cfg.o.get('display.template')
        if not template:
            vpre(VERBOSITY_INFO, u'Using default template.')
        else:
            vpre(VERBOSITY_INFO,
                u'Loading template: \'%s\'...' % template,
                end=u'')
            filenames = ()
            for (dirpath, dirnames, filenames) in os.walk(self.home):
                break
            if template not in filenames:
                vpre(VERBOSITY_WARNINGS,
                    u'\nWARNING: Template \'%s\' not found, using default one.' %\
                        template)
            else:
                try:
                    options = Namespace()
                    parsed = {}
                    publics = {
                        'template': self,
                        'def_template': Template.Default,
                        'util': Util,
                    }
                    execfile(self.home + os.sep + template, publics)

                except Exception, e:
                    # TODO: report properly
                    vpre(VERBOSITY_WARNINGS,
                        u'WARNING: Unable to load template \'%s\': %s' %\
                            (template, unicode(e)))
                vpre(VERBOSITY_INFO, u' - done!')

        self.field_delimiter = cfg.o.get('display.field_delimiter',
                                    Template.DEFAULT_FIELD_DELIMITER)

        self.minimal_item_width = Template.DEFAULT_MINIMAL_ITEM_WIDTH
        self.output_width = cfg.o.get('display.output_width',
                                    Template.DEFAULT_OUTPUT_WIDTH)

        if cache:
            self.field_by_id = cache.field_by_id
            self.field_by_name = cache.field_by_name
        else:
            self.field_by_id = {}
            self.field_by_name = {}

        # adjust template using command line options
        if cache:
            fields = cfg.o.get('display.fields')
            if fields:
                resolved_fields = []
                for name in fields:
                    resolved_name = cache.get_field_id(name)
                    resolved_fields.append(
                        resolved_name if resolved_name else name)
                self.fields = resolved_fields
            else:
                self.fields = fields


    def get_output_width(self):
        try:
            return int(os.environ.get('COLUMNS', self.output_width))
        except Exception:
            return self.output_width


    def _get_field_name(self, field_id):
        return self.cache.fields.get_field_name(field_id, field_id)


    def _get_field_id(self, field_name):
        return self.field_by_name.get(field_name)


    # default template implementation
    class Default (object):

        DATETIME_FORMAT = '%Y-%m-%d %H:%M:%S'

        @staticmethod
        def init(tpl):
            return

        @staticmethod
        def format_value(value):
            if isinstance(value, basestring):
                return value

            if value is None:
                return u''

            t = type(value)
            if t == datetime.datetime:
                return value.strftime(Template.Default.DATETIME_FORMAT)

            elif t in (tuple, list):
                return u', '.join([Template.Default.format_value(item) \
                                    for item in value])

            elif t == dict:
                return u', '.join( \
                            [u'%s: %s' %(name, val) \
                                for name, val in value.iteritems()])

            elif t in (Status, Component, Version, Project, IssueType,
                                                            Resolution):
                return value.name

            elif t == User:
                name = value.name
                disp_name = value.displayName
                email = value.emailAddress
                if disp_name:
                    str_user = '%s (%s) <%s>' % (disp_name, name, email)
                else:
                    str_user = email
                return str_user

            else:
                return str(value)


        @staticmethod
        def format_field_name(tpl, issue, field_name):
            return tpl._get_field_name(field_name)


        @staticmethod
        def format_field_value(tpl, issue, field_name, value):
            return tpl.format_value(value)


        @staticmethod
        def format_issue_from_fieldlist(tpl, issue, fields, width=None):
            if width is None:
                width = tpl.get_output_width()
            values = []
            first_field = None
            for field in fields:
                if field[0] == '$':
                    function = tpl.__dict__.get(field[1:], None)
                    if function is None:
                        value = '!function %s not found!' % field[1:]
                    value = function(tpl, issue)
                else:
                    value = Util.get_issue_field_value(issue, field)
                if first_field is None:
                    first_field = value + tpl.field_delimiter
                value = tpl.format_field_value(tpl, issue, field, value)
                values.append(value)
            if width and width > 0:
                return textwrap.wrap( \
                                tpl.field_delimiter.join(values),
                                width,
                                break_long_words=True,
                                subsequent_indent=u' ' * len(first_field))
            else:
                return (tpl.field_delimiter.join(values),)


        @staticmethod
        def get_issue_type_icon(tpl, issue):
            issue_type = Util.get_nested_value(
                                issue, 'fields.issuetype.name', '')
            issue_summary = Util.get_nested_value(
                                issue, 'fields.summary', '')
            if issue_type == u'Sub-task':
                return u'➏'
            elif issue_type == u'Blueprint':
                return u'➎'
            elif issue_type == u'Engineering card':
                return u'➃'
            elif issue_type == u'Link':
                return u'➃'
            elif issue_type == u'Roadmap Card':
                if issue_summary.lower().startswith(u'epic:'):
                    return u'➁'
                else:
                    return u'➂'
            elif issue_type == u'Request':
                return u'➀'
            elif issue_type == u'New Feature':
                return u'➀'
            elif issue_type == u'Bug':
                return u'➑'

            return issue_type


        @staticmethod
        def print_issue_list(tpl, issues, printer=None, width=None):
            if printer == None:
                printer = pr
            for issue in issues:
                for line in tpl.format_issue_list_item(tpl, issue, width):
                    printer(line)


        @staticmethod
        def format_issue_list_item(tpl, issue, width=None):
            if tpl.fields:
                return Template.Default.\
                    format_issue_from_fieldlist(tpl, issue, tpl.fields)
            if width is None:
                width = tpl.get_output_width()

            type_icon = tpl.get_issue_type_icon(tpl, issue)
            key = Util.get_nested_value(
                            issue, 'key', 'N/A')
            summary = Util.get_nested_value(
                            issue, 'fields.summary', 'N/A')
            status = Util.get_nested_value(
                            issue, 'fields.status.name', 'N/A')
            resolution = Util.get_nested_value(
                            issue, 'fields.resolution.name')
            if resolution:
                status += u' / ' + issue.fields.resolution.name

            icon_and_key = len(type_icon) + 1 + len(key) + \
                            len(tpl.field_delimiter)
            all_but_summary = icon_and_key + \
                              len(status) + len(tpl.field_delimiter)

            available_width = width

            delta = available_width - all_but_summary
            if delta < tpl.minimal_item_width:
                return textwrap.wrap( \
                            u'%s %s%s%s' % (
                                tpl.format_field_value(tpl, issue, 'key', key),
                                tpl.format_field_value(tpl, issue, 'summary', summary),
                                tpl.field_delimiter,
                                tpl.format_field_value(tpl, issue, 'status', status)))
            else:
                wrapped_summary = textwrap.wrap(summary, delta,
                                                break_long_words=True)
                result = [u'%s %s%s%s%s%s' % (
                            type_icon,
                            tpl.format_field_value(tpl, issue, 'key', key),
                            tpl.field_delimiter,
                            tpl.format_field_value(tpl, issue, 'summary', wrapped_summary[0]),
                            tpl.field_delimiter,
                            tpl.format_field_value(tpl, issue, 'status', status)),]
                for line in wrapped_summary[1:]:
                    result.append(
                            tpl.format_field_value(tpl, issue, 'status',
                                u'%s%s' % (
                                        u' ' * icon_and_key,
                                        line)))

                return result


        ISSUE_FIELDS = (
            # field name            is a massive text
            ('key',                 False),
            ('issuetype',           False),
            ('summary',             False),
            ('status',              False),
            ('resolution',          False),
            ('resolutiondate',      False),
            ('assignee',            False),
            ('updated',             False),
            ('fixVersions',         False),
            ('reporter',            False),
            ('created',             False),
            ('project',             False),
            ('components',          False),
            ('labels',              False),
            ('customfield_10204',   True),
            ('URL',                 False),
            ('description',         True),
        )

        @staticmethod
        def format_issue_fields(tpl, issue,
                                field_defs=ISSUE_FIELDS, width=None):
            if width is None:
                width = tpl.get_output_width()

            result = u''

            for field, multiline in field_defs:
                value = Util.get_issue_field_value(issue, field, True)
                if not value:
                    continue
                f_field = tpl.format_field_name(tpl, issue, field)
                f_value = tpl.format_field_value(tpl, issue, field, value)
                result += jicML.emit_value(f_value, f_field, width,
                                           force_markers=multiline)\
                          + u'\n'

            return result


        @staticmethod
        def format_all_issue_fields(tpl, issue, width=None):
            return Template.Default.format_issue_fields(
                    tpl, issue, Template.Default.ISSUE_FIELDS, width)


        @staticmethod
        def format_issue_header(tpl, issue, width=None):
            if width is None:
                width = tpl.get_output_width()
            return Template.Default.format_issue_fields(
                    tpl, issue, Template.Default.ISSUE_FIELDS[:5],
                    width)


        @staticmethod
        def print_issue_links(tpl, issue, printer=None, width=None):
            if printer == None:
                printer = pr
            if width is None:
                width = tpl.get_output_width()

            links = issue.fields.issuelinks
            name = 'Links (%d)' % len(links)
            name = tpl.format_field_name(tpl, issue, name)
            printer(u'\n%s:\n' % name)
            first = True
            for link in links:
                printer(tpl.format_issue_links_item(tpl, issue, link, width),
                        end='')


        @staticmethod
        def format_issue_links_item(tpl, issue, link, width=None):
            if width is None:
                width = tpl.get_output_width()
            child = Util.get_nested_value(link, 'inwardIssue')
            if child:
                icon = u'-'
                name = link.type.inward
                other = child
            else:
                parent = Util.get_nested_value(link, 'outwardIssue')
                icon = u'+'
                name = link.type.outward
                other = parent

            prefix = u'%s %s: ' % (icon, name)

            text = prefix + \
                    ''.join(tpl.format_issue_list_item(tpl, other))
            result = u''

            for line in textwrap.wrap(
                            text,
                            width,
                            subsequent_indent=u' ' * len(prefix)):
                result += line + u'\n'

            return result


        @staticmethod
        def print_issue_comments(tpl, issue, printer=None, width=None):
            if printer == None:
                printer = pr
            if width is None:
                width = tpl.get_output_width()

            comments = issue.fields.comment.comments
            name = 'Comments (%d)' % len(comments)
            name = tpl.format_field_name(tpl, issue, name)
            printer(u'\n%s:\n' % name)
            first = True
            for comment in comments:
                if first:
                    first = False
                else:
                    printer('')
                printer(tpl.format_issue_comments_item(tpl, issue, comment, width),
                        end='')


        @staticmethod
        def format_issue_comments_item(tpl, issue, comment, width=None,
                                        show_issue_key=False):
            if width is None:
                width = tpl.get_output_width()
            created = Util.get_issue_field_value(comment, 'created')
            updated = Util.get_issue_field_value(comment, 'updated')
            id_str = u'[%s%s] ' % (
                    (u'%s:' % issue.key) if show_issue_key else u'',
                    comment.id)
            author = comment.author
            result = u''
            if created != updated:
                editor = comment.updateAuthor
                text = u'%sOn %s, %s wrote and on %s, %s updated:\n' % (
                            id_str,
                            Template.Default.format_field_value(tpl,
                                                issue, 'created', created),
                            Template.Default.format_field_value(tpl,
                                                issue, 'author', author),
                            Template.Default.format_field_value(tpl,
                                                issue, 'updated', updated),
                            Template.Default.format_field_value(tpl,
                                                issue, 'editor', editor))
            else:
                text = u'%sOn %s, %s wrote:\n' % (
                            id_str,
                            Template.Default.format_field_value(tpl,
                                                issue, 'created', created),
                            Template.Default.format_field_value(tpl,
                                                issue, 'author', author))
            for line in textwrap.wrap(
                                text,
                                width,
                                break_long_words=True,
                                subsequent_indent=u' ' * len(id_str)):
                result += line + u'\n'


            for line in textwrap.wrap(
                                comment.body,
                                width,
                                break_long_words=True,
                                replace_whitespace=False):
                result += u'%s\n' % line

            return result


        @staticmethod
        def print_issue_history(tpl, issue, printer=None, width=None):
            if printer == None:
                printer = pr
            if width is None:
                width = tpl.get_output_width()

            changes = Util.get_issue_field_value(issue,
                                        'changelog.histories')
            name = 'Changes (%d)' % len(changes)
            name = tpl.format_field_name(tpl, issue, name)
            printer(u'\n%s:\n' % name)
            if not changes:
                printer(u'no changes')
                return

            first = True
            for change in changes:
                if first:
                    first = False
                else:
                    printer('')
                printer(tpl.format_issue_history_item(tpl, issue, change, width),
                        end='')


        @staticmethod
        def format_issue_history_item(tpl, issue, change, width=None):
            if width is None:
                width = tpl.get_output_width()
            when = Util.get_issue_field_value(change, 'created')
            who = Util.get_issue_field_value(change, 'author')
            id_str = u'[%s] ' % change.id
            text = u'%sOn %s, %s changed:\n' % (
                    id_str,
                    Template.Default.format_field_value(tpl, issue, 'created', when),
                    Template.Default.format_field_value(tpl, issue, 'author', who))
            result = u''
            for line in textwrap.wrap(
                                text,
                                width,
                                break_long_words=True,
                                subsequent_indent=u' ' * len(id_str)):
                result += line + u'\n'

            first = True
            for change in change.items:
                if first:
                    first = False
                else:
                    result += u'\n'
                what = change.field
                from_value = change.fromString \
                           if change.fromString is not None \
                           else change.__dict__['from']
                from_value = u'' if from_value is None else from_value
                from_value = from_value.splitlines()
                to_value = change.toString \
                         if change.toString is not None \
                         else change.to
                to_value = u'' if to_value is None else to_value
                to_value = to_value.splitlines()

                skipping = True
                for line in difflib.unified_diff(from_value, to_value):
                    if not skipping:
                        result += line + u'\n'
                    elif line.startswith(u'@@'):
                        skipping = False
                        result += u'%s %s\n' % (line.strip(), what)

            return result


        @staticmethod
        def print_issue_worklog(tpl, issue, printer=None, width=None):
            if printer == None:
                printer = pr
            if width is None:
                width = tpl.get_output_width()

            worklogs = issue.worklogs
            if not worklogs:
                worklogs = ()

            name = 'Worklog (%d)' % len(worklogs)
            name = tpl.format_field_name(tpl, issue, name)
            printer(u'\n%s:\n' % name)
            if not worklogs:
                printer(u'no items')
                return

            for wl in worklogs:
                printer(tpl.format_issue_worklog_item(tpl, issue, wl))


        @staticmethod
        def format_issue_worklog_item(tpl, issue, worklog_item,
                                      width=None):
            if width is None:
                width = tpl.get_output_width()

            result = u''

            id_str = u'[%s] ' % worklog_item.id
            author = Util.get_nested_value(worklog_item, 'author', True)
            created = Util.get_issue_field_value(
                            worklog_item, 'created')
            updated = Util.get_issue_field_value(
                            worklog_item, 'updated')
            started = Util.get_issue_field_value(
                            worklog_item, 'started')
            spent = Util.get_issue_field_value(
                            worklog_item, 'timeSpent')
            seconds_spent = int(Util.get_issue_field_value(
                            worklog_item, 'timeSpentSeconds'))
            comment = Util.get_issue_field_value(
                            worklog_item, 'comment')

            comment = comment.strip()

            name = Util.get_nested_value(author, 'name')
            disp_name = Util.get_nested_value(author, 'displayName')
            email = Util.get_nested_value(author, 'emailAddress')
            if disp_name:
                str_author = u'%s <%s>' % (disp_name, email)
            else:
                str_author = name

            if created != updated:
                editor = Util.get_nested_value(worklog_item,
                                                'updateAuthor', True)
                name = Util.get_nested_value(editor, 'name')
                disp_name = Util.get_nested_value(editor, 'displayName')
                email = Util.get_nested_value(editor, 'emailAddress')
                if disp_name:
                    str_editor = u'%s <%s>' % (disp_name, email)
                else:
                    str_editor = name
                text = u'%sOn %s, %s logged and on %s, %s updated %s%s\n' % (
                            id_str,
                            Template.Default.format_field_value(tpl, 'created', created),
                            str_author,
                            Template.Default.format_field_value(tpl, 'updated', updated),
                            str_editor,
                            spent,
                            u':' if len(comment) else u'')
            else:
                text = u'%sOn %s, %s logged %s%s\n' % (
                            id_str,
                            Template.Default.format_field_value(tpl, 'created', created),
                            str_author,
                            spent,
                            u':' if len(comment) else u'')

            for line in textwrap.wrap(
                                text,
                                tpl.get_output_width(),
                                break_long_words=True,
                                subsequent_indent=u' ' * len(id_str)):
                result += line + u'\n'


            if len(comment):
                for line in textwrap.wrap(
                                    comment,
                                    tpl.get_output_width(),
                                    break_long_words=True):
                    result += u'%s\n' % line

            return result


        @staticmethod
        def print_issue_tree(tpl, issue, printer=None, width=None):
            if width is None:
                width = tpl.get_output_width()
            # TODO: implement
            return u'N/A'


        @staticmethod
        def format_issue_tree_item(tpl, issue, width=None):
            if width is None:
                width = tpl.get_output_width()
            # TODO: implement
            return u'N/A'


        @staticmethod
        def format_server_list_item(tpl, srv_name, srv_def, is_default):
            flags = []
            if srv_def.get('password'):
                flags.append(u'pwd')
            if srv_def.get('user'):
                flags.append(u'usr')
            if srv_def.get('oauth.cert'):
                flags.append(u'crt')
            if srv_def.get('oauth.token'):
                flags.append(u'tok')
            if srv_def.get('oauth.secret'):
                flags.append(u'sec')

            flags = u', '.join(flags)

            url = srv_def.get('url', 'N/A')

            return u'%s %s [%s]: %s' % (u'*' if is_default else u' ',
                                        srv_name, flags, url)


        @staticmethod
        def format_server(tpl, srv_name, srv_def, is_default):
            result = u'Server%s: %s\n' % (
                    u' (default)' if is_default else u'',
                    srv_name)
            for name, value in srv_def.itertree():
                if isinstance(value, basestring) \
                and value.find('\n') != -1:
                    lines = value.splitlines()
                    max_idx = len(lines) - 1
                    first = True
                    for idx, line in enumerate(lines):
                        if first:
                            result += (u'%s = \\\n' % name)
                            first = False
                            # fall through
                        result += (u'    \'%s\'%s\n' % (
                                    line, ('\\' if idx != max_idx else '')))
                else:
                    result += (u'%s = %s\n' % (name, repr(value)))
            return result


        @staticmethod
        def get_field_list_for_issue_creation(tpl, parent_issue,
                                                    issue_type, project_key):
            return (
                'Key', 'Summary', 'Issue Type', 'Priority', 'Component',
                'Fix Version/s', 'Labels', 'Assignee', 'Reporter',
                'Description'
            )


        @staticmethod
        def get_field_list_for_issue_editing(tpl, issue):
            return (
                'Key', 'Summary', 'Issue Type', 'Priority', 'Component',
                'Fix Version/s', 'Labels', 'Assignee', 'Reporter',
                'Description'
            )

        @staticmethod
        def get_field_list_to_force_jicML_markers(tpl):
            return ( 'Description', )

        @staticmethod
        def convert_issue_fields_for_editing(tpl, issue, field_meta,
                                                fields=None):
            if not fields:
                fields = \
                    tpl.get_field_list_for_issue_editing(tpl, issue)
            #included_fields = set(fields) if fields else None
            result = OrderedDict()
            fname = field_meta.get_field_name('key', 'Key')
            result[fname] = issue.key
            #processed = set((fname,))

            issue_fields = issue.fields.__dict__

            if fields:
                for name in fields:
                    fid = field_meta.get_field_id(name, name)
                    fname = field_meta.get_field_name(name, name)
                    #if fname in processed:
                    if fname in result:
                        continue
                    #processed.add(fname)
                    value = issue_fields.get(fid)
                    if not value and fid not in issue_fields:
                        raise RuntimeError(
                            u'Field \'%s\' is not known' % name)
                    value = field_meta.convert_field_value_for_editing(
                                            fid, value)
                    if value is not None:
                        result[fname] = value
            else:
                for fid, value in issue_fields.iteritems():
                    if fid[0] == '_':
                        continue
                    fname = field_meta.get_field_name(fid, fid)
                    #if fname in processed:
                    if fname in result:
                        continue
                    #processed.add(fname)
                    value = field_meta.convert_field_value_for_editing(
                                            fid, value)
                    if value is not None:
                        result[fname] = value

            return result


        @staticmethod
        def generate_issue_fields_for_creation(tpl, issue, parent_issue,
                                    issue_type, field_meta, fields=None):
            if not fields:
                fields = \
                    tpl.get_field_list_for_issue_creation(tpl, issue)
            included_fields = set(fields) if fields else None
            result = OrderedDict()
            fname = field_meta.get_field_name('key', 'Key')
            result[fname] = issue.key
            #processed = set((fname,))

            issue_fields = issue.fields

            if fields:
                for name in fields:
                    fid = field_meta.get_field_id(name, name)
                    fname = field_meta.get_field_name(name, name)
                    #if fname in processed:
                    if fname in result:
                        continue
                    #processed.add(fname)
                    value = issue_fields.get(fid)
                    if not value and fid not in issue_fields:
                        raise RuntimeError(
                            u'Field \'%s\' is not known' % name)
                    value = field_meta.convert_field_value_for_editing(
                                            fid, value)
                    if value is not None:
                        result[fname] = value
            else:
                for fid, value in issue_fields.iteritems():
                    if fid[0] == '_':
                        continue
                    fname = field_meta.get_field_name(fid, fid)
                    #if fname in processed:
                    if fname in result:
                        continue
                    #processed.add(fname)
                    value = field_meta.convert_field_value_for_editing(
                                            fid, value)
                    if value is not None:
                        result[fname] = value

            return result



        @staticmethod
        def convert_issue_fields_after_editing(tpl, fields, field_meta):
            result = OrderedDict()

            for name, value in fields.iteritems():
                fid = field_meta.get_field_id(name)
                fvalue = field_meta.convert_field_value_after_editing(
                                                            fid, value)
                result[name] = fvalue
            return result


        @staticmethod
        def format_issue_field_meta(tpl, field_meta):
            val_type = Util.get_nested_value(
                            field_meta, 'schema.type', u'N/A')
            if val_type == 'array':
                val_type += u':%s' % Util.get_nested_value(
                            field_meta, 'schema.items', u'N/A')
            return u'- %s (%s): %s' % (
                    field_meta.get('name'),
                    field_meta.get('id'),
                    val_type)


        @staticmethod
        def get_new_issue_field_values(tpl, parent_issue, issue_type,
                                                                project):
            project_name = \
                tpl.cache.create_meta.get_project_name(project)
            values = {
                'assignee': parent_issue.fields.assignee,
                'priority': parent_issue.fields.priority,
                'project': project_name,
                'link [Implements]': parent_issue.key,
            }
            if issue_type == 'Sub-task':
                values['parent'] = parent_issue.key

            return values

    # class Default

# class Template


class jicML (object):

    MARKER_START    = u'{{{'
    MARKER_END      = u'}}}'

    @staticmethod
    def parse_nvpair(text_iter):
        """Parses a single field and its value, returns those as a
        tuple"""

        parsing_multiline = False
        folding_ws = False
        name = None
        value = u''
        line = u''
        while True:
            try:
                line = text_iter.next()
            except StopIteration:
                line = None

            if parsing_multiline:
                if line is None \
                or line.lstrip().startswith(jicML.MARKER_END):
                    if value and value[-1] == u'\n':
                        value = value[:-1]
                    return (name, value)

                pos = line.find(jicML.MARKER_END)
                if pos < 0:
                    value += line + u'\n'
                    continue

                remainder = line[:pos]
                if remainder:
                    value += remainder
                else:
                    if value[-1] == u'\n':
                        value = value[:-1]
                parsing_multiline = False
                return (name, value)

            elif folding_ws:
                if line is None \
                or not line.strip() \
                or line[0] not in u' \t':
                    if line is not None:
                        text_iter.previous()
                    value = value.replace(u'\\n', '\n')
                    return (name, value)
                value += u' ' + line.strip()
                continue

            if line is None:
                return (None, None)

            sline = line.strip()
            if not sline \
            or sline.startswith(u'#'):
                continue

            if name is None and value == u'':
                pos = line.find(jicML.MARKER_START)
                if pos < 0:
                    lhs, delimiter, rhs = line.partition(u':')
                    if delimiter:
                        name = lhs.strip()
                    else:
                        rhs = lhs
                else:
                    if line[:pos].find(u':') != -1:
                        lhs, delimiter, rhs = line.partition(u':')
                        if delimiter:
                            name = lhs.strip()
                        else:
                            rhs = lhs
                    else:
                        rhs = line

                rhs = rhs.lstrip()

                if rhs.startswith(jicML.MARKER_START):
                    value = rhs[len(jicML.MARKER_START):]
                    if not value.strip():
                        value = u''
                        parsing_multiline = True
                        continue
                    pos = value.find(jicML.MARKER_END)
                    if pos < 0:
                        parsing_multiline = True
                        continue
                    value = value[:pos]
                    return (name, value)
                else:
                    value = rhs.strip()
                    folding_ws = True
                    continue

        return (None, None) # never reached


    @staticmethod
    def parse_values(jicml):
        """Parse a stream of jicML values

        Parameters:
            jicml   - jicML formatted set of values

        Returns:
            array   - parsed values
        """
        # TODO: implement
        return None


    @staticmethod
    def parse_nvpairs(jicml):
        """Parse a stream of jicML name:value pairs

        Parameters:
            jicml   - jicML formatted set of name:value pairs

        Returns:
            dict    - parsed name:value pairs
        """
        # TODO: implement
        return None


    @staticmethod
    def emit_value(value, field_name=None, width=0,
                   force_markers=False):
        """Generates a jicML representation of a value

        Parameters:
            value           - a value to represent in jicML
            field_name      - a name of the field this value is related
                              to
            width           - text width (-1 means use terminal's one, 0
                              means no wrapping)
            force_markers   - wrap value into multiline markers
                              regardless its nature (multiline vs
                              singleline)

        Returns:
            string  - generated jicML representation
        """

        if not value:
            return u'{{{\n}}}' if force_markers else u''

        if width == -1:
            width = os.environ.get('COLUMNS', 0)

        if not isinstance(value, basestring):
            t = type(value)

            if t == datetime.date:
                value = value.strftime('%Y-%m-%d')

            elif t == datetime.datetime:
                value = value.strftime('%Y-%m-%d %H:%M:%S')

            elif t in (tuple, list):
                value = u', '.join(value)

        if force_markers or value.find('\n') != -1:
            return \
                ((field_name + u': ') if field_name else u'') + \
                u'%s\n' % jicML.MARKER_START + value + \
                u'\n%s' % jicML.MARKER_END

        else:
            text = \
                ((field_name + u': ') if field_name else u'') \
                + value
            if width:
                return u'\n'.join(
                                textwrap.wrap(text, width,
                                              break_long_words=True,
                                              subsequent_indent=u' ' * 4))
            else:
                return text


    @staticmethod
    def emit_values(values, width=0, force_markers=False):
        """Generates a jicML representation of a set of an values

        Parameters:
            values          - an enumerable container with values
            width           - text width (-1 means use terminal's one, 0
                              means no wrapping)
            force_markers   - wrap value into multiline markers
                              regardless its nature (multiline vs
                              singleline)

        Returns:
            string  - generated jicML representation
        """

        if not values:
            return ''

        result = u''

        for value in values:
            if type(value) in (list, tuple):
                field_name, field_value = value[:2]
            else:
                field_name = None
                field_value = value
            result += Util.emit_value(field_value, field_name, width,
                                                        force_markers)
        return result


    @staticmethod
    def parse_issues(text_iter):
        issues = OrderedDict()
        common_fields = []

        collecting_common_fields = True
        current_issue = None
        while True:
            name, value = jicML.parse_nvpair(text_iter)
            if not name:
                break
            lname = name.lower()

            if collecting_common_fields:
                if lname != 'key':
                    common_fields.append((name, value))
                    continue
                else:
                    collecting_common_fields = False
                    # fall through

            if lname == 'key':
                current_issue = OrderedDict()
                current_issue[name] = value
                current_issue.update(common_fields)
                issues[value] = current_issue
            else:
                current_issue[name] = value

        return issues

# class jicML


class FieldMetadata(object):

    def __init__(self, field_meta=None):
        self.field_meta = field_meta
        self.field_meta.append(
            {   u'id':      u'parent',
                u'name':    u'Parent Issue',
                u'schema':  {   u'type':    u'string',
                                u'system':  u'parent'
                            }
            })
        # index fields
        self.field_by_id = {}
        self.field_by_name = {}
        for field_def in field_meta:
            self.field_by_id[field_def.get('id')] = field_def
            self.field_by_name[field_def.get('name')] = field_def


    def get_field_id(self, partial_name, default=None):
        result = self.field_by_id.get(partial_name)
        if result:
            return result['id']

        result = self.field_by_name.get(partial_name)
        if result:
            return result['id']

        matches = []
        for name in self.field_by_id.keys():
            if name.find(partial_name) != -1:
                matches.append(self.field_by_id[name]['id'])
        if len(matches) > 1:
            raise RuntimeError(
                u'Partially specified field name \'%s\' is ambigous' %\
                    partial_name)
        if matches:
            return matches[0]

        matches = []
        for name in self.field_by_name.keys():
            if name.find(partial_name) != -1:
                matches.append(self.field_by_name[name]['id'])
        if len(matches) > 1:
            raise RuntimeError(
                u'Partially specified field name \'%s\' is ambigous' %\
                    partial_name)
        if matches:
            return matches[0]

        return default


    def get_field_name(self, partial_name, default):
        result = self.field_by_id.get(partial_name)
        if result:
            return result['name']

        result = self.field_by_name.get(partial_name)
        if result:
            return result['name']

        matches = []
        for name in self.field_by_id.keys():
            if name.find(partial_name) != -1:
                matches.append(self.field_by_id[name]['name'])
        if len(matches) > 1:
            raise RuntimeError(
                u'Partially specified field name \'%s\' is ambigous' %\
                    partial_name)
        if matches:
            return matches[0]

        matches = []
        for name in self.field_by_name.keys():
            if name.find(partial_name) != -1:
                matches.append(self.field_by_name[name]['name'])
        if len(matches) > 1:
            raise RuntimeError(
                u'Partially specified field name \'%s\' is ambigous' %\
                    partial_name)
        if matches:
            return matches[0]

        return default


    def convert_field_value_for_editing(self, field_name, field_value):
        if field_value is None:
            return u''

        field_id = self.get_field_id(field_name)
        val_type = self.get_field_type(field_id)

        return self._convert_field_value_for_editing(
                        field_id, val_type, field_value)


    def _convert_field_value_for_editing(self, fname, ftype, fvalue):

        if isinstance(fvalue, basestring) \
        and ftype[0] not in ('date', 'datetime'):
            return fvalue

        if ftype[0] in ('string',):
            if hasattr(fvalue, 'value'):
                return fvalue.value
            return unicode(fvalue)

        elif ftype[0] == 'date':
            date = datetime.date.strptime(fvalue, '%Y-%m-%d')
            #return dt.strftime('%Y-%m-%d')
            return dt

        elif ftype[0] == 'datetime':
            dt = datetime.datetime.strptime(
                    fvalue[:19], '%Y-%m-%dT%H:%M:%S')
            #return dt.strftime('%Y-%m-%d %H:%M:%S')
            return dt

        elif ftype[0] in ('priority', 'project', 'status', 'resolution',
                          'version', 'component', 'securitylevel',
                          'issuetype'):
            return Util.get_nested_value(fvalue, 'name')

        elif ftype[0] == 'number':
            return fvalue

        elif ftype[0] == 'user':
            #name = Util.get_nested_value(fvalue, 'name')
            #disp_name = Util.get_nested_value(fvalue, 'displayName')
            #email = Util.get_nested_value(fvalue, 'emailAddress')

            #result = u''
            #if disp_name:
                #result = '%s (%s) <%s>' % (disp_name, name, email)
            #else:
                #result = email

            result = Util.get_nested_value(fvalue, 'name')

            if not result:
                result = fvalue

            return result

        elif ftype[0] == 'progress':
            #return u'%d/%d' % (fvalue.progress, fvalue.total)
            return (fvalue.progress, fvalue.total)

        elif ftype[0] == 'array':
            if ftype[1] in ('comment', 'issuelinks', 'votes', 'watches',
                                'worklog'):
                return None
            result = []
            for subvalue in fvalue:
                result.append(self._convert_field_value_for_editing(
                                    fname, ftype[1:], subvalue))
            #return u', '.join(result)
            return result

        return unicode(fvalue)


    def convert_field_value_after_editing(self, field_id, field_value):
        if field_value is None:
            return u''

        ftype = self.get_field_type(field_id)

        if ftype[0] in ('string', 'issuetype', 'priority', 'project',
                            'status', 'resolution', 'version',
                            'component', 'securitylevel', 'user'):
            return field_value.strip()

        elif ftype[0] == 'date':
            if not field_value:
                return u''
            return datetime.date.strptime(field_value, '%Y-%m-%d')

        elif ftype[0] == 'datetime':
            if not field_value:
                return u''
            return datetime.datetime.strptime(field_value,
                                                    '%Y-%m-%d %H:%M:%S')

        elif ftype[0] == 'number':
            return long(field_value)

        elif ftype[0] == 'progress':
            progress, delim, total = field_value.partition('/')
            if delim:
                try:
                    return (long(progress), long(total))
                except ValueError:
                    return u''

        elif ftype[0] == 'array':
            if field_id == 'comment':
                return field_value

            if not field_value:
                return u''

            values = [item.strip() for item in field_value.split(',')]
            if ftype[1] == 'number':
                try:
                    values = [long(item) for item in values]
                except ValueError:
                    pass
            return values

        return field_value


    def get_field_type(self, field_id):
        meta = self.field_by_id.get(field_id)
        if not meta:
            return 'string'
        val_type = [Util.get_nested_value(meta, 'schema.type'), ]
        if val_type[0] == 'array':
            val_type.append(Util.get_nested_value(meta, 'schema.items'))
        return val_type


    def create_issue_mockup(self, issue_key, issue_type, field_values=None):
        """Creates a mockup of a JIRA issue (data only)

        Parameters:
            issue_key : string
                key of the issue to create mockup for
            issue_type : string
                name of the issue type
            field_values : iterable
                list of (name, value) pairs providing values for
                corresponding fields
        Returns:
            a data-only issue mockup (implemented using Namespace class)
        """
        issue_mockup = Namespace()
        for field_def in self.field_meta:
            field_name = field_def['name']
            field_name = self.get_field_id(field_name)
            value = None
            if field_values and field_name in field_values:
                value = field_values.get(field_name)
            issue_mockup.set('fields.%s' % field_name, value)

        issue_mockup.key = issue_key
        issue_mockup.issuekey = issue_key
        issue_mockup.fields.issuetype = issue_type

        issue_mockup.learn(False)

        return issue_mockup


# class FieldMetadata


class CreateIssueMetadata(object):

    def __init__(self, create_meta=None):
        self.create_meta = create_meta
        # index projects, issue types and fields
        self.project_by_key = {}
        self.project_by_name = {}
        for project_def in create_meta.get('projects'):
            project_issue_types = {}
            for issue_type_def in project_def.get('issuetypes', ()):
                issue_type_fields = issue_type_def['fields']
                issue_type_info = (issue_type_def, issue_type_fields)
                project_issue_types[issue_type_def['name']] = \
                                                        issue_type_info
            project_info = (project_def, project_issue_types)
            self.project_by_key[project_def.get('key')] = project_info
            self.project_by_name[project_def.get('name')] = project_info


    def get_project_key(self, project):
        project_def = self.project_by_key.get(project)
        if not project_def:
            project_def = self.project_by_name.get(project, (None,None))
        return project_def[0]['key']


    def get_project_name(self, project):
        project_def = self.project_by_key.get(project)
        if not project_def:
            project_def = self.project_by_name.get(project, (None,None))
        return project_def[0]['name']


    def get_project_def(self, project):
        project_def = self.project_by_key.get(project)
        if not project_def:
            project_def = self.project_by_name.get(project, (None,None))
        return project_def


    def get_project_issue_type(self, project, issue_type):
        project_def, issue_types = self.get_project_def(project)
        if not project_def:
            raise RuntimeError(u'Unknown project: \'%s\'' % project)
        pair = issue_types.get(issue_type)
        if not pair:
            raise RuntimeError(
                u'Unknown issue type \'%s\' for project \'%s\'' % (
                    issue_type, project))
        issue_type_def, field_defs = pair
        return issue_type_def


    def get_project_issue_type_fields(self, project, issue_type):
        project_def, issue_types = self.get_project_def(project)
        if not project_def:
            raise RuntimeError(u'Unknown project: \'%s\'' % project)
        pair = issue_types.get(issue_type)
        if not pair:
            raise RuntimeError(
                u'Unknown issue type \'%s\' for project \'%s\'' % (
                    issue_type, project))
        issue_type_def, field_defs = pair
        return field_defs


# class CreateIssueMetadata


class EditingContext(object):

    def __init__(self, cfg, cache, tpl):
        self.cfg = cfg
        self.cache = cache
        self.field_meta = cache.fields
        self.create_meta = cache.create_meta
        self.tpl = tpl
        self.original = OrderedDict()
        self.edited = OrderedDict()


    def prepare_issues_for_editing(self, issues):
        jicml = u''
        first = True
        prepared = OrderedDict()
        forced_markers = \
            self.tpl.get_field_list_to_force_jicML_markers(self.tpl)
        forced_markers = set([
            self.field_meta.get_field_name(item, item) \
                for item in forced_markers ])

        for issue in issues:
            if first:
                first = False
            else:
                jicml += u'\n\n'

            fields = \
                self.tpl.convert_issue_fields_for_editing(
                            self.tpl, issue, self.cache.fields,
                            self.tpl.fields)
            prepared[issue.key] = fields
            for fname, value in fields.iteritems():
                if hasattr(issue, 'editmeta') \
                and issue.editmeta is not None:
                    editmeta = issue.editmeta.get('fields', None)
                    if editmeta:
                        fid = self.field_meta.get_field_id(fname, fname)
                        field_edit_meta = editmeta.get(fid, ())
                        if field_edit_meta:
                            allowed_values = []
                            for item in field_edit_meta.get('allowedValues', ()):
                                iname = item.get('name')
                                if iname:
                                    allowed_values.append(iname)
                            if allowed_values:
                                text = u'Allowed values for '\
                                       u'\'%s\': %s\n' % (
                                            fname, u', '.join(allowed_values))
                                lines = textwrap.wrap(
                                            text, 72,
                                            break_long_words=True,
                                            initial_indent=u'# ',
                                            subsequent_indent=u'#  ')
                                jicml += u'\n'.join(lines) + u'\n'
                jicml += u'%s: %s\n' % (fname,
                            jicML.emit_value(
                                value,
                                force_markers=(fname in forced_markers)))

            # TODO: allow adding a new comment within the same change set
            #jicml += u'Comment: {{{\n}}}\n'

        self.original = prepared

        return jicml


    def create_issue_mockup(self, issue_key, parent_issue, issue_type,
                                                                project):
        """Creates a data-only mockup for an issue using information
        provided"""
        fields_with_values = self.tpl.get_new_issue_field_values(
            self.tpl, parent_issue, issue_type, project)
        mockup = self.field_meta.create_issue_mockup(
                                    issue_key, issue_type,
                                    fields_with_values)
        return mockup


    def prepare_new_issue_for_editing(self, issue, fields_to_show,
                                                    fields_meta=None):
        jicml = u''
        forced_markers = \
            self.tpl.get_field_list_to_force_jicML_markers(self.tpl)
        forced_markers = set([
            self.field_meta.get_field_name(item, item) \
                for item in forced_markers ])

        for name in fields_to_show:
            field_name = self.field_meta.get_field_name(name, name)
            field_id = self.field_meta.get_field_id(name, name)
            value = Util.get_issue_field_value(issue, field_id)
            value = self.field_meta.convert_field_value_for_editing(
                                field_id, value)

            if value is None:
                value = u''

            if fields_meta and field_id in fields_meta:
                allowed_values = []
                for item in fields_meta[field_id].get('allowedValues', ()):
                    iname = item.get('name')
                    if iname:
                        allowed_values.append(iname)
                if allowed_values:
                    text = u'Allowed values for '\
                           u'\'%s\': %s\n' % (
                                field_name, u', '.join(allowed_values))
                    lines = textwrap.wrap(
                                text, 72,
                                break_long_words=True,
                                initial_indent=u'# ',
                                subsequent_indent=u'#  ')
                    jicml += u'\n'.join(lines) + u'\n'

            jicml += u'%s: %s\n' % (field_name,
                        jicML.emit_value(
                                value,
                                force_markers=(field_name in forced_markers)))

        return jicml


    def prepare_issues_for_creating(self, issues):
        jicml = u''
        first = True
        prepared = OrderedDict()
        for issue in issues:
            if first:
                first = False
            else:
                jicml += u'\n\n'

            fields = \
                self.tpl.generate_issue_fields_for_creation(
                            self.tpl, issue, self.cache.fields,
                            self.tpl.fields)
            prepared[issue.key] = fields
            for fname, value in fields.iteritems():
                if hasattr(issue, 'editmeta') \
                and issue.editmeta is not None:
                    editmeta = issue.editmeta.get('fields', None)
                    if editmeta:
                        fid = self.field_meta.get_field_id(fname, fname)
                        field_edit_meta = editmeta.get(fid, ())
                        if field_edit_meta:
                            allowed_values = []
                            for item in field_edit_meta.get('allowedValues', ()):
                                iname = item.get('name')
                                if iname:
                                    allowed_values.append(iname)
                            if allowed_values:
                                text = u'Allowed values: %s\n' % (u', '.join(allowed_values))
                                lines = textwrap.wrap(
                                            text, 72,
                                            break_long_words=True,
                                            initial_indent=u'# ',
                                            subsequent_indent=u'#  ')
                                jicml += u'\n'.join(lines) + u'\n'
                jicml += u'%s: %s\n' % (fname, jicML.emit_value(value))

            # allow adding a new comment within the same change set
            #jicml += u'Comment: {{{\n}}}\n'

        self.original = prepared

        return jicml


    def parse_edited_issues(self, jicml_text):
        issues = jicML.parse_issues(TextIterator(jicml_text))
        result = OrderedDict
        for key in issues:
            fields = issues.get(key)
            fields = self.tpl.convert_issue_fields_after_editing(
                            self.tpl, fields, self.cache.fields)
            issues[key] = fields
        self.edited = issues
        return issues


    def generate_create_job(self):
        edited = self.edited
        if not edited:
            raise RuntimeError(
                u'Internal Error: no edited values for EditingContext')

        field_meta = self.cache.fields

        job = {}
        current_issue = {}

        # go through the issues added in editor
        for issue_key, fields in edited.iteritems():
            if not issue_key.startswith('NEW-'):
                continue

            fields_to_set = {}
            for fname, value in fields.iteritems():
                fid = field_meta.get_field_id(fname)

                if fid in ('issuekey', 'key'):
                    continue

                if value:
                    self._add_field_update_job(
                        fields_to_set, fid, None, value)
            if fields_to_set:
                job[issue_key] = fields_to_set

        return job


    def generate_update_job(self):
        original = self.original
        #if not original:
            #raise RuntimeError(
                #u'Internal Error: no original values for EditingContext')
        edited = self.edited
        if not edited:
            raise RuntimeError(
                u'Internal Error: no edited values for EditingContext')

        field_meta = self.cache.fields

        job = {}
        current_issue = {}
        eissues_processed = set()

        # go through the originally listed issues
        for issue_key, ofields in original.iteritems():
            if issue_key not in edited:
                continue # removed by user - skip
            if issue_key.startswith('NEW-'):
                continue
            eissues_processed.add(issue_key)
            efields = edited.get(issue_key)
            efields_processed = set(('key', 'issuekey'))

            # go through the original fields
            for fname, ovalue in ofields.iteritems():
                fid = field_meta.get_field_id(fname)
                if fid in ('issuekey', 'key'):
                    continue

                efields_processed.add(fname)

                evalue = efields.get(fname)

                if fname not in efields \
                or ovalue == evalue \
                or (not ovalue and not evalue):
                    continue

                if issue_key not in job:
                    current_issue = {}
                    job[issue_key] = current_issue

                self._add_field_update_job(
                    current_issue, fid, ovalue, efields.get(fname))

            # now - through the newly added ones
            for fname, evalue in efields.iteritems():
                if fname in efields_processed:
                    continue

                fid = field_meta.get_field_id(fname)

                if fid in ('issuekey', 'key'):
                    continue

                if issue_key not in job:
                    current_issue = {}
                    job[issue_key] = current_issue

                self._add_field_update_job(
                    current_issue, fid, None, evalue)

        # now go through the issues added in editor
        for issue_key, efields in edited.iteritems():
            if issue_key in eissues_processed:
                continue
            if issue_key.startswith('NEW-'):
                continue

            for fname, evalue in efields.iteritems():
                fid = field_meta.get_field_id(fname)

                if fid in ('issuekey', 'key'):
                    continue

                if issue_key not in job:
                    current_issue = {}
                    job[issue_key] = current_issue

                self._add_field_update_job(
                    current_issue, fid, None, evalue)

        return job


    def _add_field_update_job(self, issue_job, fid, ovalue, evalue):
        ftype = self.field_meta.get_field_type(fid)
        if ftype[0] == 'array':
            if fid == 'labels' and not evalue:
                evalue = []
            if fid not in ('labels',):
                evalue = [{ 'name': item} for item in evalue]
        elif ftype[0] in ('priority', 'user', 'issuetype'):
            evalue = { 'name': evalue }
        elif ftype[0] in ('project',):
            project_key = self.create_meta.get_project_key(evalue)
            evalue = { 'key': project_key }

        if fid == 'parent':
            evalue = { 'key': evalue }

        issue_job[fid] = evalue
        return issue_job

# class EditingContext


################################################################
###  Commands  #################################################
################################################################


GET_COMMENTS_PROMPT = """\
# Please enter one or more comments to be added for the following
# issues (in jicml value format - please see `man jicml`):
# %s
#
# If you provide less comments than the number issues listed, the last
# comment provided will be used for all the issues that are lacking
# their individually provided comments (this can be used to add the same
# comment into multiple issues - just provide one comment in this case).
#
# Leave the file intact or delete all its content to cancel the
# operation.

"""

def cmd_comments_add(cfg):
    cache = Cache(cfg)
    tpl = Template(cfg, cache)

    if cache.mode == Cache.MODE_OFFLINE:
        raise RuntimeError(
                u'Can\'t add comments in offline mode yet')

    listed_issues = \
        Util.unwrap_list_of_lists(cfg.o.get('query.args',()))

    if not listed_issues:
        vpre(VERBOSITY_ERRORS, u'ERROR: Please specify issue '\
                               u'id(s) to add comment(s) to')
        return 1

    job = []
    job_keys = set()
    for key in listed_issues:
        if not Util.is_issue_key(key):
            vpre(VERBOSITY_WARNINGS, u'WARNING: Invalid issue key '\
                                     u'\'%s\' - skipped.' % key)
            continue
        if key not in job_keys:
            job.append(key)
            job_keys.add(key)

    if not job:
        vpre(VERBOSITY_WARNINGS, u'WARNING: Nothing to do.')
        return 1

    issues = cache.get(job)
    if not issues:
        vpre(VERBOSITY_ERRORS, u'ERROR: Unable to retrieve issues: '\
                               u'%s' % (u', '.join(job)))
        return 1

    # editor based
    if cfg.o.get('cl.use_editor', False):
        text_for_editing = GET_COMMENTS_PROMPT % (u', '.join(job))
        editor = cfg.o.get('editor', 'sensible-editor')
        vpre(VERBOSITY_INFO, u'Invoking %s to edit get comment(s)' %\
                                                            editor)
        comment_bodies = Util.get_from_editor(cfg, editor,
                                              text_for_editing, 'text')
        if not comment_bodies \
        or comment_bodies == text_for_editing:
            vpre(VERBOSITY_INFO, u'Cancelled')
            return 1

        strin = TextIterator(comment_bodies)

        _, comment_body = jicML.parse_nvpair(strin)
        if comment_body is None or not comment_body.strip():
            vpre(VERBOSITY_WARNINGS, u'WARNING: Not adding an empty comment')
            return 1

        for issue in issues:
            try:
                cache.add_comment(issue, comment_body)
            except Exception, e:
                vpre(VERBOSITY_ERRORS,
                     u'ERROR: Unable to add new comment for '\
                     u'issue \'%s\': %s' % (issue.key, str(e)))

            # if there are no more comments - use the last one
            _, next_comment = jicML.parse_nvpair(strin)
            if next_comment is not None:
                comment_body = next_comment

    # stdin based
    else:
        if sys.stdin.isatty():
            raise RuntimeError(
                u'Please pipe comment body in or use -e switch.')
        stdin = FileTextIterator(sys.stdin)
        _, comment_body = jicML.parse_nvpair(stdin)
        if comment_body is None or not comment_body.strip():
            vpre(VERBOSITY_ERRORS, u'ERROR: Not adding an empty comment')
            return 1

        for issue in issues:
            try:
                cache.add_comment(issue, comment_body)
            except Exception, e:
                vpre(VERBOSITY_ERRORS,
                     u'ERROR: Unable to add new comment for issue '\
                     u'\'%s\': %s' % (issue.key, str(e)))

            # if there are no more comments - use the last one
            _, next_comment = jicML.parse_nvpair(stdin)
            if next_comment is not None:
                comment_body = next_comment

    return 0


def cmd_comments_delete(cfg):
    cache = Cache(cfg)
    tpl = Template(cfg, cache)

    if cache.mode == Cache.MODE_OFFLINE:
        raise RuntimeError(
                u'Can\'t delete comments in offline mode yet')

    if cfg.o.get('cl.use_editor', False):
        raise RuntimeError(
            u'Comment deletion using an editor is not implemented yet.')

    listed_comments = \
        Util.unwrap_list_of_lists(cfg.o.get('query.args',()))

    job = Util.parse_comment_ids(listed_comments)

    if not job:
        if sys.stdin.isatty():
            raise RuntimeError(
                u'Please pipe the key:comment pairs in or use -e switch.')
        else:
            vpre(VERBOSITY_WARNINGS, u'WARNING: Nothing to do')

    pre(u'The following comments are going to be deleted:\n')

    to_delete = []
    to_delete_ids = set()
    for issue_key, comment_ids in job:
        if not comment_ids:
            vpre(VERBOSITY_WARNINGS,
                u'WARNING: Will not delete all comments '\
                u'for issue \'%s\'' % issue_key)
            continue

        issue = cache.get(issue_key)
        if not issue:
            vpre(VERBOSITY_WARNINGS,
                'WARNING: issue \'%s\' not found - skipped' % issue_key)
            continue
        issue = issue[0]

        for comment in issue.fields.comment.comments:
            if not comment_ids or comment.id in comment_ids:
                to_delete.append((issue, comment))
                key = u'%s:%s' % (issue.key, comment.id)
                if key not in to_delete_ids:
                    pre(tpl.format_issue_comments_item(tpl, issue,
                                    comment, show_issue_key=True))
                    to_delete_ids.add(key)

    pre()

    if not to_delete:
        vpre(VERBOSITY_WARNINGS, u'WARNING: Nothing to do.')
        return 0

    if Util.confirm(u'Are you sure you want to delete them? (type YES)',
                                                        strict=True):
        for issue, comment in to_delete:
            try:
                comment.delete()
            except Exception, e:
                vpre(VERBOSITY_ERRORS,
                    u'Unable to delete comment %s:%s: %s' % (
                        issue.key, comment.id, str(e)))
        cache.fetch([issue.key for issue, _ in to_delete])
    else:
        vpre(VERBOSITY_WARNINGS, u'Not deleting.')

    return 0


EDIT_COMMENTS_PROMPT = """\
# Please edit the comment%s listed below. You may also add additional
# comments you would like to edit with their respective new text, or
# remove ones you would not like to edit.
#
# Leave the file intact or delete all its content to cancel the
# operation.

"""

def cmd_comments_edit(cfg):
    cache = Cache(cfg)
    tpl = Template(cfg, cache)

    if cache.mode == Cache.MODE_OFFLINE:
        raise RuntimeError(
                u'Can\'t edit comments in offline mode yet')

    listed_comments = \
        Util.unwrap_list_of_lists(cfg.o.get('query.args',()))

    job = Util.parse_comment_ids(listed_comments)

    vpre(VERBOSITY_INFO,
        u'The following comments are going to be edited:\n')

    to_edit = []
    to_edit_ids = set()
    for issue_key, comment_ids in job:
        if not comment_ids:
            vpre(VERBOSITY_WARNINGS,
                u'WARNING: Will not edit all comments '\
                u'for issue \'%s\'' %  issue_key)
            continue

        issue = cache.get(issue_key)
        if not issue:
            vpre(VERBOSITY_WARNINGS,
                u'WARNING: issue \'%s\' not found - skipped' % \
                    issue_key)
            continue
        issue = issue[0]

        for comment in issue.fields.comment.comments:
            if not comment_ids or comment.id in comment_ids:
                to_edit.append((issue, comment))
                key = u'%s:%s' % (issue.key, comment.id)
                if key not in to_edit_ids:
                    vpre(VERBOSITY_INFO,
                            tpl.format_issue_comments_item(tpl, issue,
                                comment, show_issue_key=True))
                    to_edit_ids.add(key)

    vpre(VERBOSITY_INFO, u'')

    if not to_edit:
        vpre(VERBOSITY_WARNINGS, u'WARNING: Nothing to do.')
        return 0

    # editor based
    if cfg.o.get('cl.use_editor', False):
        raise RuntimeError(
            u'Comment editing using an editor is not implemented yet.')
        # generate textual representation of comments
        # invoke editor
        # parse edited file
        # show changes and get confirmation
        # apply changes if any

    # stdin based
    else:
        if sys.stdin.isatty():
            raise RuntimeError(
                u'Please pipe the new comment bodies in or use -e switch')

        stdin = FileTextIterator(sys.stdin)
        _, comment_body = jicML.parse_nvpair(stdin)
        if comment_body is None or not comment_body.strip():
            raise RuntimeError(
                u'ERROR: Not replacing with an empty comment')

        for issue, comment in to_edit:
            try:
                # Workaround replacing the line below (not yet
                # implemented in jira-python)
                # comment.update(stripped)
                data = { 'body': comment_body }
                super(Comment, comment).update(**data)
            except Exception, e:
                vpre(VERBOSITY_ERRORS,
                    u'ERROR: Unable to edit comment %s for issue '\
                    u'\'%s\': %s' % (comment.id, issue.key, str(e)))

            # if there are no more comments - use the last one
            _, next_comment = jicML.parse_nvpair(stdin)
            if next_comment is not None:
                comment_body = next_comment

        vpre(VERBOSITY_INFO,
            u'Fetching %d updated issues...' % len(to_edit),
            end=u'')
        cache.fetch([issue.key for issue, _ in to_edit])
        vpre(VERBOSITY_INFO, u' - done!')

    return 0


def cmd_comments_list(cfg):
    listed_issues = \
        Util.unwrap_list_of_lists(cfg.o.get('query.args',()))

    cache = Cache(cfg)
    tpl = Template(cfg, cache)

    issues = cache.get(
                listed_issues,
                cfg.o.get('query.down', False),
                cfg.o.get('query.up', False),
                cfg.o.get('query.down_from'),
                cfg.o.get('query.up_from'),
                cfg.o.get('query.include_self', False),
                cfg.o.get('query.link_types'),
                cfg.o.get('query.depth'),
                cfg.o.get('display.order_by'),
                cfg.o.get('query.number_of_items'),
                cfg.o.get('query.filter'),
                cfg.o.get('query.jql'))

    first = True
    for issue in issues:
        if first:
            first = False
        else:
            pr()
        pr(tpl.format_issue_header(tpl, issue), end='')
        tpl.print_issue_comments(tpl, issue)

    return 0


def cmd_comments_reply(cfg):
    raise RuntimeError(u'Not implemented yet.')
    pre(u'WIP:cmd_comments_reply')
    return 0


def cmd_comments_show(cfg):
    listed_comments = \
        Util.unwrap_list_of_lists(cfg.o.get('query.args',()))

    job = Util.parse_comment_ids(listed_comments)

    cache = Cache(cfg)
    tpl = Template(cfg, cache)

    for issue_key, comment_ids in job:
        issue = cache.get(issue_key)
        if not issue:
            vpre(VERBOSITY_WARNINGS,
                'WARNING: issue \'%s\' not found - skipped' % issue_key)
            continue
        issue = issue[0]
        for comment in issue.fields.comment.comments:
            if not comment_ids or comment.id in comment_ids:
                if cfg.o.get('display.raw', False):
                    #pr(jicML.emit_value(
                            #comment.body, force_markers=True))
                    pr(jicML.emit_value(comment.body,
                        force_markers=False))
                else:
                    pr(tpl.format_issue_comments_item(tpl, issue,
                                comment, show_issue_key=True))
    return 0


def cmd_commands_symlink(cfg):
    commands = cfg.o.get('commands')
    if not commands:
        raise RuntimeError(
            u'No porcelain commands defined')

    jic_file = Util.get_jic_file()
    jic_location = Util.get_jic_location()
    symlink_location = os.path.expanduser(os.path.expandvars(
                    cfg.o.get('symlink.location', jic_location)))

    symlink_mode = cfg.o.get('symlink.mode')
    if symlink_mode is None:
        symlink_mode = 0700

    try:
       os.makedirs(symlink_location, symlink_mode)
    except OSError, e:
        if e.errno != errno.EEXIST:
            raise e

    need_su = False
    for cmd_name in commands.iterkeys():
        symlink_name = symlink_location + os.sep + cmd_name
        vpre(VERBOSITY_INFO,
            u'Creating a symlink for %s...' % cmd_name)
        try:
            if os.access(symlink_name, os.R_OK):
                os.remove(symlink_name)
            os.symlink(jic_file, symlink_name)
        except OSError, e:
            if e.errno == errno.EPERM:
                need_su = True
            vpre(VERBOSITY_ERRORS,
                u'ERROR: Unable to create a symlink '\
                u'for \'%s\' at %s: %s' % (
                    cmd_name, symlink_name, str(e)))

    if need_su:
        vpre(VERBOSITY_ERRORS,
            u'Please repeat the same command as superuser '\
            u'or change the `symlink_location` config option '\
            u'to point to a directory in your PATH that you '\
            u'have permission to modify.')


def cmd_configuration_edit(cfg):
    editor = cfg.o.get('editor', 'sensible-editor')
    Util.edit_file(editor, cfg.config_file)


# TODO: get from template
CREATE_ISSUES_PROMPT = """\
# Please edit the field values for the new issue%s listed below.
# You may also add additional issues you would like to create and/or
# fields you would like to provide values for with their respective new
# values, or remove ones you would not like to create.
#
# New issues should have 'NEW-' prefix in their keys.
#
# Leave the file intact or delete all its content to cancel the
# operation.

"""

def cmd_issues_create(cfg):
    cache = Cache(cfg)

    if cache.mode == Cache.MODE_OFFLINE:
        raise RuntimeError(
                u'Can\'t create issues in offline mode yet')

    arguments = \
        Util.unwrap_list_of_lists(cfg.o.get('query.args',()))

    if not cfg.o.get('cl.use_editor', False) \
    or not sys.stdin.isatty() \
    or not sys.stdout.isatty():
        raise RuntimeError(
            u'Issue creation is only sopported using an editor for now')

    parent_issues = []
    projects_to_create_issues_in = []
    issues_to_edit = []

    go_down = cfg.o.get('query.down', False)

    down_from = cfg.o.get('query.down_from', [])
    if down_from:
        parent_issues.extend(down_from)

    issue_types = cfg.o.get('query.issue_types')
    if not issue_types:
        raise RuntimeError(
            u'One or more issue type need to be specified '\
            u'to create issues')

    # get a list of issue IDs to create issues with
    # validate issues listed
    for issue in arguments:
        if Util.is_issue_key(issue):
            if go_down:
                parent_issues.append(issue)
            else:
                issues_to_edit.append(issue)
        else:
            projects_to_create_issues_in.append(issue)

    if not projects_to_create_issues_in and not issues_to_edit:
        vpre(VERBOSITY_WARNINGS, u'WARNING: Nothing to do.')
        return 0

    tpl = Template(cfg, cache)

    edc = EditingContext(cfg, cache, tpl)

    # fetch existing ones (if any)
    if parent_issues:
        vpre(VERBOSITY_INFO,
            u'Fetching %d parent issues...' % len(parent_issues),
            end=u'')
        parent_issues = cache.fetch(parent_issues)

    if issues_to_edit:
        vpre(VERBOSITY_INFO,
            u'Fetching %d issues for editing...' % len(issues_to_edit),
            end=u'')
        issues_to_edit = cache.fetch(issues_to_edit)


    ##### the code below should be refactored and relocated into
    ##### corresponding classes

    issues_to_create = []
    issue_counters = {}

    for project in projects_to_create_issues_in:
        issue_counters[project] = 1

    # process all the issues being created
    first = True
    jicml_created = u''
    for parent_issue in parent_issues:
        for issue_type in issue_types:
            for project in projects_to_create_issues_in:
                # determine the fields for each new issue:
                # first - the always required ones...
                fields_to_show = \
                    [u'issuekey', u'summary', u'issuetype',
                            u'project']
                fields_processed = set(fields_to_show)
                fields_processed.add(u'key')

                # ...then - required ones that are not listed by
                # the template...
                template_fields = tpl.get_field_list_for_issue_creation(
                            tpl, parent_issue, issue_type, project)
                template_fields = [edc.field_meta.get_field_id(name, name) \
                                    for name in template_fields]
                all_fields = cache.create_meta.\
                                get_project_issue_type_fields(
                                    project, issue_type)
                required_fields = [ \
                    field_id \
                        for field_id, field_def in all_fields.iteritems() \
                        if field_def['required'] ]
                covered_by_template = set(fields_processed)
                covered_by_template.update(template_fields)

                for field_name in required_fields:
                    if field_name not in covered_by_template:
                        fields_to_show.append(field_name)
                        fields_processed.add(field_name)

                for field_name in covered_by_template:
                    if field_name not in fields_processed:
                        fields_to_show.append(field_name)
                        fields_processed.add(field_name)

                # ...and then the ones from template
                for field_name in template_fields:
                    if field_name not in fields_processed:
                        fields_to_show.append(field_name)
                        fields_processed.add(field_name)

                issue_key = 'NEW-%s-%d' % (
                                project, issue_counters[project])
                issue_counters[project] += 1

                mockup = edc.create_issue_mockup(
                        issue_key, parent_issue, issue_type, project)

                mockup.set('fields.reporter', cache.user)

                issues_to_create.append((mockup, fields_to_show))

                if first:
                    first = False
                else:
                    jicml_created += u'\n\n'

                fields_meta = \
                    edc.create_meta.get_project_issue_type_fields(
                                        project, issue_type)

                jicml_created += edc.prepare_new_issue_for_editing(
                                            mockup, fields_to_show,
                                            fields_meta)

    jicml = CREATE_ISSUES_PROMPT % (
        u's' if len(issues_to_create) != 1 else u'')
    jicml += jicml_created
    if issues_to_edit:
        jicml += u'\n\n' + EDIT_ISSUES_PROMPT % (
            u's' if len(issues_to_edit) != 1 else u'')
        jicml += edc.prepare_issues_for_editing(issues_to_edit)

    # invoke an editor
    editor = cfg.o.get('editor', 'sensible-editor')
    edited_jicml = Util.get_from_editor(
                    cfg, editor, jicml, file_suffix=u'jicml')

    if not edited_jicml:
        vpre(VERBOSITY_INFO, u'Cancelled by the user')
        return 0

    # parse issues
    parsed_issues = edc.parse_edited_issues(edited_jicml)

    # generate jobs
    create_job = edc.generate_create_job()
    update_job = edc.generate_update_job()

    if create_job:
        pre(u'New issues to be created:')
        issue_keys = sorted(update_job.keys())
        for issue in issue_keys:
            fields = update_job.get(issue)
            pre(u'* %s' % issue)
            issue_fields = sorted(fields.keys())
            for fid in issue_fields:
                value = fields.get(fid)
                fname = cache.fields.get_field_name(fid, fid)
                if not value:
                    value = u''
                else:
                    if type(value) in (list, tuple):
                        items = []
                        for item in value:
                            if type(item) == dict:
                                if item:
                                    items.append(item.get(item.keys()[0]))
                        else:
                            items.append(str(item))
                        value = u', '.join(items)
                    elif type(value) == dict:
                        if 'name' in value:
                            value = value.get('name', value)
                        elif 'key' in value:
                            value = value.get('key', value)
                        else:
                            value = value.get(value.keys()[0])
                    if not value:
                        value = u''
                value = jicML.emit_value(value)
                pre(u'  - %s: %s' % (fname, value))

    # show update job and get user's confirmation
    if update_job:
        pre(u'\n\nPending changes to be applied:')
        issue_keys = sorted(update_job.keys())
        for issue in issue_keys:
            fields = update_job.get(issue)
            pre(u'* %s' % issue)
            issue_fields = sorted(fields.keys())
            for fid in issue_fields:
                value = fields.get(fid)
                fname = cache.fields.get_field_name(fid, fid)
                if not value:
                    value = u''
                else:
                    if type(value) in (list, tuple):
                        items = []
                        for item in value:
                            if type(item) == dict:
                                if item:
                                    items.append(item.get(item.keys()[0]))
                        else:
                            items.append(str(item))
                        value = u', '.join(items)
                    elif type(value) == dict:
                        if 'name' in value:
                            value = value.get('name', value)
                        elif 'key' in value:
                            value = value.get('key', value)
                        else:
                            value = value.get(value.keys()[0])
                    if not value:
                        value = u''
                value = jicML.emit_value(value)
                pre(u'  - %s: %s' % (fname, value))

    if not Util.confirm(u'\nWould you like to apply them? (y/n)'):
        return 1

    # execute create job
    created_issues = []
    if create_job:
        for issue_key, fields in create_job.iteritems():
            pr('%s: %s' % (issue_key, repr(fields)))
            vpre(VERBOSITY_INFO, u'Creating %s...' % issue_key, end=u'')
            issue = cache.create(fields)
            created_issues.append(issue.key)
            pre(VERBOSITY_ERRORS, u'\nCreated new issue for alias %s: %s' % \
                                                (issue_key, issue.key))
            vpre(VERBOSITY_INFO, u'Done!')

    # execute the job
    if update_job:
        for issue_key, fields in update_job.iteritems():
            vpre(VERBOSITY_INFO, u'Updating %s...' % issue_key, end=u'')
            issue = cache.get(issue_key)[0]
            issue.update(**fields)
            vpre(VERBOSITY_INFO, u' - done!')

    issues = created_issues
    issues.extend(update_job.keys())
    vpre(VERBOSITY_INFO, u'Fetching %d issues...' % len(issues), end=u'')
    cache.fetch(issues)
    vpre(VERBOSITY_INFO, u' - done!')

    return 0


# TODO: get from template
EDIT_ISSUES_PROMPT = """\
# Please edit the issue%s listed below. You may also add additional
# issues and/or fields you would like to edit with their respective new
# values, or remove ones (or just kip them intact) you would not like to
# edit.
#
# Leave the file intact or delete all its content to cancel the
# operation.

"""

def cmd_issues_edit(cfg):
    cache = Cache(cfg)

    if cache.mode == Cache.MODE_OFFLINE:
        raise RuntimeError(
                u'Can\'t edit issues in offline mode yet')

    listed_issues = \
        Util.unwrap_list_of_lists(cfg.o.get('query.args',()))

    if not cfg.o.get('cl.use_editor', False) \
    or not sys.stdin.isatty() \
    or not sys.stdout.isatty():
        raise RuntimeError(
            u'Issue editing is only sopported using an editor for now')

    # validate issues listed
    to_edit = []
    for issue in listed_issues:
        if not Util.is_issue_key(issue):
            vpre(VERBOSITY_WARNINGS,
                u'Not an issue key: \'%s\'. Skipped.' % issue)
            continue
        to_edit.append(issue)

    if not to_edit:
        vpre(VERBOSITY_WARNINGS, u'WARNING: Nothing to do.')
        return 0

    tpl = Template(cfg, cache)

    edc = EditingContext(cfg, cache, tpl)

    # fetch issues
    vpre(VERBOSITY_INFO,
        u'Fetching %d issues for editing...' % len(to_edit),
        end=u'')
    issues = cache.fetch(to_edit)
    vpre(VERBOSITY_INFO, u' - done!')

    # emit jicML for all the issues
    jicml = EDIT_ISSUES_PROMPT % (u's' if len(to_edit) != 1 else u'')
    jicml += edc.prepare_issues_for_editing(issues)

    # invoke editor
    editor = cfg.o.get('editor', 'sensible-editor')
    edited_jicml = Util.get_from_editor(
                    cfg, editor, jicml, file_suffix=u'jicml')

    if not edited_jicml:
        vpre(VERBOSITY_INFO, u'Cancelled by the user')
        return 0

    # parse issues
    parsed_issues = edc.parse_edited_issues(edited_jicml)

    # generate job
    update_job = edc.generate_update_job()

    # show job and get user's confirmation
    pre(u'Pending changes to be applied:')
    issue_keys = sorted(update_job.keys())
    for issue in issue_keys:
        fields = update_job.get(issue)
        pre(u'* %s' % issue)
        issue_fields = sorted(fields.keys())
        for fid in issue_fields:
            value = fields.get(fid)
            fname = cache.fields.get_field_name(fid, fid)
            if not value:
                value = u''
            else:
                if type(value) in (list, tuple):
                    items = []
                    for item in value:
                        if type(item) == dict:
                            if item:
                                items.append(item.get(item.keys()[0]))
                        else:
                            items.append(str(item))
                    value = u', '.join(items)
                elif type(value) == dict:
                    if 'name' in value:
                        value = value.get('name', value)
                    elif 'key' in value:
                        value = value.get('key', value)
                    else:
                        value = value.get(value.keys()[0])
                if not value:
                    value = u''
            value = jicML.emit_value(value)
            #pre(u'  - %s: %s' % (fname, repr(value)))
            pre(u'  - %s: %s' % (fname, value))

    if not Util.confirm(u'\nWould you like to apply them? (y/n)'):
        return 1

    # execute the job
    for issue_key, fields in update_job.iteritems():
        vpre(VERBOSITY_INFO, u'Updating %s...' % issue_key, end=u'')
        issue = cache.get(issue_key)[0]
        issue.update(**fields)
        vpre(VERBOSITY_INFO, u' - done!')

    issues = update_job.keys()
    vpre(VERBOSITY_INFO, u'Fetching %d issues...' % len(issues), end=u'')
    cache.fetch(issues)
    vpre(VERBOSITY_INFO, u' - done!')

    return 0


def cmd_issues_fetch(cfg):
    if cache.mode == Cache.MODE_OFFLINE:
        raise RuntimeError(
                u'Can\'t fetch issues in offline mode')

    listed_issues = \
        Util.unwrap_list_of_lists(cfg.o.get('query.args',()))

    cache = Cache(cfg)
    tpl = Template(cfg, cache)

    cache.fetch(listed_issues,
                cfg.o.get('query.down', False),
                cfg.o.get('query.up', False),
                cfg.o.get('query.down_from'),
                cfg.o.get('query.up_from'),
                cfg.o.get('query.include_self', False),
                cfg.o.get('query.link_types'),
                cfg.o.get('query.depth'),
                cfg.o.get('display.order_by'),
                cfg.o.get('query.number_of_items'),
                cfg.o.get('query.filter'),
                cfg.o.get('query.jql'))

    return 0


def cmd_issues_fields(cfg):
    partial_names = \
        Util.unwrap_list_of_lists(cfg.o.get('query.args',()))

    cache = Cache(cfg)
    tpl = Template(cfg, cache)

    to_match = [name.lower() for name in partial_names]

    matched = False
    for field in cache.fields.field_meta:
        if partial_names:
            id = field.get('id').lower()
            name = field.get('name').lower()
            for part_name in to_match:
                if id.find(part_name) != -1 \
                or name.find(part_name) != -1:
                    matched = True
                    pr(tpl.format_issue_field_meta(tpl, field))
                    break
        else:
            matched = True
            pr(tpl.format_issue_field_meta(tpl, field))
    if not matched:
        pr(u'No fields matched: %s' % (u', '.join(partial_names)))


def cmd_issues_forget(cfg):
    listed_issues = \
        Util.unwrap_list_of_lists(cfg.o.get('query.args',()))

    cache = Cache(cfg)

    cache.forget(listed_issues)


def cmd_issues_list(cfg):
    listed_issues = \
        Util.unwrap_list_of_lists(cfg.o.get('query.args',()))

    cache = Cache(cfg)
    tpl = Template(cfg, cache)

    issues = cache.get(
                listed_issues,
                cfg.o.get('query.down', False),
                cfg.o.get('query.up', False),
                cfg.o.get('query.down_from'),
                cfg.o.get('query.up_from'),
                cfg.o.get('query.include_self', False),
                cfg.o.get('query.link_types'),
                cfg.o.get('query.depth'),
                cfg.o.get('display.order_by'),
                cfg.o.get('query.number_of_items'),
                cfg.o.get('query.filter'),
                cfg.o.get('query.jql'))

    tpl.print_issue_list(tpl, issues)

    return 0


def cmd_issues_open(cfg):
    cache = Cache(cfg)

    listed_issues = \
        Util.unwrap_list_of_lists(cfg.o.get('query.args',()))


    browser = cfg.o.get('browser', 'sensible-browser')
    server_url = cache.srv_cfg.get('url')
    if not server_url:
        raise RuntimeError(
            u'Internal Error: missing server url')

    if not listed_issues:
        vargs = (browser, server_url)
        subprocess.Popen(vargs, stdout=open('/dev/null', 'w'),
                         stderr=subprocess.STDOUT)
        return 0

    for issue in listed_issues:
        url = server_url + '/browse/%s' % issue
        vargs = (browser, url)
        subprocess.Popen(vargs, stdout=open('/dev/null', 'w'),
                         stderr=subprocess.STDOUT)

    return 0


def cmd_issues_pull(cfg):
    cache = Cache(cfg)

    cache.pull()

    return 0


def cmd_issues_show(cfg):
    listed_issues = \
        Util.unwrap_list_of_lists(cfg.o.get('query.args',()))

    parts = cfg.o.get('query.parts', ('fields', 'comments'))
    all = 'all' in parts
    show_worklog = all or 'worklog' in parts

    cache = Cache(cfg)
    tpl = Template(cfg, cache)

    issues = cache.get(
                listed_issues,
                cfg.o.get('query.down', False),
                cfg.o.get('query.up', False),
                cfg.o.get('query.down_from'),
                cfg.o.get('query.up_from'),
                cfg.o.get('query.include_self', False),
                cfg.o.get('query.link_types'),
                cfg.o.get('query.depth'),
                cfg.o.get('display.order_by'),
                cfg.o.get('query.number_of_items'),
                cfg.o.get('query.filter'),
                cfg.o.get('query.jql'),
                worklogs=show_worklog)

    for issue in issues:
        if all or 'fields' in parts:
            pr(tpl.format_all_issue_fields(tpl, issue), end='')
        else:
            pr(tpl.format_issue_header(tpl, issue), end='')
        if all or 'links' in parts:
            tpl.print_issue_links(tpl, issue)
        if all or 'comments' in parts:
            tpl.print_issue_comments(tpl, issue)
        if all or 'history' in parts:
            tpl.print_issue_history(tpl, issue)
        if show_worklog:
            tpl.print_issue_worklog(tpl, issue)
        pr()

    return 0


server_definition_values = {
    'name':     'servers.',
    'url':      'url',
    'user':     'user',
    'password': 'password',
    'mode':     'cache.mode',
    'ttl':      'cache.ttl',
    'cert':     'oauth.cert',
    'token':    'oauth.token',
    'secret':   'oauth.secret',
}

def cmd_servers_add(cfg):
    """Arguments passed via command line:
        #1: 'name' - server name
        #2: 'url' - server url
        #3: 'user' - user name
        #4: 'password' - password
        #5: 'mode' - default cache mode
        #6: 'ttl' - ttl for cached data
        #7: 'cert' - certificate for OAuth
        #8: 'token' - OAuth token
        #9: 'secret' - OAuth secret
    """
    global server_definition_values

    args = \
        Util.unwrap_list_of_lists(cfg.o.get('query.args',()))

    if not sys.stdin.isatty():
        for line in sys.stdin:
            args.append(line.strip())

    if not args or len(args) < 1:
        raise RuntimeError(
            u'Please specify server name')

    if not args or len(args) < 2:
        raise RuntimeError(
            u'Please specify at least one option')

    server_name = args.pop(0)

    for idx, ch in enumerate(server_name):
        if (idx == 0 and not ch.isalpha()) \
        or (idx > 0 and not ch.isalnum() and ch != u'_'):
            raise RuntimeError(
                u'Server name can only contain alpha-numerics ' \
                u'and underscores.')

    server_def = {}
    in_error = False
    for arg in args:
        name, _, value = arg.partition(u':')
        if name not in server_definition_values:
            vpre(VERBOSITY_ERRORS, u'ERROR: Unknown parameter: %s' % name)
            in_error = True
            continue
        server_def[name] = value

    if in_error:
        return 1

    server_path = 'servers.%s.' % server_name

    job = {}
    for option, value in server_def.iteritems():
        option = server_definition_values.get(option, option)
        if option == 'oauth.cert':
            if not value.lstrip().startswith(
                                u'-----BEGIN PRIVATE KEY-----'):
                try:
                    value = os.path.expandvars(
                                os.path.expanduser(value))
                    f = open(value, 'r')
                    cert_body = f.read()
                    f.close()
                    value = cert_body.strip()
                except IOError, e:
                    raise RuntimeError(
                        u'Unable to load certificate: %s' % str(e))
        elif option == 'cache.ttl':
            value = int(value)
        job['%s%s' % (server_path, option)] =  value
    cfg.update_file(job)


def cmd_servers_dance(cfg):
    args = \
        Util.unwrap_list_of_lists(cfg.o.get('query.args',()))

    if not sys.stdin.isatty():
        raise RuntimeError(
            u'This is an interactive operation - please do not '\
            u'redirect jic\'s standard input')

    if not args or len(args) < 1:
        raise RuntimeError(
            u'Please specify server name')

    browser = cfg.o.get('browser', 'sensible-browser')

    server_name = args[0].strip()

    server_url = cfg.o.get('servers.%s.url' % server_name)

    if not server_url:
        raise RuntimeError(
            u'Server \'%s\' has no url defined.' % server_name)

    if len(args) == 2:
        cert = args[1]
        if not cert.lstrip().startswith(
                        u'-----BEGIN PRIVATE KEY-----'):
            try:
                cert_file = os.path.expandvars(
                            os.path.expanduser(cert))
                f = open(cert_file, 'r')
                cert_body = f.read()
                f.close()
                cert = cert_body.strip()
            except IOError, e:
                raise RuntimeError(
                    u'Unable to load certificate: %s' % str(e))
    else:
        cert = cfg.o.get('oauth.cert')

    if not cert:
        raise RuntimeError(
            u'Server should have a certificate set to perform '\
            u'an OAuth dance.\nPlease see `man jic-config` for '\
            u'details.')

    class RSA_SHA1_SignatureMethod(oauth.SignatureMethod):
        cert = None
        name = 'RSA-SHA1'

        def signing_base(self, request, consumer, token):

            if not hasattr(request, 'normalized_url') \
            or request.normalized_url is None:
                raise ValueError("Request is missing the Base URL")

            sig = (
                oauth.escape(request.method),
                oauth.escape(request.normalized_url),
                oauth.escape(request.get_normalized_parameters()),
            )

            key = '%s&' % oauth.escape(consumer.secret)
            if token:
                key += oauth.escape(token.secret)
            raw = '&'.join(sig)

            return key, raw

        def sign(self, request, consumer, token):

            key, raw = self.signing_base(request, consumer, token)

            pvt_key_body = RSA_SHA1_SignatureMethod.cert
            pvt_key = keyfactory.parsePrivateKey(pvt_key_body)
            signature = pvt_key.hashAndSign(raw)

            return base64.b64encode(signature)

    # class SignatureMethod_RSA_SHA1

    RSA_SHA1_SignatureMethod.cert = cert

    consumer_key = OAUTH_APPLICATION_KEY
    consumer_secret = 'whatever'

    request_token_url = \
        '%s/plugins/servlet/oauth/request-token' % server_url
    access_token_url = \
        '%s/plugins/servlet/oauth/access-token' % server_url
    authorize_url = \
        '%s/plugins/servlet/oauth/authorize' % server_url

    consumer = oauth.Consumer(consumer_key, consumer_secret)
    client = oauth.Client(consumer)
    client.set_signature_method(RSA_SHA1_SignatureMethod())

    vpre(VERBOSITY_INFO,
        'OAuth: Requesting token at %s' % request_token_url)
    res, raw = client.request(request_token_url, "POST")
    if res['status'] != '200':
        raise RuntimeError(
            u'OAuth: Invalid response %s: %s' % (res['status'], raw))

    req_token = dict(urlparse.parse_qsl(raw))

    authorize_url += '?oauth_token=%s' % req_token['oauth_token']
    pre('Opening OAuth authorization page using %s...' % browser)
    vargs = (browser, authorize_url)
    subprocess.Popen(vargs, stdout=open('/dev/null', 'w'),
                     stderr=subprocess.STDOUT)
    pre('Now please authorize jic in JIRA using the web '\
       'page\n%s\nopened in %s.' % (authorize_url, browser))
    pre()

    if not Util.confirm(u'Have you performed authorization? (y/n)'):
        return 1

    token = oauth.Token(req_token['oauth_token'],
        req_token['oauth_token_secret'])
    client = oauth.Client(consumer, token)
    client.set_signature_method(RSA_SHA1_SignatureMethod())

    res, raw = client.request(access_token_url, "POST")
    acc_token = dict(urlparse.parse_qsl(raw))

    if 'oauth_problem' in acc_token:
        raise RuntimeError(
            u'Could not get OAuth token: %s' % \
                acc_token['oauth_problem'])
    else:
        job = {}
        job['servers.%s.oauth.token' % server_name] = \
                                        acc_token['oauth_token']
        job['servers.%s.oauth.secret' % server_name] = \
                                        acc_token['oauth_token_secret']
        job['servers.%s.oauth.cert' % server_name] = \
                                        cert
        cfg.update_file(job)

    return 0


def cmd_servers_delete(cfg):
    server_names = \
        Util.unwrap_list_of_lists(cfg.o.get('query.args',()))

    servers = cfg.o.get('servers')
    if servers is None:
        raise RuntimeError(
            u'No servers configured.')

    default = cfg.o.get('server', '')

    cache = Cache(cfg)
    tpl = Template(cfg, cache)

    first = True
    to_delete = []
    deleting_default = False
    job = {}
    for name in server_names:
        server = servers.get(name)
        if not server:
            vpre(VERBOSITY_WARNINGS,
                u'WARNING: Server \'%s\' is not known - skipped' % name)
            continue
        if first:
            pre(u'The following servers are going to be deleted:\n')
            first = False

        pr(tpl.format_server(tpl, name, server, name == default))

        to_delete.append(name)

        if name == default:
            deleting_default = True

        for opt_name, value in server.itertree():
            option = 'servers.%s.%s' % (name, opt_name)
            job[option] = None

    if not job:
        vpre(VERBOSITY_WARNINGS, u'WARNING: Nothing to do.')
        return 0

    if Util.confirm(
            u'\nAre you sure you want to delete them? (type YES)',
            strict=True):
        if deleting_default:
            job['server'] = None
        cfg.update_file(job)
        vpre(VERBOSITY_INFO, u'Deleted servers: %s' % (u', '.join(to_delete)))
        if deleting_default:
            vpre(VERBOSITY_WARNINGS,
                u'WARNING: There is no default server set anymore.')
    else:
        vpre(VERBOSITY_INFO, u'Not deleting.')

    return 0


def cmd_servers_list(cfg):
    tpl = Template(cfg)

    default = cfg.o.get('server', '')

    for srv_name, srv_def in cfg.o.get('servers').iteritems():
        pr(tpl.format_server_list_item(
                tpl, srv_name, srv_def, srv_name == default))


def cmd_servers_select(cfg):
    server_names = \
        Util.unwrap_list_of_lists(cfg.o.get('query.args',()))

    if len(server_names) != 1:
        raise RuntimeError(
            u'Please specify one name of the server')

    server_name = server_names[0]

    server = cfg.o.get('servers.%s' % server_name)
    if not server:
        raise RuntimeError(
            u'Server \'%s\' is not known.' % server_name)

    job = { 'server': server_name }

    cfg.update_file(job)

    vpre(VERBOSITY_INFO,
        u'Selected \'%s\' as the default server' % server_name)

    return 0


def cmd_servers_show(cfg):
    servers = cfg.o.get('servers')
    if servers is None:
        raise RuntimeError(
            u'No servers configured.')

    server_names = \
        Util.unwrap_list_of_lists(cfg.o.get('query.args',()))

    if not server_names:
        default = cfg.o.get('server')
        if not default:
            raise RuntimeError(
                u'No server name provided and no default server set')
        server_names = ( default, )

    tpl = Template(cfg)

    default = cfg.o.get('server', '')

    first = True
    to_show = []
    for srv_name in server_names:
        srv_def  = servers.get(srv_name)
        if not srv_def :
            pre(u'Server \'%s\' is not known - skipped' % srv_name)
            continue
        to_show.append((srv_name, srv_def ))

    if not to_show:
        vpre(VERBOSITY_WARNINGS, u'WARNING: Nothing to do.')
        return 0

    for srv_name, srv_def in to_show:
        pr(tpl.format_server(
                tpl, srv_name, srv_def, srv_name == default))

    return 0


OAUTH_APPLICATION_KEY='jic-tool'
ASK_FOR_VALUE='<ask>'


def ctrl_c_handler(signum, frame):
    pre('\nInterrupted.')
    sys.exit(1)

status_code_messages = {
    400: u'Bad Request',
    401: u'Unauthorized',
    403: u'Forbidden',
    404: u'Not Found',
    500: u'Internal Server Error'
}

def error_from_status_code(status_code):
    return status_code_messages.get(status_code, u'Unknown')

def error_message(exception):
    if exception is None \
    or 'status_code' not in exception.__dict__:
        return u'Unknown error'

    return u'%d: %s' % \
        (exception.status_code,
         error_from_status_code(exception.status_code))

def pre(string=u'', end=u'\n', flush=False):
    print(string.encode('utf-8'), file=sys.stderr, end=end)
    if flush:
        sys.stderr.flush()

def pr(string=u'', end=u'\n', flush=False):
    print(string.encode('utf-8'), file=sys.stdout, end=end)
    if flush:
        sys.stdout.flush()

def main():

    signal.signal(signal.SIGINT, ctrl_c_handler)

    try:
        cfg = Configuration()
        cl = CommandLine(cfg)
        cfg.freeze()

        if not cl.command_path:
            raise RuntimeError(
                u'Did not recognize any commands.')

        return cl.execute(cfg)

    except RuntimeError, e:
        vpre(VERBOSITY_ERRORS, u'ERROR: %s' % str(e))
        return 1

    except JIRAError, e:
        text = u''
        if isinstance(e.text, dict):
            first = True
            for name, value in e.text.iteritems():
                if first:
                    first = False
                else:
                    text += u'; '
                text += u'%s: %s' % (name, value)
        vpre(VERBOSITY_ERRORS, u'ERROR: %s' % text)
        vpre(VERBOSITY_INFO, traceback.format_exc())
        return 1

    except Exception, e:
        vpre(VERBOSITY_ERRORS, u'ERROR: %s' % str(e))
        vpre(VERBOSITY_ERRORS, traceback.format_exc())
        return 1


if __name__ == '__main__':
    main()
